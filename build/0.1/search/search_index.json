{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Boxs \ud83d\udd17 Boxs is a python library that manages data automatically and keeps track of different versions of the same data created in different runs of the same script. No more need to manually think about file paths and S3 keys, just store the data and let boxs manage the rest. Besides managing the version history of the data, boxs allows to track the dependencies between different artifacts. It is meant as a tool for making it easy to manage artifacts in workflows for data science and machine learning. It is currently under development by Kantai GmbH and licensed under MIT License . Interested in first steps using boxs? \ud83d\udd17 Take a look at our Getting started documentation . Want to learn more about the details? \ud83d\udd17 Read through our User guide to understand how it works. You have questions? \ud83d\udd17 Feel free to reach out to us. Our support channels can be found on our documentation home on https://docs.kant.ai .","title":"Home"},{"location":"#boxs","text":"Boxs is a python library that manages data automatically and keeps track of different versions of the same data created in different runs of the same script. No more need to manually think about file paths and S3 keys, just store the data and let boxs manage the rest. Besides managing the version history of the data, boxs allows to track the dependencies between different artifacts. It is meant as a tool for making it easy to manage artifacts in workflows for data science and machine learning. It is currently under development by Kantai GmbH and licensed under MIT License .","title":"Boxs"},{"location":"#interested-in-first-steps-using-boxs","text":"Take a look at our Getting started documentation .","title":"Interested in first steps using boxs?"},{"location":"#want-to-learn-more-about-the-details","text":"Read through our User guide to understand how it works.","title":"Want to learn more about the details?"},{"location":"#you-have-questions","text":"Feel free to reach out to us. Our support channels can be found on our documentation home on https://docs.kant.ai .","title":"You have questions?"},{"location":"api/","text":"Automatically track data and artifacts This package provides an API to automatically track data and artifacts in a machine learning process without the need to manually think about file names or S3 keys. By using its API the data is automatically stored and loaded in different versions per execution which allows to compare the data between different runs. api \ud83d\udd17 API to be used by users info ( data_ref ) \ud83d\udd17 Load info from a reference to an item. Parameters: Name Type Description Default data_ref boxs.data.DataRef Data reference that points to the data whose info is requested. required Returns: Type Description boxs.data.DataInfo The info about the data. Exceptions: Type Description boxs.errors.BoxNotDefined If the data is stored in an unknown box. boxs.errors.DataNotFound If no data with the specific ids are stored in this box. Source code in boxs/api.py def info ( data_ref ): \"\"\" Load info from a reference to an item. Args: data_ref (boxs.data.DataRef): Data reference that points to the data whose info is requested. Returns: boxs.data.DataInfo: The info about the data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in this box. \"\"\" box_id = data_ref . box_id box = get_box ( box_id ) logger . debug ( \"Getting info about value %s from box %s \" , data_ref . uri , box . box_id ) return box . info ( data_ref ) load ( data , value_type = None ) \ud83d\udd17 Load the content of the data item. Parameters: Name Type Description Default data Union[boxs.data.DataRef,boxs.data.DataInfo] DataInfo or DataRef that points to the data that should be loaded. required value_type boxs.value_types.ValueType The value type to use when loading the data. Defaults to None , in which case the same value type will be used that was used when the data was initially stored. None Returns: Type Description Any The loaded data. Exceptions: Type Description boxs.errors.BoxNotDefined If the data is stored in an unknown box. boxs.errors.DataNotFound If no data with the specific ids are stored in the referenced box. Source code in boxs/api.py def load ( data , value_type = None ): \"\"\" Load the content of the data item. Args: data (Union[boxs.data.DataRef,boxs.data.DataInfo]): DataInfo or DataRef that points to the data that should be loaded. value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in the referenced box. \"\"\" box_id = data . box_id box = get_box ( box_id ) logger . debug ( \"Loading value %s from box %s \" , data . uri , box . box_id ) return box . load ( data , value_type = value_type ) store ( value , * parents , * , name = None , origin = ORIGIN_FROM_FUNCTION_NAME , tags = None , meta = None , value_type = None , run_id = None , box = None ) \ud83d\udd17 Store new data in this box. Parameters: Name Type Description Default value Any A value that should be stored. required *parents Union[boxs.data.DataInfo,boxs.data.DataRef] Parent data refs, that this data depends on. () origin Union[str,Callable] A string or callable returning a string, that is used as an origin for deriving the data's id. Defaults to a callable, that takes the name of the function, from which store is being called as origin. ORIGIN_FROM_FUNCTION_NAME name str An optional user-defined name, that can be used for looking up data manually. None tags Dict[str,str] A dictionary of tags that can be used for grouping multiple data together. Keys and values have to be strings. None meta Dict[str, Any] Additional meta-data about this data. This can be used for arbitrary information that might be useful, e.g. information about type or format of the data, timestamps, user info etc. None value_type boxs.value_types.ValueType The value_type to use for writing this value to the storage. Defaults to None in which case a suitable value type is taken from the list of predefined values types. None run_id str The id of the run when the data was stored. Defaults to the current global run_id (see get_run_id() ). None box Union[str,boxs.box.Box] The box in which the data should be stored. The box can be either given as Box instance, or by its box_id . None Returns: Type Description boxs.data.DataInfo Data instance that contains information about the data and allows referring to it. Exceptions: Type Description ValueError If no box or no origin was provided. boxs.errors.BoxNotDefined If no box with the given box id is defined. Source code in boxs/api.py def store ( value , * parents , name = None , origin = ORIGIN_FROM_FUNCTION_NAME , tags = None , meta = None , value_type = None , run_id = None , box = None ): \"\"\" Store new data in this box. Args: value (Any): A value that should be stored. *parents (Union[boxs.data.DataInfo,boxs.data.DataRef]): Parent data refs, that this data depends on. origin (Union[str,Callable]): A string or callable returning a string, that is used as an origin for deriving the data's id. Defaults to a callable, that takes the name of the function, from which `store` is being called as origin. name (str): An optional user-defined name, that can be used for looking up data manually. tags (Dict[str,str]): A dictionary of tags that can be used for grouping multiple data together. Keys and values have to be strings. meta (Dict[str, Any]): Additional meta-data about this data. This can be used for arbitrary information that might be useful, e.g. information about type or format of the data, timestamps, user info etc. value_type (boxs.value_types.ValueType): The value_type to use for writing this value to the storage. Defaults to `None` in which case a suitable value type is taken from the list of predefined values types. run_id (str): The id of the run when the data was stored. Defaults to the current global run_id (see `get_run_id()`). box (Union[str,boxs.box.Box]): The box in which the data should be stored. The box can be either given as Box instance, or by its `box_id`. Returns: boxs.data.DataInfo: Data instance that contains information about the data and allows referring to it. Raises: ValueError: If no box or no origin was provided. boxs.errors.BoxNotDefined: If no box with the given box id is defined. \"\"\" if box is None : box = get_config () . default_box logger . debug ( \"No box defined, using default_box %s from config\" , box ) if box is None : raise ValueError ( \"'box' must be set.\" ) if isinstance ( box , str ): box = get_box ( box ) origin = determine_origin ( origin , name = name , tags = tags , level = 3 ) return box . store ( value , * parents , name = name , origin = origin , tags = tags , meta = meta , value_type = value_type , run_id = run_id ) box \ud83d\udd17 Boxes to store items in Box \ud83d\udd17 Box that allows to store and load data. Attributes: Name Type Description box_id str The id that uniquely identifies this Box. storage boxs.storage.Storage The storage that actually writes and reads the data. transformers boxs.storage.Transformer A tuple with transformers, that add additional meta-data and transform the data stored and loaded. Source code in boxs/box.py class Box : \"\"\"Box that allows to store and load data. Attributes: box_id (str): The id that uniquely identifies this Box. storage (boxs.storage.Storage): The storage that actually writes and reads the data. transformers (boxs.storage.Transformer): A tuple with transformers, that add additional meta-data and transform the data stored and loaded. \"\"\" def __init__ ( self , box_id , storage , * transformers ): self . box_id = box_id self . storage = storage self . transformers = transformers self . value_types = [ BytesValueType (), StreamValueType (), StringValueType (), FileValueType (), JsonValueType (), ] register_box ( self ) def add_value_type ( self , value_type ): \"\"\" Add a new value type. The value type is added at the beginning of the list, so that it takes precedence over the already added value types. Args: value_type (boxs.value_types.ValueType): The new value type to add. \"\"\" self . value_types . insert ( 0 , value_type ) def store ( self , value , * parents , origin = ORIGIN_FROM_FUNCTION_NAME , name = None , tags = None , meta = None , value_type = None , run_id = None , ): \"\"\" Store new data in this box. Args: value (Any): A value that should be stored. *parents (Union[boxs.data.DataInfo, boxs.data.DataRef]): Parent data refs, that this data depends on. origin (Union[str,Callable]): A string or callable returning a string, that is used as an origin for deriving the data's id. Defaults to a callable, that takes the name of the function, from which `store` is being called as origin. name (str): An optional user-defined name, that can be used for looking up data manually. tags (Dict[str,str]): A dictionary of tags that can be used for grouping multiple data together. Keys and values have to be strings. meta (Dict[str, Any]): Additional meta-data about this data. This can be used for arbitrary information that might be useful, e.g. information about type or format of the data, timestamps, user info etc. value_type (boxs.value_types.ValueType): The value_type to use for writing this value to the storage. Defaults to `None` in which case a suitable value type is taken from the list of predefined values types. run_id (str): The id of the run when the data was stored. Returns: boxs.data.DataInfo: Data instance that contains information about the data and allows referring to it. \"\"\" if tags is None : tags = {} if meta is None : meta = {} else : meta = dict ( meta ) origin = determine_origin ( origin , name = name , tags = tags , level = 3 ) logger . info ( \"Storing value in box %s with origin %s \" , self . box_id , origin ) parent_ids = tuple ( p . data_id for p in parents ) data_id = calculate_data_id ( origin , parent_ids = parent_ids , name = name ) logger . debug ( \"Calculate data_id %s from origin %s with parents %s \" , data_id , origin , parent_ids , ) if run_id is None : run_id = get_run_id () ref = DataRef ( self . box_id , data_id , run_id ) writer = self . storage . create_writer ( ref , name , tags ) logger . debug ( \"Created writer %s for data %s \" , writer , ref ) writer = self . _apply_transformers_to_writer ( writer ) if value_type is None : value_type = self . _find_suitable_value_type ( value ) if value_type is None : raise MissingValueType ( value ) logger . debug ( \"Write value for data %s with value type %s \" , ref . uri , value_type . get_specification (), ) writer . write_value ( value , value_type ) meta [ 'value_type' ] = value_type . get_specification () meta = dict ( meta ) meta . update ( writer . meta ) data_info = DataInfo ( DataRef . from_item ( writer . item ), origin = origin , parents = parents , name = name , tags = tags , meta = meta , ) logger . debug ( \"Write info for data %s \" , ref . uri ) writer . write_info ( data_info . value_info ()) return data_info def _find_suitable_value_type ( self , value ): value_type = None for configured_value_type in self . value_types : if configured_value_type . supports ( value ): value_type = configured_value_type logger . debug ( \"Automatically chose value type %s \" , value_type . get_specification (), ) return value_type def _apply_transformers_to_writer ( self , writer ): for transformer in self . transformers : logger . debug ( \"Applying transformer %s \" , transformer ) writer = transformer . transform_writer ( writer ) return writer def load ( self , data_ref , value_type = None ): \"\"\" Load data from the box. Args: data_ref (Union[boxs.data.DataRef,boxs.data.DataInfo]): Data reference that points to the data content to be loaded. value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.DataNotFound: If no data with the specific ids are stored in this box. ValueError: If the data refers to a different box by its box_id. \"\"\" if data_ref . box_id != self . box_id : raise ValueError ( \"Data references different box id\" ) logger . info ( \"Loading value %s from box %s \" , data_ref . uri , self . box_id ) info = data_ref . info if value_type is None : value_type = self . _get_value_type_from_meta_data ( info ) reader = self . storage . create_reader ( data_ref ) logger . debug ( \"Created reader %s for data %s \" , reader , data_ref ) reader = self . _apply_transformers_to_reader ( reader ) logger . debug ( \"Read value from data %s with value type %s \" , data_ref . uri , value_type . get_specification (), ) return reader . read_value ( value_type ) @staticmethod def _get_value_type_from_meta_data ( info ): value_type_specification = info . meta [ 'value_type' ] value_type = ValueType . from_specification ( value_type_specification ) logger . debug ( \"Use value type %s taken from meta-data\" , value_type . get_specification (), ) return value_type def _apply_transformers_to_reader ( self , reader ): for transformer in reversed ( self . transformers ): logger . debug ( \"Applying transformer %s \" , transformer ) reader = transformer . transform_reader ( reader ) return reader def info ( self , data_ref ): \"\"\" Load info from the box. Args: data_ref (boxs.data.DataRef): Data reference that points to the data whose info is requested. Returns: boxs.data.DataInfo: The info about the data. Raises: boxs.errors.DataNotFound: If no data with the specific ids are stored in this box. ValueError: If the data refers to a different box by its box_id. \"\"\" if data_ref . box_id != self . box_id : raise ValueError ( \"Data references different box id\" ) logger . info ( \"Getting info for value %s from box %s \" , data_ref . uri , self . box_id ) reader = self . storage . create_reader ( data_ref ) logger . debug ( \"Created reader %s for data %s \" , reader , data_ref ) return DataInfo . from_value_info ( reader . info ) add_value_type ( self , value_type ) \ud83d\udd17 Add a new value type. The value type is added at the beginning of the list, so that it takes precedence over the already added value types. Parameters: Name Type Description Default value_type boxs.value_types.ValueType The new value type to add. required Source code in boxs/box.py def add_value_type ( self , value_type ): \"\"\" Add a new value type. The value type is added at the beginning of the list, so that it takes precedence over the already added value types. Args: value_type (boxs.value_types.ValueType): The new value type to add. \"\"\" self . value_types . insert ( 0 , value_type ) info ( self , data_ref ) \ud83d\udd17 Load info from the box. Parameters: Name Type Description Default data_ref boxs.data.DataRef Data reference that points to the data whose info is requested. required Returns: Type Description boxs.data.DataInfo The info about the data. Exceptions: Type Description boxs.errors.DataNotFound If no data with the specific ids are stored in this box. ValueError If the data refers to a different box by its box_id. Source code in boxs/box.py def info ( self , data_ref ): \"\"\" Load info from the box. Args: data_ref (boxs.data.DataRef): Data reference that points to the data whose info is requested. Returns: boxs.data.DataInfo: The info about the data. Raises: boxs.errors.DataNotFound: If no data with the specific ids are stored in this box. ValueError: If the data refers to a different box by its box_id. \"\"\" if data_ref . box_id != self . box_id : raise ValueError ( \"Data references different box id\" ) logger . info ( \"Getting info for value %s from box %s \" , data_ref . uri , self . box_id ) reader = self . storage . create_reader ( data_ref ) logger . debug ( \"Created reader %s for data %s \" , reader , data_ref ) return DataInfo . from_value_info ( reader . info ) load ( self , data_ref , value_type = None ) \ud83d\udd17 Load data from the box. Parameters: Name Type Description Default data_ref Union[boxs.data.DataRef,boxs.data.DataInfo] Data reference that points to the data content to be loaded. required value_type boxs.value_types.ValueType The value type to use when loading the data. Defaults to None , in which case the same value type will be used that was used when the data was initially stored. None Returns: Type Description Any The loaded data. Exceptions: Type Description boxs.errors.DataNotFound If no data with the specific ids are stored in this box. ValueError If the data refers to a different box by its box_id. Source code in boxs/box.py def load ( self , data_ref , value_type = None ): \"\"\" Load data from the box. Args: data_ref (Union[boxs.data.DataRef,boxs.data.DataInfo]): Data reference that points to the data content to be loaded. value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.DataNotFound: If no data with the specific ids are stored in this box. ValueError: If the data refers to a different box by its box_id. \"\"\" if data_ref . box_id != self . box_id : raise ValueError ( \"Data references different box id\" ) logger . info ( \"Loading value %s from box %s \" , data_ref . uri , self . box_id ) info = data_ref . info if value_type is None : value_type = self . _get_value_type_from_meta_data ( info ) reader = self . storage . create_reader ( data_ref ) logger . debug ( \"Created reader %s for data %s \" , reader , data_ref ) reader = self . _apply_transformers_to_reader ( reader ) logger . debug ( \"Read value from data %s with value type %s \" , data_ref . uri , value_type . get_specification (), ) return reader . read_value ( value_type ) store ( self , value , * parents , * , origin = ORIGIN_FROM_FUNCTION_NAME , name = None , tags = None , meta = None , value_type = None , run_id = None ) \ud83d\udd17 Store new data in this box. Parameters: Name Type Description Default value Any A value that should be stored. required *parents Union[boxs.data.DataInfo, boxs.data.DataRef] Parent data refs, that this data depends on. () origin Union[str,Callable] A string or callable returning a string, that is used as an origin for deriving the data's id. Defaults to a callable, that takes the name of the function, from which store is being called as origin. ORIGIN_FROM_FUNCTION_NAME name str An optional user-defined name, that can be used for looking up data manually. None tags Dict[str,str] A dictionary of tags that can be used for grouping multiple data together. Keys and values have to be strings. None meta Dict[str, Any] Additional meta-data about this data. This can be used for arbitrary information that might be useful, e.g. information about type or format of the data, timestamps, user info etc. None value_type boxs.value_types.ValueType The value_type to use for writing this value to the storage. Defaults to None in which case a suitable value type is taken from the list of predefined values types. None run_id str The id of the run when the data was stored. None Returns: Type Description boxs.data.DataInfo Data instance that contains information about the data and allows referring to it. Source code in boxs/box.py def store ( self , value , * parents , origin = ORIGIN_FROM_FUNCTION_NAME , name = None , tags = None , meta = None , value_type = None , run_id = None , ): \"\"\" Store new data in this box. Args: value (Any): A value that should be stored. *parents (Union[boxs.data.DataInfo, boxs.data.DataRef]): Parent data refs, that this data depends on. origin (Union[str,Callable]): A string or callable returning a string, that is used as an origin for deriving the data's id. Defaults to a callable, that takes the name of the function, from which `store` is being called as origin. name (str): An optional user-defined name, that can be used for looking up data manually. tags (Dict[str,str]): A dictionary of tags that can be used for grouping multiple data together. Keys and values have to be strings. meta (Dict[str, Any]): Additional meta-data about this data. This can be used for arbitrary information that might be useful, e.g. information about type or format of the data, timestamps, user info etc. value_type (boxs.value_types.ValueType): The value_type to use for writing this value to the storage. Defaults to `None` in which case a suitable value type is taken from the list of predefined values types. run_id (str): The id of the run when the data was stored. Returns: boxs.data.DataInfo: Data instance that contains information about the data and allows referring to it. \"\"\" if tags is None : tags = {} if meta is None : meta = {} else : meta = dict ( meta ) origin = determine_origin ( origin , name = name , tags = tags , level = 3 ) logger . info ( \"Storing value in box %s with origin %s \" , self . box_id , origin ) parent_ids = tuple ( p . data_id for p in parents ) data_id = calculate_data_id ( origin , parent_ids = parent_ids , name = name ) logger . debug ( \"Calculate data_id %s from origin %s with parents %s \" , data_id , origin , parent_ids , ) if run_id is None : run_id = get_run_id () ref = DataRef ( self . box_id , data_id , run_id ) writer = self . storage . create_writer ( ref , name , tags ) logger . debug ( \"Created writer %s for data %s \" , writer , ref ) writer = self . _apply_transformers_to_writer ( writer ) if value_type is None : value_type = self . _find_suitable_value_type ( value ) if value_type is None : raise MissingValueType ( value ) logger . debug ( \"Write value for data %s with value type %s \" , ref . uri , value_type . get_specification (), ) writer . write_value ( value , value_type ) meta [ 'value_type' ] = value_type . get_specification () meta = dict ( meta ) meta . update ( writer . meta ) data_info = DataInfo ( DataRef . from_item ( writer . item ), origin = origin , parents = parents , name = name , tags = tags , meta = meta , ) logger . debug ( \"Write info for data %s \" , ref . uri ) writer . write_info ( data_info . value_info ()) return data_info calculate_data_id ( origin , parent_ids = (), name = None ) \ud83d\udd17 Derive a data_id from origin and parent_ids Parameters: Name Type Description Default origin str The origin of the data. required parent_ids tuple[str] A tuple of data_ids of \"parent\" data, that this data is derived from. () Returns: Type Description str The data_id. Source code in boxs/box.py def calculate_data_id ( origin , parent_ids = tuple (), name = None ): \"\"\" Derive a data_id from origin and parent_ids Args: origin (str): The origin of the data. parent_ids (tuple[str]): A tuple of data_ids of \"parent\" data, that this data is derived from. Returns: str: The data_id. \"\"\" id_origin_data = ':' . join ( [ origin , name or '' , ] + sorted ( parent_ids ) ) return hashlib . blake2b ( id_origin_data . encode ( 'utf-8' ), digest_size = 8 ) . hexdigest () box_registry \ud83d\udd17 Registry of boxes get_box ( box_id = None ) \ud83d\udd17 Return the box with the given box_id. Parameters: Name Type Description Default box_id Optional[str] The id of the box that should be returned. Defaults to None in which case the default box is taken from the config and returned. None Returns: Type Description boxs.box.Box The box with the given box_id . Exceptions: Type Description boxs.errors.BoxNotDefined If no box with the given id is defined. Source code in boxs/box_registry.py def get_box ( box_id = None ): \"\"\" Return the box with the given box_id. Args: box_id (Optional[str]): The id of the box that should be returned. Defaults to `None` in which case the default box is taken from the config and returned. Returns: boxs.box.Box: The box with the given `box_id`. Raises: boxs.errors.BoxNotDefined: If no box with the given id is defined. \"\"\" logger . debug ( \"Getting box %s \" , box_id ) if box_id is None : box_id = get_config () . default_box logger . debug ( \"Using default_box %s from config\" , box_id ) if box_id not in _BOX_REGISTRY : raise BoxNotDefined ( box_id ) return _BOX_REGISTRY [ box_id ] register_box ( box ) \ud83d\udd17 Registers a new box. Parameters: Name Type Description Default box boxs.box.Box The box that should be registered. required Exceptions: Type Description boxs.errors.BoxAlreadyDefined If a box with the same id is already registered. Source code in boxs/box_registry.py def register_box ( box ): \"\"\" Registers a new box. Args: box (boxs.box.Box): The box that should be registered. Raises: boxs.errors.BoxAlreadyDefined: If a box with the same id is already registered. \"\"\" box_id = box . box_id logger . info ( \"Registering box %s \" , box_id ) if box_id in _BOX_REGISTRY : raise BoxAlreadyDefined ( box_id ) _BOX_REGISTRY [ box . box_id ] = box unregister_box ( box_id ) \ud83d\udd17 Unregisters the box with the given box_id. Parameters: Name Type Description Default box_id str The id of the box that should be removed. required Exceptions: Type Description boxs.errors.BoxNotDefined If no box with the given id is defined. Source code in boxs/box_registry.py def unregister_box ( box_id ): \"\"\" Unregisters the box with the given box_id. Args: box_id (str): The id of the box that should be removed. Raises: boxs.errors.BoxNotDefined: If no box with the given id is defined. \"\"\" logger . info ( \"Unregistering box %s \" , box_id ) if box_id not in _BOX_REGISTRY : raise BoxNotDefined ( box_id ) del _BOX_REGISTRY [ box_id ] checksum \ud83d\udd17 Checksum data to detect errors ChecksumTransformer ( Transformer ) \ud83d\udd17 Transformer that calculates and verifies the checksums of data. The transformer adds three values to the data's meta data: - 'checksum_digest': The hex-string representation of the checksum. - 'checksum_digest_size': The size in bytes of the checksum (not its representation). - 'checksum_algorithm': The hashing algorithm which is used for calculating the checksum. Currently, only 'blake2b' is supported. Source code in boxs/checksum.py class ChecksumTransformer ( Transformer ): \"\"\" Transformer that calculates and verifies the checksums of data. The transformer adds three values to the data's meta data: - 'checksum_digest': The hex-string representation of the checksum. - 'checksum_digest_size': The size in bytes of the checksum (not its representation). - 'checksum_algorithm': The hashing algorithm which is used for calculating the checksum. Currently, only 'blake2b' is supported. \"\"\" def __init__ ( self , digest_size = 32 ): \"\"\" Create a new ChecksumTransformer. Args: digest_size (int): Length of the checksum in bytes. Defaults to `32`. Since a checksum is represented as a hex-string, where a single byte is represented by two characters, the length of the resulting checksum string will be twice of the `digest_size`. \"\"\" self . digest_size = digest_size def transform_reader ( self , reader ): return _ChecksumReader ( reader , default_digest_size = self . digest_size ) def transform_writer ( self , writer ): return _ChecksumWriter ( writer , digest_size = self . digest_size ) __init__ ( self , digest_size = 32 ) special \ud83d\udd17 Create a new ChecksumTransformer. Parameters: Name Type Description Default digest_size int Length of the checksum in bytes. Defaults to 32 . Since a checksum is represented as a hex-string, where a single byte is represented by two characters, the length of the resulting checksum string will be twice of the digest_size . 32 Source code in boxs/checksum.py def __init__ ( self , digest_size = 32 ): \"\"\" Create a new ChecksumTransformer. Args: digest_size (int): Length of the checksum in bytes. Defaults to `32`. Since a checksum is represented as a hex-string, where a single byte is represented by two characters, the length of the resulting checksum string will be twice of the `digest_size`. \"\"\" self . digest_size = digest_size transform_reader ( self , reader ) \ud83d\udd17 Transform a given reader. Parameters: Name Type Description Default reader boxs.storage.Reader Reader object that is used for reading data content and meta-data. required Returns: Type Description boxs.storage.Reader A modified reader that will be used instead. Source code in boxs/checksum.py def transform_reader ( self , reader ): return _ChecksumReader ( reader , default_digest_size = self . digest_size ) transform_writer ( self , writer ) \ud83d\udd17 Transform a given writer. Parameters: Name Type Description Default writer boxs.storage.Writer Writer object that is used for writing new data content and meta-data. required Returns: Type Description boxs.storage.Writer A modified writer that will be used instead. Source code in boxs/checksum.py def transform_writer ( self , writer ): return _ChecksumWriter ( writer , digest_size = self . digest_size ) DataChecksumMismatch ( DataError ) \ud83d\udd17 Exception that is raised if a checksum doesn't match. Attributes: Name Type Description item boxs.storage.Item The item where the mismatch occurred. expected str Checksum that was expected. calculated str Checksum that was actually calculated. Source code in boxs/checksum.py class DataChecksumMismatch ( DataError ): \"\"\" Exception that is raised if a checksum doesn't match. Attributes: item (boxs.storage.Item): The item where the mismatch occurred. expected (str): Checksum that was expected. calculated (str): Checksum that was actually calculated. \"\"\" def __init__ ( self , item , expected , calculated ): self . item = item self . expected = expected self . calculated = calculated super () . __init__ ( f \" { self . item } has wrong checksum ' { self . calculated } '\" f \", expected ' { self . expected } '\" ) cli \ud83d\udd17 Command line interface clean_runs_command ( args ) \ud83d\udd17 Function that removes old runs. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def clean_runs_command ( args ): \"\"\" Function that removes old runs. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" box = get_box () storage = box . storage logger . info ( \"Removing runs in box %s \" , box . box_id ) runs = storage . list_runs ( box . box_id ) runs_to_keep = set ( runs [: args . count ]) if not args . remove_named : _keep_runs_with_name ( runs , runs_to_keep ) if not args . ignore_dependencies : _keep_runs_that_are_dependencies ( runs_to_keep , storage ) runs_to_delete = [ run for run in runs if run not in runs_to_keep ] _print_result ( \"Delete runs\" , runs_to_delete , args ) if runs_to_delete : if not args . quiet : if not _confirm ( \"Really delete all listed runs? (y/N)\" ): return for run in runs_to_delete : box . storage . delete_run ( run . box_id , run . run_id ) delete_run_command ( args ) \ud83d\udd17 Command that allows to delete a specific run. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def delete_run_command ( args ): \"\"\" Command that allows to delete a specific run. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" box = get_box () storage = box . storage run = _get_run_from_args ( args ) if run is None : return logger . info ( \"Deleting run %s in box %s \" , run . run_id , box . box_id , ) if not args . quiet : if not _confirm ( f \"Really delete the run { run . run_id } ? There might be other \" f \"runs referencing data from it. (y/N)\" ): return storage . delete_run ( box . box_id , run . run_id ) _print_result ( f \"Run { run . run_id } deleted.\" , [ run ], args ) diff_command ( args ) \ud83d\udd17 Command that compares two runs or data items. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def diff_command ( args ): \"\"\" Command that compares two runs or data items. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" def _get_data_item_as_file ( ref ): return ref . load ( value_type = FileValueType ()) results = [] for obj_string in args . queries : item_query = _parse_query ( obj_string ) box = get_box ( item_query . box ) item_query . box = box . box_id results . append ( box . storage . list_items ( item_query )) if len ( results [ 0 ]) == 1 and len ( results [ 1 ]) == 1 : first_ref = DataRef . from_item ( results [ 0 ][ 0 ]) second_ref = DataRef . from_item ( results [ 1 ][ 0 ]) logger . info ( \"Showing diff between items %s and %s \" , first_ref . uri , second_ref . uri , ) first_file_path = _get_data_item_as_file ( first_ref ) first_label = args . queries [ 0 ] second_file_path = _get_data_item_as_file ( second_ref ) second_label = args . queries [ 1 ] command = [ args . diff , str ( first_file_path ), str ( second_file_path )] if args . labels : command . extend ( [ '--label' , first_label , '--label' , second_label , ] ) command . extend ( args . diff_args ) logger . info ( \"Calling diff %s \" , command ) subprocess . run ( command , stdout = sys . stdout , stderr = sys . stderr , check = False ) else : _print_error ( \"Ambiguous values to diff.\" , args ) export_command ( args ) \ud83d\udd17 Command that exports a data item to a file. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def export_command ( args ): \"\"\" Command that exports a data item to a file. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" def _export_item_as_file ( ref , file_path ): return ref . load ( value_type = FileValueType ( file_path = file_path )) item_query = _parse_query ( args . query ) box = get_box ( item_query . box ) item_query . box = box . box_id items = box . storage . list_items ( item_query ) if len ( items ) == 0 : _print_error ( f \"No item found for { args . query } .\" , args ) elif len ( items ) > 1 : _print_error ( f \"Multiple items found for { args . query } .\" , args ) _print_result ( '' , items , args ) else : ref = DataRef . from_item ( items [ 0 ]) export_file_path = pathlib . Path ( args . file ) logger . info ( \"Exporting item %s to file %s \" , ref . uri , export_file_path ) _export_item_as_file ( ref , export_file_path ) _print_result ( f \" { args . query } successfully exported to { args . file } \" , [], args ) graph_command ( args ) \ud83d\udd17 Command that creates a graph out of data items. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def graph_command ( args ): \"\"\" Command that creates a graph out of data items. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" item_query = _parse_query ( args . query ) if item_query . box is None : item_query . box = get_config () . default_box box = get_box ( item_query . box ) items = box . storage . list_items ( item_query ) refs = [ DataRef . from_item ( item ) for item in items ] if args . file == '-' : writer = sys . stdout else : writer = io . FileIO ( args . file , 'w' ) writer = codecs . getwriter ( 'utf-8' )( writer ) with writer : write_graph_of_refs ( writer , refs ) info_command ( args ) \ud83d\udd17 Command that shows the information about a data item. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def info_command ( args ): \"\"\" Command that shows the information about a data item. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" item_query = _parse_query ( args . query [ 0 ]) box = get_box ( item_query . box ) item_query . box = box . box_id items = box . storage . list_items ( item_query ) if len ( items ) == 0 : _print_error ( f \"No item found by query { args . query [ 0 ] } \" , args ) return if len ( items ) > 1 : _print_error ( f \"Multiple items found by query { args . query [ 0 ] } \" , args ) _print_result ( '' , items , args ) return item = items [ 0 ] logger . info ( \"Showing info about item %s from run %s in box %s \" , item . data_id , item . run_id , item . box_id , ) info = box . storage . create_reader ( DataRef . from_item ( item )) . info _print_result ( f \"Info { item . data_id } { item . run_id } \" , info , args ) list_command ( args ) \ud83d\udd17 Function that lists the data items of a specific run. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def list_command ( args ): \"\"\" Function that lists the data items of a specific run. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" item_query = _parse_query ( args . query [ 0 ]) logger . info ( \"Listing items by query %s \" , item_query ) box = get_box ( item_query . box ) item_query . box = box . box_id items = box . storage . list_items ( item_query ) if len ( items ) == 0 : _print_error ( f \"No items found by query { args . query [ 0 ] } \" , args ) return _print_result ( f \"List items { item_query } \" , items , args ) list_runs_command ( args ) \ud83d\udd17 Function that lists runs. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def list_runs_command ( args ): \"\"\" Function that lists runs. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" box = get_box () storage = box . storage logger . info ( \"Listing all runs in box %s \" , box . box_id ) runs = storage . list_runs ( box . box_id , name_filter = args . filter , limit = args . limit ) _print_result ( \"List runs\" , runs , args ) main ( argv = None ) \ud83d\udd17 main() method of our command line interface. Parameters: Name Type Description Default argv List[str] Command line arguments given to the function. If None , the arguments are taken from sys.argv . None Source code in boxs/cli.py def main ( argv = None ): \"\"\" main() method of our command line interface. Args: argv (List[str]): Command line arguments given to the function. If `None`, the arguments are taken from `sys.argv`. \"\"\" argv = argv or sys . argv [ 1 :] boxs_home_dir = pathlib . Path . home () / '.boxs' boxs_home_dir . mkdir ( exist_ok = True ) file_handler = logging . FileHandler ( boxs_home_dir / 'cli.log' ) file_handler . level = logging . DEBUG file_handler . setFormatter ( logging . Formatter ( fmt = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) ) logging . basicConfig ( level = logging . DEBUG , handlers = [ file_handler ], ) logger . debug ( \"Command line arguments: %s \" , argv ) parser = argparse . ArgumentParser ( prog = 'boxs' , description = \"Allows to inspect and manipulate boxes that are used for \" \"storing data items using the python 'boxs' library.\" , ) parser . set_defaults ( command = lambda _ : parser . print_help ()) parser . add_argument ( '-b' , '--default-box' , metavar = 'BOX' , dest = 'default_box' , help = \"The id of the default box to use. If not set, the default is taken \" \"from the BOXS_DEFAULT_BOX environment variable.\" , ) parser . add_argument ( '-i' , '--init-module' , dest = 'init_module' , help = \"A python module that should be automatically loaded. If not set, the \" \"default is taken from the BOXS_INIT_MODULE environment variable.\" , ) parser . add_argument ( '-j' , '--json' , dest = 'json' , action = 'store_true' , help = \"Print output as json\" , ) subparsers = parser . add_subparsers ( help = \"Commands\" ) _add_list_runs_command ( subparsers ) _add_name_run_command ( subparsers ) _add_delete_run_command ( subparsers ) _add_clean_runs_command ( subparsers ) _add_list_command ( subparsers ) _add_info_command ( subparsers ) _add_diff_command ( subparsers ) _add_export_command ( subparsers ) _add_graph_command ( subparsers ) args = parser . parse_args ( argv ) config = get_config () if args . default_box : config . default_box = args . default_box if args . init_module : config . init_module = args . init_module try : args . command ( args ) except BoxsError as error : _print_error ( error , args ) name_run_command ( args ) \ud83d\udd17 Command that allows to set a name for a specific run. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def name_run_command ( args ): \"\"\" Command that allows to set a name for a specific run. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" box = get_box () storage = box . storage run = _get_run_from_args ( args ) if run is None : return logger . info ( \"Setting name of run %s in box %s to %s \" , run . run_id , box . box_id , args . name , ) run = storage . set_run_name ( box . box_id , run . run_id , args . name ) _print_result ( f \"Run name set { run . run_id } \" , [ run ], args ) config \ud83d\udd17 Configuration for Boxs Configuration \ud83d\udd17 Class that contains the individual config values. Attributes: Name Type Description default_box str The id of a box that should be used, no other box id is specified. Will be initialized from the BOXS_DEFAULT_BOX environment variable if defined, otherwise is initialized to None . init_module str The name of a python module, that should be automatically loaded at initialization time. Ideally, the loading of this module should trigger the definition of all boxes that are used, so that they can be found if needed. Setting this to a new module name will lead to an import of the module. Will be initialized from the BOXS_INIT_MODULE environment variable if defined, otherwise is initialized to None . Source code in boxs/config.py class Configuration : \"\"\" Class that contains the individual config values. Attributes: default_box (str): The id of a box that should be used, no other box id is specified. Will be initialized from the `BOXS_DEFAULT_BOX` environment variable if defined, otherwise is initialized to `None`. init_module (str): The name of a python module, that should be automatically loaded at initialization time. Ideally, the loading of this module should trigger the definition of all boxes that are used, so that they can be found if needed. Setting this to a new module name will lead to an import of the module. Will be initialized from the `BOXS_INIT_MODULE` environment variable if defined, otherwise is initialized to `None`. \"\"\" def __init__ ( self ): self . _initialized = False self . default_box = os . environ . get ( 'BOXS_DEFAULT_BOX' , None ) logger . info ( \"Setting default_box to %s \" , self . default_box ) self . init_module = os . environ . get ( 'BOXS_INIT_MODULE' , None ) logger . info ( \"Setting init_module to %s \" , self . init_module ) @property def default_box ( self ): \"\"\" Returns the id of the default box. Returns: str: The id of the id of the default box. \"\"\" return self . _default_box @default_box . setter def default_box ( self , default_box ): \"\"\" Set the id of the default box. Args: default_box (str): The ix of the box that should be used if no box is specified. \"\"\" self . _default_box = default_box @property def init_module ( self ): \"\"\" Returns the name of the init_module that is used in this configuration. Returns: str: The name of the init_module that is used. \"\"\" return self . _init_module @init_module . setter def init_module ( self , init_module ): \"\"\" Set the name of the init_module. Setting this value might lead to the module being imported, if boxs is properly initialized. Args: init_module (str): The name of the module to use for initialization. \"\"\" self . _init_module = init_module self . _load_init_module () @property def initialized ( self ): \"\"\" Returns if boxs is completely initialized. Returns: bool: `True` if the boxs library is initialized, otherwise `False`. \"\"\" return self . _initialized @initialized . setter def initialized ( self , initialized ): \"\"\" Set the initialization status of boxs. Setting this value to `True` might lead to the init_module being imported, if `init_module` is set. Args: initialized (bool): If the library is fully initialized. \"\"\" if self . _initialized and not initialized : self . _initialized = False if not self . _initialized and initialized : self . _initialized = True self . _load_init_module () def _load_init_module ( self ): if self . init_module is not None and self . initialized : logger . info ( \"Import init_module %s \" , self . init_module ) try : importlib . import_module ( self . init_module ) except ImportError as import_error : self . initialized = False raise import_error default_box property writable \ud83d\udd17 Returns the id of the default box. Returns: Type Description str The id of the id of the default box. init_module property writable \ud83d\udd17 Returns the name of the init_module that is used in this configuration. Returns: Type Description str The name of the init_module that is used. initialized property writable \ud83d\udd17 Returns if boxs is completely initialized. Returns: Type Description bool True if the boxs library is initialized, otherwise False . get_config () \ud83d\udd17 Returns the configuration. Returns: Type Description boxs.config.Configuration The configuration. Source code in boxs/config.py def get_config (): \"\"\" Returns the configuration. Returns: boxs.config.Configuration: The configuration. \"\"\" global _CONFIG # pylint: disable=global-statement if _CONFIG is None : logger . info ( \"Create new configuration\" ) _CONFIG = Configuration () _CONFIG . initialized = True return _CONFIG data \ud83d\udd17 Classes representing data items and references DataInfo \ud83d\udd17 Class representing a stored data item. Attributes: Name Type Description ref boxs.data.DataRef Reference to this item. origin str The origin of the data. parents Tuple[boxs.data.DataItem] A tuple containing other data items from which this item was derived. name Optional[str] A string that can be used to refer to this item by an user. Defaults to None . tags Dict[str,str] A dictionary containing string keys and values, that can be used for grouping multiple items together. Defaults to an empty dict. meta Dict[str,Any] A dictionary containing meta-data. This meta-data can have arbitrary values as long as they can be serialized to JSON. Defaults to an empty dict. Source code in boxs/data.py class DataInfo : \"\"\" Class representing a stored data item. Attributes: ref (boxs.data.DataRef): Reference to this item. origin (str): The origin of the data. parents (Tuple[boxs.data.DataItem]): A tuple containing other data items from which this item was derived. name (Optional[str]): A string that can be used to refer to this item by an user. Defaults to `None`. tags (Dict[str,str]): A dictionary containing string keys and values, that can be used for grouping multiple items together. Defaults to an empty dict. meta (Dict[str,Any]): A dictionary containing meta-data. This meta-data can have arbitrary values as long as they can be serialized to JSON. Defaults to an empty dict. \"\"\" __slots__ = [ 'ref' , 'origin' , 'name' , 'parents' , 'tags' , 'meta' , ] def __init__ ( self , ref , origin , parents = tuple (), name = None , tags = None , meta = None , ): # pylint: disable=too-many-arguments self . ref = ref self . origin = origin self . parents = parents self . name = name self . tags = tags or {} self . meta = meta or {} @property def data_id ( self ): \"\"\"Returns the data_id.\"\"\" return self . ref . data_id @property def box_id ( self ): \"\"\"Returns the box_id.\"\"\" return self . ref . box_id @property def run_id ( self ): \"\"\"Returns the run_id.\"\"\" return self . ref . run_id @property def uri ( self ): \"\"\"Returns the uri.\"\"\" return self . ref . uri @property def info ( self ): \"\"\"Returns the info. This is to be compatible with DataRef\"\"\" return self def load ( self , value_type = None ): \"\"\" Load the content of the data item. Args: value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in the referenced box. \"\"\" return load ( self , value_type = value_type ) def value_info ( self ): \"\"\" Returns information about this data item. Returns: Dict[str,str]: A dict containing information about this reference. \"\"\" value_info = { 'ref' : self . ref . value_info (), 'origin' : self . origin , 'name' : self . name , 'tags' : self . tags , 'parents' : [ parent . value_info () for parent in self . parents ], 'meta' : self . meta , } return value_info @classmethod def from_value_info ( cls , value_info ): \"\"\" Recreate a DataInfo from its value_info. Args: value_info (Dict[str,str]): A dictionary containing the info. Returns: boxs.data.DataInfo: The information about the data item. Raises: KeyError: If necessary attributes are missing from the `value_info`. \"\"\" if 'ref' not in value_info : return DataRef . from_value_info ( value_info ) data_ref = DataRef . from_value_info ( value_info [ 'ref' ]) origin = value_info [ 'origin' ] name = value_info [ 'name' ] tags = value_info [ 'tags' ] meta = value_info [ 'meta' ] parents = tuple ( DataInfo . from_value_info ( parent_info ) for parent_info in value_info [ 'parents' ] ) return DataInfo ( data_ref , origin , parents , name = name , tags = tags , meta = meta , ) def __str__ ( self ): return self . uri box_id property readonly \ud83d\udd17 Returns the box_id. data_id property readonly \ud83d\udd17 Returns the data_id. info property readonly \ud83d\udd17 Returns the info. This is to be compatible with DataRef run_id property readonly \ud83d\udd17 Returns the run_id. uri property readonly \ud83d\udd17 Returns the uri. from_value_info ( value_info ) classmethod \ud83d\udd17 Recreate a DataInfo from its value_info. Parameters: Name Type Description Default value_info Dict[str,str] A dictionary containing the info. required Returns: Type Description boxs.data.DataInfo The information about the data item. Exceptions: Type Description KeyError If necessary attributes are missing from the value_info . Source code in boxs/data.py @classmethod def from_value_info ( cls , value_info ): \"\"\" Recreate a DataInfo from its value_info. Args: value_info (Dict[str,str]): A dictionary containing the info. Returns: boxs.data.DataInfo: The information about the data item. Raises: KeyError: If necessary attributes are missing from the `value_info`. \"\"\" if 'ref' not in value_info : return DataRef . from_value_info ( value_info ) data_ref = DataRef . from_value_info ( value_info [ 'ref' ]) origin = value_info [ 'origin' ] name = value_info [ 'name' ] tags = value_info [ 'tags' ] meta = value_info [ 'meta' ] parents = tuple ( DataInfo . from_value_info ( parent_info ) for parent_info in value_info [ 'parents' ] ) return DataInfo ( data_ref , origin , parents , name = name , tags = tags , meta = meta , ) load ( self , value_type = None ) \ud83d\udd17 Load the content of the data item. Parameters: Name Type Description Default value_type boxs.value_types.ValueType The value type to use when loading the data. Defaults to None , in which case the same value type will be used that was used when the data was initially stored. None Returns: Type Description Any The loaded data. Exceptions: Type Description boxs.errors.BoxNotDefined If the data is stored in an unknown box. boxs.errors.DataNotFound If no data with the specific ids are stored in the referenced box. Source code in boxs/data.py def load ( self , value_type = None ): \"\"\" Load the content of the data item. Args: value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in the referenced box. \"\"\" return load ( self , value_type = value_type ) value_info ( self ) \ud83d\udd17 Returns information about this data item. Returns: Type Description Dict[str,str] A dict containing information about this reference. Source code in boxs/data.py def value_info ( self ): \"\"\" Returns information about this data item. Returns: Dict[str,str]: A dict containing information about this reference. \"\"\" value_info = { 'ref' : self . ref . value_info (), 'origin' : self . origin , 'name' : self . name , 'tags' : self . tags , 'parents' : [ parent . value_info () for parent in self . parents ], 'meta' : self . meta , } return value_info DataRef \ud83d\udd17 Reference to a DataInfo. Source code in boxs/data.py class DataRef : \"\"\" Reference to a DataInfo. \"\"\" __slots__ = [ 'box_id' , 'data_id' , 'run_id' , '_info' , ] def __init__ ( self , box_id , data_id , run_id ): self . box_id = box_id self . data_id = data_id self . run_id = run_id self . _info = None def value_info ( self ): \"\"\" Returns information about this reference. Returns: Dict[str,str]: A dict containing information about this reference. \"\"\" value_info = { 'box_id' : self . box_id , 'data_id' : self . data_id , 'run_id' : self . run_id , } return value_info @classmethod def from_value_info ( cls , value_info ): \"\"\" Recreate a DataRef from its value_info. Args: value_info (Dict[str,str]): A dictionary containing the ids. Returns: boxs.data.DataRef: The DataRef referencing the data. Raises: KeyError: If necessary attributes are missing from the `value_info`. \"\"\" box_id = value_info [ 'box_id' ] data_id = value_info [ 'data_id' ] run_id = value_info [ 'run_id' ] data = DataRef ( box_id , data_id , run_id ) return data @property def uri ( self ): \"\"\"Return the URI of the data item referenced.\"\"\" return f 'boxs:// { self . box_id } / { self . data_id } / { self . run_id } ' @classmethod def from_uri ( cls , uri ): \"\"\" Recreate a DataRef from a URI. Args: uri (str): URI in the format 'box://<box-id>/<data-id>/<run-id>'. Returns: DataRef: The DataRef referencing the data. Raises: ValueError: If the URI doesn't follow the expected format. \"\"\" url_parts = urllib . parse . urlparse ( uri ) if url_parts . scheme != 'boxs' : raise ValueError ( \"Invalid scheme\" ) box_id = url_parts . hostname data_id , run_id = url_parts . path [ 1 :] . split ( '/' , 1 ) data = DataRef ( box_id , data_id , run_id ) return data @classmethod def from_item ( cls , item ): \"\"\" Recreate a DataRef from an Item. Args: item (boxs.storage.Item): The item which describes the data we want to refer to. Returns: DataRef: The DataRef referencing the data. \"\"\" return DataRef ( item . box_id , item . data_id , item . run_id ) @property def info ( self ): \"\"\" Returns the info object describing the referenced data item. Returns: boxs.data.DataInfo: The info about the data item referenced. \"\"\" if self . _info is None : self . _info = info ( self ) return self . _info def load ( self , value_type = None ): \"\"\" Load the content of the data item. Args: value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in the referenced box. \"\"\" return self . info . load ( value_type = value_type ) def __eq__ ( self , other ): if not isinstance ( other , type ( self )): return False return ( self . box_id == other . box_id and self . data_id == other . data_id and self . run_id == other . run_id ) def __hash__ ( self ): return hash (( self . box_id , self . data_id , self . run_id )) def __str__ ( self ): return self . uri info property readonly \ud83d\udd17 Returns the info object describing the referenced data item. Returns: Type Description boxs.data.DataInfo The info about the data item referenced. uri property readonly \ud83d\udd17 Return the URI of the data item referenced. from_item ( item ) classmethod \ud83d\udd17 Recreate a DataRef from an Item. Parameters: Name Type Description Default item boxs.storage.Item The item which describes the data we want to refer to. required Returns: Type Description DataRef The DataRef referencing the data. Source code in boxs/data.py @classmethod def from_item ( cls , item ): \"\"\" Recreate a DataRef from an Item. Args: item (boxs.storage.Item): The item which describes the data we want to refer to. Returns: DataRef: The DataRef referencing the data. \"\"\" return DataRef ( item . box_id , item . data_id , item . run_id ) from_uri ( uri ) classmethod \ud83d\udd17 Recreate a DataRef from a URI. Parameters: Name Type Description Default uri str URI in the format 'box:// / / '. required Returns: Type Description DataRef The DataRef referencing the data. Exceptions: Type Description ValueError If the URI doesn't follow the expected format. Source code in boxs/data.py @classmethod def from_uri ( cls , uri ): \"\"\" Recreate a DataRef from a URI. Args: uri (str): URI in the format 'box://<box-id>/<data-id>/<run-id>'. Returns: DataRef: The DataRef referencing the data. Raises: ValueError: If the URI doesn't follow the expected format. \"\"\" url_parts = urllib . parse . urlparse ( uri ) if url_parts . scheme != 'boxs' : raise ValueError ( \"Invalid scheme\" ) box_id = url_parts . hostname data_id , run_id = url_parts . path [ 1 :] . split ( '/' , 1 ) data = DataRef ( box_id , data_id , run_id ) return data from_value_info ( value_info ) classmethod \ud83d\udd17 Recreate a DataRef from its value_info. Parameters: Name Type Description Default value_info Dict[str,str] A dictionary containing the ids. required Returns: Type Description boxs.data.DataRef The DataRef referencing the data. Exceptions: Type Description KeyError If necessary attributes are missing from the value_info . Source code in boxs/data.py @classmethod def from_value_info ( cls , value_info ): \"\"\" Recreate a DataRef from its value_info. Args: value_info (Dict[str,str]): A dictionary containing the ids. Returns: boxs.data.DataRef: The DataRef referencing the data. Raises: KeyError: If necessary attributes are missing from the `value_info`. \"\"\" box_id = value_info [ 'box_id' ] data_id = value_info [ 'data_id' ] run_id = value_info [ 'run_id' ] data = DataRef ( box_id , data_id , run_id ) return data load ( self , value_type = None ) \ud83d\udd17 Load the content of the data item. Parameters: Name Type Description Default value_type boxs.value_types.ValueType The value type to use when loading the data. Defaults to None , in which case the same value type will be used that was used when the data was initially stored. None Returns: Type Description Any The loaded data. Exceptions: Type Description boxs.errors.BoxNotDefined If the data is stored in an unknown box. boxs.errors.DataNotFound If no data with the specific ids are stored in the referenced box. Source code in boxs/data.py def load ( self , value_type = None ): \"\"\" Load the content of the data item. Args: value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in the referenced box. \"\"\" return self . info . load ( value_type = value_type ) value_info ( self ) \ud83d\udd17 Returns information about this reference. Returns: Type Description Dict[str,str] A dict containing information about this reference. Source code in boxs/data.py def value_info ( self ): \"\"\" Returns information about this reference. Returns: Dict[str,str]: A dict containing information about this reference. \"\"\" value_info = { 'box_id' : self . box_id , 'data_id' : self . data_id , 'run_id' : self . run_id , } return value_info errors \ud83d\udd17 Errors in boxs BoxAlreadyDefined ( BoxError ) \ud83d\udd17 Error that is raised if multiple boxes are defined using the same box id. Attributes: Name Type Description box_id str The id of the box. Source code in boxs/errors.py class BoxAlreadyDefined ( BoxError ): \"\"\" Error that is raised if multiple boxes are defined using the same box id. Attributes: box_id (str): The id of the box. \"\"\" def __init__ ( self , box_id ): self . box_id = box_id super () . __init__ ( f \"Box with box id { self . box_id } already defined\" ) BoxError ( BoxsError ) \ud83d\udd17 Base class for all errors related to boxes Source code in boxs/errors.py class BoxError ( BoxsError ): \"\"\"Base class for all errors related to boxes\"\"\" BoxNotDefined ( BoxError ) \ud83d\udd17 Error that is raised if a box id refers to a non-defined box. Attributes: Name Type Description box_id str The id of the box. Source code in boxs/errors.py class BoxNotDefined ( BoxError ): \"\"\" Error that is raised if a box id refers to a non-defined box. Attributes: box_id (str): The id of the box. \"\"\" def __init__ ( self , box_id ): self . box_id = box_id super () . __init__ ( f \"Box with box id { self . box_id } not defined\" ) BoxNotFound ( BoxError ) \ud83d\udd17 Error that is raised if a box can't be found. Attributes: Name Type Description box_id str The id of the box which should contain the data item. Source code in boxs/errors.py class BoxNotFound ( BoxError ): \"\"\" Error that is raised if a box can't be found. Attributes: box_id (str): The id of the box which should contain the data item. \"\"\" def __init__ ( self , box_id ): self . box_id = box_id super () . __init__ ( f \"Box { self . box_id } does not exist in storage.\" ) BoxsError ( Exception ) \ud83d\udd17 Base class for all boxs specific errors Source code in boxs/errors.py class BoxsError ( Exception ): \"\"\"Base class for all boxs specific errors\"\"\" DataCollision ( DataError ) \ud83d\udd17 Error that is raised if a newly created data item already exists. Attributes: Name Type Description box_id str The id of the box containing the data item. data_id str The id of the data item. run_id str The id of the run when the data was created. Source code in boxs/errors.py class DataCollision ( DataError ): \"\"\" Error that is raised if a newly created data item already exists. Attributes: box_id (str): The id of the box containing the data item. data_id (str): The id of the data item. run_id (str): The id of the run when the data was created. \"\"\" def __init__ ( self , box_id , data_id , run_id ): self . box_id = box_id self . data_id = data_id self . run_id = run_id super () . __init__ ( f \"Data { self . data_id } from run { self . run_id } \" f \"already exists in box { self . box_id } \" ) DataError ( BoxsError ) \ud83d\udd17 Base class for all boxs specific errors related to data Source code in boxs/errors.py class DataError ( BoxsError ): \"\"\"Base class for all boxs specific errors related to data\"\"\" DataNotFound ( DataError ) \ud83d\udd17 Error that is raised if a data item can't be found. Attributes: Name Type Description box_id str The id of the box which should contain the data item. data_id str The id of the data item. run_id str The id of the run when the data was created. Source code in boxs/errors.py class DataNotFound ( DataError ): \"\"\" Error that is raised if a data item can't be found. Attributes: box_id (str): The id of the box which should contain the data item. data_id (str): The id of the data item. run_id (str): The id of the run when the data was created. \"\"\" def __init__ ( self , box_id , data_id , run_id ): self . box_id = box_id self . data_id = data_id self . run_id = run_id super () . __init__ ( f \"Data { self . data_id } from run { self . run_id } \" f \"does not exist in box { self . box_id } \" ) MissingValueType ( ValueTypeError ) \ud83d\udd17 Error that is raised if no ValueType can be found that supports the value. Attributes: Name Type Description box_id str The id of the box. Source code in boxs/errors.py class MissingValueType ( ValueTypeError ): \"\"\" Error that is raised if no ValueType can be found that supports the value. Attributes: box_id (str): The id of the box. \"\"\" def __init__ ( self , value ): self . value = value super () . __init__ ( f \"No value type found for ' { self . value } '.\" ) NameCollision ( DataError ) \ud83d\udd17 Error that is raised if a data item with the same name already exists. Attributes: Name Type Description box_id str The id of the box containing the data item. data_id str The id of the data item. run_id str The id of the run when the data was created. name str The name of the data item that is used twice. Source code in boxs/errors.py class NameCollision ( DataError ): \"\"\" Error that is raised if a data item with the same name already exists. Attributes: box_id (str): The id of the box containing the data item. data_id (str): The id of the data item. run_id (str): The id of the run when the data was created. name (str): The name of the data item that is used twice. \"\"\" def __init__ ( self , box_id , data_id , run_id , name ): self . box_id = box_id self . data_id = data_id self . run_id = run_id self . name = name super () . __init__ ( f \"There already exists a data item in run { self . run_id } with the \" f \"name { self . name } in box { self . box_id } \" ) RunError ( BoxsError ) \ud83d\udd17 Base class for all run specific errors Source code in boxs/errors.py class RunError ( BoxsError ): \"\"\"Base class for all run specific errors\"\"\" RunNotFound ( RunError ) \ud83d\udd17 Error that is raised if a run can't be found. Attributes: Name Type Description box_id str The id of the box which should contain the run. run_id str The id of the run. Source code in boxs/errors.py class RunNotFound ( RunError ): \"\"\" Error that is raised if a run can't be found. Attributes: box_id (str): The id of the box which should contain the run. run_id (str): The id of the run. \"\"\" def __init__ ( self , box_id , run_id ): self . box_id = box_id self . run_id = run_id super () . __init__ ( f \"Run { self . run_id } does not exist in box { self . box_id } \" ) ValueTypeError ( BoxsError ) \ud83d\udd17 Base class for all boxs specific errors related to value types Source code in boxs/errors.py class ValueTypeError ( BoxsError ): \"\"\"Base class for all boxs specific errors related to value types\"\"\" filesystem \ud83d\udd17 Store data in a local filesystem FileSystemStorage ( Storage ) \ud83d\udd17 Storage implementation that stores data items and meta-data in a directory. Source code in boxs/filesystem.py class FileSystemStorage ( Storage ): \"\"\"Storage implementation that stores data items and meta-data in a directory.\"\"\" def __init__ ( self , directory ): \"\"\" Create the storage. Args: directory (Union[str,pathlib.Path]): The path to the directory where the data will be stored. \"\"\" self . root_directory = pathlib . Path ( directory ) def _data_file_paths ( self , item ): base_path = ( self . root_directory / item . box_id / 'data' / item . data_id / item . run_id ) return base_path . with_suffix ( '.data' ), base_path . with_suffix ( '.info' ) def _run_file_path ( self , item ): return self . _runs_directory_path ( item . box_id ) / item . run_id / item . data_id def _runs_directory_path ( self , box_id ): path = self . root_directory / box_id / 'runs' path . mkdir ( parents = True , exist_ok = True ) return path def _runs_names_directory_path ( self , box_id ): path = self . _runs_directory_path ( box_id ) / '_named' path . mkdir ( parents = True , exist_ok = True ) return path def _run_directory_path ( self , box_id , run_id ): return self . _runs_directory_path ( box_id ) / run_id def _box_directory_path ( self , box_id ): return self . root_directory / box_id def list_runs ( self , box_id , limit = None , name_filter = None ): box_directory = self . _box_directory_path ( box_id ) logger . debug ( \"List runs from directory %s \" , box_directory ) if not box_directory . exists (): raise BoxNotFound ( box_id ) runs = self . _list_runs_in_box ( box_id ) runs = sorted ( runs , key = lambda x : x . time , reverse = True ) if name_filter is not None : runs = list ( filter ( lambda x : ( x . name or '' ) . startswith ( name_filter ), runs )) if limit is not None : runs = runs [: limit ] return runs def _list_runs_in_box ( self , box_id ): runs_directory = self . _runs_directory_path ( box_id ) runs = [ self . _create_run_from_run_path ( box_id , path ) for path in runs_directory . iterdir () if path . is_dir () and path != self . _runs_names_directory_path ( box_id ) ] return runs def list_items ( self , item_query ): box_id = item_query . box box_directory = self . _box_directory_path ( box_id ) if not box_directory . exists (): raise BoxNotFound ( box_id ) logger . debug ( \"List items with query %s \" , item_query ) runs = self . _list_runs_in_box ( box_id ) if item_query . run : runs = [ run for run in runs if run . run_id . startswith ( item_query . run or '' ) or ( run . name or '' ) . startswith ( item_query . run or '' ) ] runs = sorted ( runs , key = lambda x : x . time ) all_items = [] for run in runs : items = self . _get_items_in_run ( box_id , run . run_id ) items = sorted ( items , key = lambda x : x . time ) all_items . extend ( ( item for item in items if item . data_id . startswith ( item_query . data or '' ) or ( item . name or '' ) . startswith ( item_query . data or '' ) ) ) return all_items def set_run_name ( self , box_id , run_id , name ): logger . debug ( \"Set name of run %s in box %s to %s \" , run_id , box_id , name ) box_directory = self . _box_directory_path ( box_id ) if not box_directory . exists (): raise BoxNotFound ( box_id ) run_directory = self . _run_directory_path ( box_id , run_id ) if not run_directory . exists (): raise RunNotFound ( box_id , run_id ) run_path = self . _run_directory_path ( box_id , run_id ) self . _remove_name_for_run ( box_id , run_id ) if name is not None : self . _set_name_for_run_path ( box_id , name , run_path ) run = self . _create_run_from_run_path ( box_id , run_path ) return run def delete_run ( self , box_id , run_id ): run_directory = self . _run_directory_path ( box_id , run_id ) if not run_directory . exists (): raise RunNotFound ( box_id , run_id ) items = self . _get_items_in_run ( box_id , run_id ) for item in items : data_file , info_file = self . _data_file_paths ( item ) data_file . unlink () info_file . unlink () shutil . rmtree ( run_directory ) def create_writer ( self , item , name = None , tags = None ): logger . debug ( \"Create writer for %s \" , item ) tags = tags or {} data_file , info_file = self . _data_file_paths ( item ) run_file = self . _run_file_path ( item ) return _FileSystemWriter ( item , name , tags , data_file , info_file , run_file ) def create_reader ( self , item ): logger . debug ( \"Create reader for %s \" , item ) data_file , info_file = self . _data_file_paths ( item ) return _FileSystemReader ( item , data_file , info_file ) def _get_run_names ( self , box_id ): name_directory = self . _runs_names_directory_path ( box_id ) run_names = {} for named_link_file in name_directory . iterdir (): name = named_link_file . name resolved_run_dir = named_link_file . resolve () run_id = resolved_run_dir . name run_names [ run_id ] = name return run_names def _set_name_for_run_path ( self , box_id , name , run_path ): name_dir = self . _runs_names_directory_path ( box_id ) name_dir . mkdir ( exist_ok = True ) name_symlink_file = name_dir / name symlink_path = os . path . relpath ( run_path , name_dir ) name_symlink_file . symlink_to ( symlink_path ) def _remove_name_for_run ( self , box_id , run_id ): run_names = self . _get_run_names ( box_id ) if run_id in run_names : name_dir = self . _runs_names_directory_path ( box_id ) name_symlink_file = name_dir / run_names [ run_id ] name_symlink_file . unlink () def _get_items_in_run ( self , box_id , run_id ): named_items = self . _get_item_names_in_run ( box_id , run_id ) items = [ Item ( box_id , path . name , run_id , named_items . get ( path . name , '' ), datetime . datetime . fromtimestamp ( path . stat () . st_mtime , tz = datetime . timezone . utc , ), ) for path in self . _run_directory_path ( box_id , run_id ) . iterdir () if path . is_file () ] return items def _get_item_names_in_run ( self , box_id , run_id ): name_directory = self . _run_directory_path ( box_id , run_id ) / '_named' named_items = {} if name_directory . exists (): for named_link_file in name_directory . iterdir (): name = named_link_file . name resolved_info_file = named_link_file . resolve () data_id = resolved_info_file . name named_items [ data_id ] = name return named_items def _create_run_from_run_path ( self , box_id , run_path ): run_names = self . _get_run_names ( box_id ) run_id = run_path . name return Run ( box_id , run_id , run_names . get ( run_id ), datetime . datetime . fromtimestamp ( run_path . stat () . st_mtime , tz = datetime . timezone . utc , ), ) __init__ ( self , directory ) special \ud83d\udd17 Create the storage. Parameters: Name Type Description Default directory Union[str,pathlib.Path] The path to the directory where the data will be stored. required Source code in boxs/filesystem.py def __init__ ( self , directory ): \"\"\" Create the storage. Args: directory (Union[str,pathlib.Path]): The path to the directory where the data will be stored. \"\"\" self . root_directory = pathlib . Path ( directory ) create_reader ( self , item ) \ud83d\udd17 Creates a Reader instance, that allows to load existing data. Parameters: Name Type Description Default item boxs.storage.Item The item that should be read. required Returns: Type Description boxs.storage.Reader The reader that will load the data from the storage. Source code in boxs/filesystem.py def create_reader ( self , item ): logger . debug ( \"Create reader for %s \" , item ) data_file , info_file = self . _data_file_paths ( item ) return _FileSystemReader ( item , data_file , info_file ) create_writer ( self , item , name = None , tags = None ) \ud83d\udd17 Creates a Writer instance, that allows to store new data. Parameters: Name Type Description Default item boxs.storage.Item The new data item. required name str An optional name, that can be used for referring to this item within the run. Defaults to None . None tags Dict[str,str] A dictionary containing tags that can be used for grouping multiple items together. Defaults to an empty dictionary. None Returns: Type Description boxs.storage.Writer The writer that will write the data into the storage. Source code in boxs/filesystem.py def create_writer ( self , item , name = None , tags = None ): logger . debug ( \"Create writer for %s \" , item ) tags = tags or {} data_file , info_file = self . _data_file_paths ( item ) run_file = self . _run_file_path ( item ) return _FileSystemWriter ( item , name , tags , data_file , info_file , run_file ) delete_run ( self , box_id , run_id ) \ud83d\udd17 Delete all the data of the specified run. Args; box_id (str): box_id of the box in which the run is stored. run_id (str): Run id of the run which should be deleted. Source code in boxs/filesystem.py def delete_run ( self , box_id , run_id ): run_directory = self . _run_directory_path ( box_id , run_id ) if not run_directory . exists (): raise RunNotFound ( box_id , run_id ) items = self . _get_items_in_run ( box_id , run_id ) for item in items : data_file , info_file = self . _data_file_paths ( item ) data_file . unlink () info_file . unlink () shutil . rmtree ( run_directory ) list_items ( self , item_query ) \ud83d\udd17 List all items that match a given query. The item query can contain parts of box id, run id or run name and data id or data name. If a query value is not set ( == None ) it is not used as a filter criteria. Parameters: Name Type Description Default item_query boxs.storage.ItemQuery The query which defines which items should be listed. required Returns: Type Description List[box.storage.Item] The runs. Source code in boxs/filesystem.py def list_items ( self , item_query ): box_id = item_query . box box_directory = self . _box_directory_path ( box_id ) if not box_directory . exists (): raise BoxNotFound ( box_id ) logger . debug ( \"List items with query %s \" , item_query ) runs = self . _list_runs_in_box ( box_id ) if item_query . run : runs = [ run for run in runs if run . run_id . startswith ( item_query . run or '' ) or ( run . name or '' ) . startswith ( item_query . run or '' ) ] runs = sorted ( runs , key = lambda x : x . time ) all_items = [] for run in runs : items = self . _get_items_in_run ( box_id , run . run_id ) items = sorted ( items , key = lambda x : x . time ) all_items . extend ( ( item for item in items if item . data_id . startswith ( item_query . data or '' ) or ( item . name or '' ) . startswith ( item_query . data or '' ) ) ) return all_items list_runs ( self , box_id , limit = None , name_filter = None ) \ud83d\udd17 List the runs within a box stored in this storage. The runs should be returned in descending order of their start time. Parameters: Name Type Description Default box_id str box_id of the box in which to look for runs. required limit Optional[int] Limits the returned runs to maximum limit number. Defaults to None in which case all runs are returned. None name_filter Optional[str] If set, only include runs which have names that have the filter as prefix. Defaults to None in which case all runs are returned. None Returns: Type Description List[box.storage.Run] The runs. Source code in boxs/filesystem.py def list_runs ( self , box_id , limit = None , name_filter = None ): box_directory = self . _box_directory_path ( box_id ) logger . debug ( \"List runs from directory %s \" , box_directory ) if not box_directory . exists (): raise BoxNotFound ( box_id ) runs = self . _list_runs_in_box ( box_id ) runs = sorted ( runs , key = lambda x : x . time , reverse = True ) if name_filter is not None : runs = list ( filter ( lambda x : ( x . name or '' ) . startswith ( name_filter ), runs )) if limit is not None : runs = runs [: limit ] return runs set_run_name ( self , box_id , run_id , name ) \ud83d\udd17 Set the name of a run. The name can be updated and removed by providing None . Args; box_id (str): box_id of the box in which the run is stored. run_id (str): Run id of the run which should be named. name (Optional[str]): New name of the run. If None , an existing name will be removed. Returns: Type Description box.storage.Run The run with its new name. Source code in boxs/filesystem.py def set_run_name ( self , box_id , run_id , name ): logger . debug ( \"Set name of run %s in box %s to %s \" , run_id , box_id , name ) box_directory = self . _box_directory_path ( box_id ) if not box_directory . exists (): raise BoxNotFound ( box_id ) run_directory = self . _run_directory_path ( box_id , run_id ) if not run_directory . exists (): raise RunNotFound ( box_id , run_id ) run_path = self . _run_directory_path ( box_id , run_id ) self . _remove_name_for_run ( box_id , run_id ) if name is not None : self . _set_name_for_run_path ( box_id , name , run_path ) run = self . _create_run_from_run_path ( box_id , run_path ) return run graph \ud83d\udd17 Functions for creating dependency graphs write_graph_of_refs ( writer , refs ) \ud83d\udd17 Write the dependency graph in DOT format for the given refs to the writer. Parameters: Name Type Description Default writer io.TextIO A text stream, to which the graph definition will be written. required refs list[boxs.data.DataRef] A list of DataRef instances for which the dependency graph will be created. required Source code in boxs/graph.py def write_graph_of_refs ( writer , refs ): \"\"\" Write the dependency graph in DOT format for the given refs to the writer. Args: writer (io.TextIO): A text stream, to which the graph definition will be written. refs (list[boxs.data.DataRef]): A list of DataRef instances for which the dependency graph will be created. \"\"\" writer . write ( \"digraph { \\n \" ) infos_by_run = collections . defaultdict ( list ) visited = set () queue = collections . deque () queue . extend ( refs ) while queue : ref = queue . popleft () if ref . uri in visited : continue info = ref . info infos_by_run [ ref . run_id ] . append ( info ) for parent in info . parents : queue . appendleft ( parent ) visited . add ( ref . uri ) for run_id , infos in infos_by_run . items (): writer . write ( f ' subgraph \"cluster_ { run_id } \" {{\\n ' ) writer . write ( f ' label=\"Run { run_id } \"; \\n ' ) _write_nodes_for_infos ( infos , writer ) writer . write ( \" } \\n \" ) for run_id , infos in infos_by_run . items (): _write_edges_to_parents_for_infos ( infos , writer ) writer . write ( \"} \\n \" ) io \ud83d\udd17 Functions for I/O of data DelegatingStream ( RawIOBase ) \ud83d\udd17 Stream that delegates to another stream. Source code in boxs/io.py class DelegatingStream ( io . RawIOBase ): \"\"\"Stream that delegates to another stream.\"\"\" def __init__ ( self , delegate ): \"\"\" Creates a new DelegatingStream. Args: delegate (io.RawIOBase): The delegate stream. \"\"\" self . delegate = delegate super () . __init__ () def close ( self ): self . delegate . close () @property def closed ( self ): \"\"\"Property that returns if a stream is closed.\"\"\" return self . delegate . closed def flush ( self ): self . delegate . flush () def seek ( self , offset , whence = io . SEEK_SET ): return self . delegate . seek ( offset , whence ) def seekable ( self ): return self . delegate . seekable () def tell ( self ): return self . delegate . tell () def truncate ( self , size = None ): return self . delegate . truncate ( size ) def writable ( self ): return self . delegate . writable () def readinto ( self , byte_buffer ): return self . delegate . readinto ( byte_buffer ) def write ( self , byte_buffer ): return self . delegate . write ( byte_buffer ) closed property readonly \ud83d\udd17 Property that returns if a stream is closed. __init__ ( self , delegate ) special \ud83d\udd17 Creates a new DelegatingStream. Parameters: Name Type Description Default delegate io.RawIOBase The delegate stream. required Source code in boxs/io.py def __init__ ( self , delegate ): \"\"\" Creates a new DelegatingStream. Args: delegate (io.RawIOBase): The delegate stream. \"\"\" self . delegate = delegate super () . __init__ () close ( self ) \ud83d\udd17 Flush and close the IO object. This method has no effect if the file is already closed. Source code in boxs/io.py def close ( self ): self . delegate . close () flush ( self ) \ud83d\udd17 Flush write buffers, if applicable. This is not implemented for read-only and non-blocking streams. Source code in boxs/io.py def flush ( self ): self . delegate . flush () seek ( self , offset , whence = 0 ) \ud83d\udd17 Change stream position. Change the stream position to the given byte offset. The offset is interpreted relative to the position indicated by whence. Values for whence are: 0 -- start of stream (the default); offset should be zero or positive 1 -- current stream position; offset may be negative 2 -- end of stream; offset is usually negative Return the new absolute position. Source code in boxs/io.py def seek ( self , offset , whence = io . SEEK_SET ): return self . delegate . seek ( offset , whence ) seekable ( self ) \ud83d\udd17 Return whether object supports random access. If False, seek(), tell() and truncate() will raise OSError. This method may need to do a test seek(). Source code in boxs/io.py def seekable ( self ): return self . delegate . seekable () tell ( self ) \ud83d\udd17 Return current stream position. Source code in boxs/io.py def tell ( self ): return self . delegate . tell () truncate ( self , size = None ) \ud83d\udd17 Truncate file to size bytes. File pointer is left unchanged. Size defaults to the current IO position as reported by tell(). Returns the new size. Source code in boxs/io.py def truncate ( self , size = None ): return self . delegate . truncate ( size ) writable ( self ) \ud83d\udd17 Return whether object was opened for writing. If False, write() will raise OSError. Source code in boxs/io.py def writable ( self ): return self . delegate . writable () origin \ud83d\udd17 Origins of data ORIGIN_FROM_FUNCTION_NAME \ud83d\udd17 OriginMappingFunction that uses the function_name as origin. ORIGIN_FROM_NAME \ud83d\udd17 OriginMappingFunction that uses the name as origin. ORIGIN_FROM_TAGS \ud83d\udd17 OriginMappingFunction that uses the tags in JSON format as origin. OriginMappingFunction \ud83d\udd17 A function that takes a OriginContext and returns the origin as string. Parameters: Name Type Description Default context boxs.origin.OriginContext The context from which to derive the origin. required Returns: Type Description str The origin. OriginContext \ud83d\udd17 Context from which an origin mapping function can derive the origin. Attributes: Name Type Description function_name str The name of the function that called. arg_info inspect.ArgInfo A data structure that contains the arguments of the function which called. name str The name that was given to store() . tags Dict[str,str] The tags this item will be assigned to. Source code in boxs/origin.py class OriginContext : \"\"\" Context from which an origin mapping function can derive the origin. Attributes: function_name (str): The name of the function that called. arg_info (inspect.ArgInfo): A data structure that contains the arguments of the function which called. name (str): The name that was given to `store()`. tags (Dict[str,str]): The tags this item will be assigned to. \"\"\" def __init__ ( self , name , tags , level = 2 ): frame = inspect . currentframe () for _ in range ( level ): frame = frame . f_back self . function_name = frame . f_code . co_name self . arg_info = inspect . getargvalues ( frame ) self . name = name self . tags = tags determine_origin ( origin , name = None , tags = None , level = 2 ) \ud83d\udd17 Determine an origin. If the given origin is a callable, we run it and take its return value as new origin. Parameters: Name Type Description Default origin Union[str, OriginMappingFunction, Callable[[],str]] A string or a callable that returns a string. The callable can either have no arguments or a single argument of type boxs.origin.OriginContext . required name str Name that will be available in the OriginContext if needed. None tags Dict[str,str] Tags that will be available in the context if needed. None level int The levels on the stack that we should go back. Defaults to 2 which selects the calling frame of determine_origin(). 2 Returns: Type Description str The origin as string. Source code in boxs/origin.py def determine_origin ( origin , name = None , tags = None , level = 2 ): \"\"\" Determine an origin. If the given origin is a callable, we run it and take its return value as new origin. Args: origin (Union[str, OriginMappingFunction, Callable[[],str]]): A string or a callable that returns a string. The callable can either have no arguments or a single argument of type `boxs.origin.OriginContext`. name (str): Name that will be available in the OriginContext if needed. tags (Dict[str,str]): Tags that will be available in the context if needed. level (int): The levels on the stack that we should go back. Defaults to 2 which selects the calling frame of determine_origin(). Returns: str: The origin as string. \"\"\" if callable ( origin ): if inspect . signature ( origin ) . parameters : context = OriginContext ( name , tags , level = level ) origin = origin ( context ) else : origin = origin () if origin is None : raise ValueError ( \"No origin given (is 'None').\" ) return origin pandas \ud83d\udd17 Value type definitions for pandas specific classes PandasDataFrameCsvValueType ( StringValueType ) \ud83d\udd17 A value type for storing and loading pandas DataFrame. Source code in boxs/pandas.py class PandasDataFrameCsvValueType ( StringValueType ): \"\"\" A value type for storing and loading pandas DataFrame. \"\"\" def supports ( self , value ): return isinstance ( value , pandas . DataFrame ) def write_value_to_writer ( self , value , writer ): with writer . as_stream () as stream , io . TextIOWrapper ( stream , encoding = self . _default_encoding ) as text_writer : value . to_csv ( text_writer ) writer . meta [ 'encoding' ] = self . _default_encoding def read_value_from_reader ( self , reader ): encoding = reader . meta . get ( 'encoding' , self . _default_encoding ) with reader . as_stream () as stream : text_stream = codecs . getreader ( encoding )( stream ) setattr ( text_stream , 'mode' , 'r' ) result = pandas . read_csv ( text_stream , encoding = encoding ) return result read_value_from_reader ( self , reader ) \ud83d\udd17 Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/pandas.py def read_value_from_reader ( self , reader ): encoding = reader . meta . get ( 'encoding' , self . _default_encoding ) with reader . as_stream () as stream : text_stream = codecs . getreader ( encoding )( stream ) setattr ( text_stream , 'mode' , 'r' ) result = pandas . read_csv ( text_stream , encoding = encoding ) return result supports ( self , value ) \ud83d\udd17 Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/pandas.py def supports ( self , value ): return isinstance ( value , pandas . DataFrame ) write_value_to_writer ( self , value , writer ) \ud83d\udd17 Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/pandas.py def write_value_to_writer ( self , value , writer ): with writer . as_stream () as stream , io . TextIOWrapper ( stream , encoding = self . _default_encoding ) as text_writer : value . to_csv ( text_writer ) writer . meta [ 'encoding' ] = self . _default_encoding run \ud83d\udd17 Functions for managing the run id. get_run_id () \ud83d\udd17 Returns the run id. The run id is a unique identifier that is specific to an individual run of a workflow. It stays the same across all task executions and can be used for tracking metrics and differentiating between different runs of the same workflow where task_id and run_id stay the same. Returns: Type Description str The unique run id. Source code in boxs/run.py def get_run_id (): \"\"\" Returns the run id. The run id is a unique identifier that is specific to an individual run of a workflow. It stays the same across all task executions and can be used for tracking metrics and differentiating between different runs of the same workflow where task_id and run_id stay the same. Returns: str: The unique run id. \"\"\" if _RUN_ID is None : set_run_id ( str ( uuid . uuid1 ())) return _RUN_ID set_run_id ( run_id ) \ud83d\udd17 Sets the run id. Setting the run id explicitly is usually not necessary. The function is mainly used when task executions are run in a different process to make sure the run id is consistent with the spawning process, but it can be used e.g. if an external system provides a unique identifier for a specific workflow run. When set_run_id(run_id) is being used, it must be run before the first tasks are actually defined. Exceptions: Type Description RuntimeError If the run id was already set before. Source code in boxs/run.py def set_run_id ( run_id ): \"\"\" Sets the run id. Setting the run id explicitly is usually not necessary. The function is mainly used when task executions are run in a different process to make sure the run id is consistent with the spawning process, but it can be used e.g. if an external system provides a unique identifier for a specific workflow run. When `set_run_id(run_id)` is being used, it must be run before the first tasks are actually defined. Raises: RuntimeError: If the run id was already set before. \"\"\" global _RUN_ID # pylint: disable=global-statement if _RUN_ID is not None : logger . error ( \"run_id already set to %s when trying to set again\" , _RUN_ID ) raise RuntimeError ( \"Run ID was already set\" ) logger . info ( \"Set run_id to %s \" , run_id ) _RUN_ID = run_id statistics \ud83d\udd17 Collecting statistics about data StatisticsTransformer ( Transformer ) \ud83d\udd17 Transformer that collects statistics about data items. This transformer gathers statistics like size of the data, number of lines in the data or time when it was stored and adds those as additional values in the data's meta-data. The following meta-data values are set: 'size_in_bytes' as int 'number_of_lines' as int 'store_start' Timestamp in ISO-format when the storing of the data started. 'store_end' Timestamp in ISO-format when the storing of the data finished. Source code in boxs/statistics.py class StatisticsTransformer ( Transformer ): \"\"\" Transformer that collects statistics about data items. This transformer gathers statistics like size of the data, number of lines in the data or time when it was stored and adds those as additional values in the data's meta-data. The following meta-data values are set: - 'size_in_bytes' as int - 'number_of_lines' as int - 'store_start' Timestamp in ISO-format when the storing of the data started. - 'store_end' Timestamp in ISO-format when the storing of the data finished. \"\"\" def transform_writer ( self , writer ): return _StatisticsWriter ( writer ) transform_writer ( self , writer ) \ud83d\udd17 Transform a given writer. Parameters: Name Type Description Default writer boxs.storage.Writer Writer object that is used for writing new data content and meta-data. required Returns: Type Description boxs.storage.Writer A modified writer that will be used instead. Source code in boxs/statistics.py def transform_writer ( self , writer ): return _StatisticsWriter ( writer ) storage \ud83d\udd17 Interface to backend storage Item ( Item ) \ud83d\udd17 A class representing a data item. Source code in boxs/storage.py class Item ( collections . namedtuple ( 'Item' , 'box_id data_id run_id name time' )): \"\"\" A class representing a data item. \"\"\" __slots__ = () def __str__ ( self ): return f \"Item(boxs:// { self . box_id } / { self . data_id } / { self . run_id } )\" ItemQuery \ud83d\udd17 Query object that allows to query a Storage for items. The query is build from a string with up to 3 components separated by ':'. The individual components are the : : . A query doesn't have to contain all components, but it needs to contain at least one with its trailing ':'. All components are treated as prefixes, so one doesn't have to write the full ids. Examples: Query all items in a specific run \ud83d\udd17 >>> ItemQuery ( 'my-run-id' ) # or with written separators >>> ItemQuery ( '::my-run-id' ) Query all items with the same data-id in all runs \ud83d\udd17 >>> ItemQuery ( 'my-data-id:' ) Query all items with the same data-id in specific runs with a shared prefix \ud83d\udd17 >>> ItemQuery ( 'my-data-id:my-run' ) # for multiple runs like e.g. my-run-1 and my-run-2 Query everything in a specific box: \ud83d\udd17 >>> ItemQuery ( 'box-id::' ) Attributes: Name Type Description box Optional[str] The optional box id. data Optional[str] The optional prefix for data ids or names. run Optional[str] The optional prefix for run ids or names. Source code in boxs/storage.py class ItemQuery : \"\"\" Query object that allows to query a Storage for items. The query is build from a string with up to 3 components separated by ':'. The individual components are the <box-id>:<data-id>:<run-id>. A query doesn't have to contain all components, but it needs to contain at least one with its trailing ':'. All components are treated as prefixes, so one doesn't have to write the full ids. Examples: # Query all items in a specific run >>> ItemQuery('my-run-id') # or with written separators >>> ItemQuery('::my-run-id') # Query all items with the same data-id in all runs >>> ItemQuery('my-data-id:') # Query all items with the same data-id in specific runs with a shared prefix >>> ItemQuery('my-data-id:my-run') # for multiple runs like e.g. my-run-1 and my-run-2 # Query everything in a specific box: >>> ItemQuery('box-id::') Attributes: box (Optional[str]): The optional box id. data (Optional[str]): The optional prefix for data ids or names. run (Optional[str]): The optional prefix for run ids or names. \"\"\" def __init__ ( self , string ): parts = list ( reversed ( string . strip () . rsplit ( ':' ))) self . run = parts [ 0 ] or None if len ( parts ) > 1 : self . data = parts [ 1 ] or None else : self . data = None if len ( parts ) > 2 : self . box = parts [ 2 ] or None else : self . box = None if len ( parts ) > 3 : raise ValueError ( \"Invalid query, must be in format '<box>:<data>:<run>'.\" ) if self . run is None and self . data is None and self . box is None : raise ValueError ( \"Neither, box, data or run is specified.\" ) @classmethod def from_fields ( cls , box = None , data = None , run = None ): \"\"\" Create an ItemQuery from the individual fields of the query. Args: box (Optional[str]): The search string for boxes. Defaults to `None` matching all boxes. data (Optional[str]): The search string for data items. Defaults to `None` matching all data items. run (Optional[str]): The search string for run. Defaults to `None` matching all runs. Returns: ItemQuery: The new item query with the given search fields. \"\"\" return ItemQuery ( ':' . join ([ box or '' , data or '' , run or '' ])) def __str__ ( self ): return ':' . join ([ self . box or '' , self . data or '' , self . run or '' ]) from_fields ( box = None , data = None , run = None ) classmethod \ud83d\udd17 Create an ItemQuery from the individual fields of the query. Parameters: Name Type Description Default box Optional[str] The search string for boxes. Defaults to None matching all boxes. None data Optional[str] The search string for data items. Defaults to None matching all data items. None run Optional[str] The search string for run. Defaults to None matching all runs. None Returns: Type Description ItemQuery The new item query with the given search fields. Source code in boxs/storage.py @classmethod def from_fields ( cls , box = None , data = None , run = None ): \"\"\" Create an ItemQuery from the individual fields of the query. Args: box (Optional[str]): The search string for boxes. Defaults to `None` matching all boxes. data (Optional[str]): The search string for data items. Defaults to `None` matching all data items. run (Optional[str]): The search string for run. Defaults to `None` matching all runs. Returns: ItemQuery: The new item query with the given search fields. \"\"\" return ItemQuery ( ':' . join ([ box or '' , data or '' , run or '' ])) Reader ( ABC ) \ud83d\udd17 Base class for the storage specific reader implementations. Source code in boxs/storage.py class Reader ( abc . ABC ): \"\"\" Base class for the storage specific reader implementations. \"\"\" def __init__ ( self , item ): \"\"\" Creates a `Reader` instance, that allows to load existing data. Args: item (boxs.storage.Item): The `item` with the data that should be loaded. \"\"\" self . _item = item @property def item ( self ): \"\"\"The item of the data that this reader can read.\"\"\" return self . _item def read_value ( self , value_type ): \"\"\" Read the value and return it. Args: value_type (boxs.value_types.ValueType): The value type that reads the value from the reader and converts it to the correct type. Returns: Any: The returned value from the `value_type`. \"\"\" return value_type . read_value_from_reader ( self ) @property @abc . abstractmethod def info ( self ): \"\"\"Dictionary containing information about the data.\"\"\" @property def meta ( self ): \"\"\"Dictionary containing the meta-data about the data.\"\"\" return self . info [ 'meta' ] @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream from which the data content can be read. Returns: io.RawIOBase: A stream instance from which the data can be read. \"\"\" info property readonly \ud83d\udd17 Dictionary containing information about the data. item property readonly \ud83d\udd17 The item of the data that this reader can read. meta property readonly \ud83d\udd17 Dictionary containing the meta-data about the data. __init__ ( self , item ) special \ud83d\udd17 Creates a Reader instance, that allows to load existing data. Parameters: Name Type Description Default item boxs.storage.Item The item with the data that should be loaded. required Source code in boxs/storage.py def __init__ ( self , item ): \"\"\" Creates a `Reader` instance, that allows to load existing data. Args: item (boxs.storage.Item): The `item` with the data that should be loaded. \"\"\" self . _item = item as_stream ( self ) \ud83d\udd17 Return a stream from which the data content can be read. Returns: Type Description io.RawIOBase A stream instance from which the data can be read. Source code in boxs/storage.py @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream from which the data content can be read. Returns: io.RawIOBase: A stream instance from which the data can be read. \"\"\" read_value ( self , value_type ) \ud83d\udd17 Read the value and return it. Parameters: Name Type Description Default value_type boxs.value_types.ValueType The value type that reads the value from the reader and converts it to the correct type. required Returns: Type Description Any The returned value from the value_type . Source code in boxs/storage.py def read_value ( self , value_type ): \"\"\" Read the value and return it. Args: value_type (boxs.value_types.ValueType): The value type that reads the value from the reader and converts it to the correct type. Returns: Any: The returned value from the `value_type`. \"\"\" return value_type . read_value_from_reader ( self ) Run ( Run ) \ud83d\udd17 A class representing a run. Source code in boxs/storage.py class Run ( collections . namedtuple ( 'Run' , 'box_id run_id name time' )): \"\"\" A class representing a run. \"\"\" __slots__ = () def __str__ ( self ): return f \"Run( { self . box_id } / { self . run_id } )\" def __eq__ ( self , o ): return ( self . box_id , self . run_id ) == ( o . box_id , o . run_id ) def __hash__ ( self ): return hash (( self . box_id , self . run_id )) Storage ( ABC ) \ud83d\udd17 Backend that allows a box to store and load data in arbitrary storage locations. This abstract base class defines the interface, that is used by Box to store and load data. The data items between Box and Storage are always identified by their box_id , data_id and run_id . The functionality to store data is provided by the Writer object, that is created by the create_writer() method. Similarly, loading data is implemented in a separate Reader object that is created by create_reader() . Source code in boxs/storage.py class Storage ( abc . ABC ): \"\"\" Backend that allows a box to store and load data in arbitrary storage locations. This abstract base class defines the interface, that is used by `Box` to store and load data. The data items between `Box` and `Storage` are always identified by their `box_id`, `data_id` and `run_id`. The functionality to store data is provided by the `Writer` object, that is created by the `create_writer()` method. Similarly, loading data is implemented in a separate `Reader` object that is created by `create_reader()`. \"\"\" @abc . abstractmethod def create_reader ( self , item ): \"\"\" Creates a `Reader` instance, that allows to load existing data. Args: item (boxs.storage.Item): The item that should be read. Returns: boxs.storage.Reader: The reader that will load the data from the storage. \"\"\" @abc . abstractmethod def create_writer ( self , item , name = None , tags = None ): \"\"\" Creates a `Writer` instance, that allows to store new data. Args: item (boxs.storage.Item): The new data item. name (str): An optional name, that can be used for referring to this item within the run. Defaults to `None`. tags (Dict[str,str]): A dictionary containing tags that can be used for grouping multiple items together. Defaults to an empty dictionary. Returns: boxs.storage.Writer: The writer that will write the data into the storage. \"\"\" @abc . abstractmethod def list_runs ( self , box_id , limit = None , name_filter = None ): \"\"\" List the runs within a box stored in this storage. The runs should be returned in descending order of their start time. Args: box_id (str): `box_id` of the box in which to look for runs. limit (Optional[int]): Limits the returned runs to maximum `limit` number. Defaults to `None` in which case all runs are returned. name_filter (Optional[str]): If set, only include runs which have names that have the filter as prefix. Defaults to `None` in which case all runs are returned. Returns: List[box.storage.Run]: The runs. \"\"\" @abc . abstractmethod def list_items ( self , item_query ): \"\"\" List all items that match a given query. The item query can contain parts of box id, run id or run name and data id or data name. If a query value is not set (`== None`) it is not used as a filter criteria. Args: item_query (boxs.storage.ItemQuery): The query which defines which items should be listed. Returns: List[box.storage.Item]: The runs. \"\"\" @abc . abstractmethod def set_run_name ( self , box_id , run_id , name ): \"\"\" Set the name of a run. The name can be updated and removed by providing `None`. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be named. name (Optional[str]): New name of the run. If `None`, an existing name will be removed. Returns: box.storage.Run: The run with its new name. \"\"\" @abc . abstractmethod def delete_run ( self , box_id , run_id ): \"\"\" Delete all the data of the specified run. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be deleted. \"\"\" create_reader ( self , item ) \ud83d\udd17 Creates a Reader instance, that allows to load existing data. Parameters: Name Type Description Default item boxs.storage.Item The item that should be read. required Returns: Type Description boxs.storage.Reader The reader that will load the data from the storage. Source code in boxs/storage.py @abc . abstractmethod def create_reader ( self , item ): \"\"\" Creates a `Reader` instance, that allows to load existing data. Args: item (boxs.storage.Item): The item that should be read. Returns: boxs.storage.Reader: The reader that will load the data from the storage. \"\"\" create_writer ( self , item , name = None , tags = None ) \ud83d\udd17 Creates a Writer instance, that allows to store new data. Parameters: Name Type Description Default item boxs.storage.Item The new data item. required name str An optional name, that can be used for referring to this item within the run. Defaults to None . None tags Dict[str,str] A dictionary containing tags that can be used for grouping multiple items together. Defaults to an empty dictionary. None Returns: Type Description boxs.storage.Writer The writer that will write the data into the storage. Source code in boxs/storage.py @abc . abstractmethod def create_writer ( self , item , name = None , tags = None ): \"\"\" Creates a `Writer` instance, that allows to store new data. Args: item (boxs.storage.Item): The new data item. name (str): An optional name, that can be used for referring to this item within the run. Defaults to `None`. tags (Dict[str,str]): A dictionary containing tags that can be used for grouping multiple items together. Defaults to an empty dictionary. Returns: boxs.storage.Writer: The writer that will write the data into the storage. \"\"\" delete_run ( self , box_id , run_id ) \ud83d\udd17 Delete all the data of the specified run. Args; box_id (str): box_id of the box in which the run is stored. run_id (str): Run id of the run which should be deleted. Source code in boxs/storage.py @abc . abstractmethod def delete_run ( self , box_id , run_id ): \"\"\" Delete all the data of the specified run. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be deleted. \"\"\" list_items ( self , item_query ) \ud83d\udd17 List all items that match a given query. The item query can contain parts of box id, run id or run name and data id or data name. If a query value is not set ( == None ) it is not used as a filter criteria. Parameters: Name Type Description Default item_query boxs.storage.ItemQuery The query which defines which items should be listed. required Returns: Type Description List[box.storage.Item] The runs. Source code in boxs/storage.py @abc . abstractmethod def list_items ( self , item_query ): \"\"\" List all items that match a given query. The item query can contain parts of box id, run id or run name and data id or data name. If a query value is not set (`== None`) it is not used as a filter criteria. Args: item_query (boxs.storage.ItemQuery): The query which defines which items should be listed. Returns: List[box.storage.Item]: The runs. \"\"\" list_runs ( self , box_id , limit = None , name_filter = None ) \ud83d\udd17 List the runs within a box stored in this storage. The runs should be returned in descending order of their start time. Parameters: Name Type Description Default box_id str box_id of the box in which to look for runs. required limit Optional[int] Limits the returned runs to maximum limit number. Defaults to None in which case all runs are returned. None name_filter Optional[str] If set, only include runs which have names that have the filter as prefix. Defaults to None in which case all runs are returned. None Returns: Type Description List[box.storage.Run] The runs. Source code in boxs/storage.py @abc . abstractmethod def list_runs ( self , box_id , limit = None , name_filter = None ): \"\"\" List the runs within a box stored in this storage. The runs should be returned in descending order of their start time. Args: box_id (str): `box_id` of the box in which to look for runs. limit (Optional[int]): Limits the returned runs to maximum `limit` number. Defaults to `None` in which case all runs are returned. name_filter (Optional[str]): If set, only include runs which have names that have the filter as prefix. Defaults to `None` in which case all runs are returned. Returns: List[box.storage.Run]: The runs. \"\"\" set_run_name ( self , box_id , run_id , name ) \ud83d\udd17 Set the name of a run. The name can be updated and removed by providing None . Args; box_id (str): box_id of the box in which the run is stored. run_id (str): Run id of the run which should be named. name (Optional[str]): New name of the run. If None , an existing name will be removed. Returns: Type Description box.storage.Run The run with its new name. Source code in boxs/storage.py @abc . abstractmethod def set_run_name ( self , box_id , run_id , name ): \"\"\" Set the name of a run. The name can be updated and removed by providing `None`. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be named. name (Optional[str]): New name of the run. If `None`, an existing name will be removed. Returns: box.storage.Run: The run with its new name. \"\"\" Writer ( ABC ) \ud83d\udd17 Base class for the storage specific writer implementations. Source code in boxs/storage.py class Writer ( abc . ABC ): \"\"\" Base class for the storage specific writer implementations. \"\"\" def __init__ ( self , item , name , tags ): \"\"\" Creates a `Writer` instance, that allows to store new data. Args: item (boxs.storage.Item): The new item. \"\"\" self . _item = item self . _name = name self . _tags = tags self . _meta = {} @property def item ( self ): \"\"\"Returns the item which this writer writes to.\"\"\" return self . _item @property def name ( self ): \"\"\"Returns the name of the new data item.\"\"\" return self . _name @property def tags ( self ): \"\"\"Returns the tags of the new data item.\"\"\" return self . _tags @property def meta ( self ): \"\"\" Returns a dictionary which contains meta-data of the item. This allows either ValueTypes or Transformers to add additional meta-data for the data item. \"\"\" return self . _meta def write_value ( self , value , value_type ): \"\"\" Write the data content to the storage. Args: value (Any): The value that should be written to the writer. value_type (boxs.value_types.ValueType): The value type that takes care of actually writing the value and converting it to the correct type. \"\"\" value_type . write_value_to_writer ( value , self ) @abc . abstractmethod def write_info ( self , info ): \"\"\" Write the info for the data item to the storage. Args: info (Dict[str,Any]): The information about the new data item. Raises: boxs.errors.DataCollision: If a data item with the same ids already exists. \"\"\" @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream to which the data content should be written. This method can be used by the ValueType to actually transfer the data. Returns: io.RawIOBase: The binary io-stream. Raises: boxs.errors.DataCollision: If a data item with the same ids already exists. \"\"\" item property readonly \ud83d\udd17 Returns the item which this writer writes to. meta property readonly \ud83d\udd17 Returns a dictionary which contains meta-data of the item. This allows either ValueTypes or Transformers to add additional meta-data for the data item. name property readonly \ud83d\udd17 Returns the name of the new data item. tags property readonly \ud83d\udd17 Returns the tags of the new data item. __init__ ( self , item , name , tags ) special \ud83d\udd17 Creates a Writer instance, that allows to store new data. Parameters: Name Type Description Default item boxs.storage.Item The new item. required Source code in boxs/storage.py def __init__ ( self , item , name , tags ): \"\"\" Creates a `Writer` instance, that allows to store new data. Args: item (boxs.storage.Item): The new item. \"\"\" self . _item = item self . _name = name self . _tags = tags self . _meta = {} as_stream ( self ) \ud83d\udd17 Return a stream to which the data content should be written. This method can be used by the ValueType to actually transfer the data. Returns: Type Description io.RawIOBase The binary io-stream. Exceptions: Type Description boxs.errors.DataCollision If a data item with the same ids already exists. Source code in boxs/storage.py @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream to which the data content should be written. This method can be used by the ValueType to actually transfer the data. Returns: io.RawIOBase: The binary io-stream. Raises: boxs.errors.DataCollision: If a data item with the same ids already exists. \"\"\" write_info ( self , info ) \ud83d\udd17 Write the info for the data item to the storage. Parameters: Name Type Description Default info Dict[str,Any] The information about the new data item. required Exceptions: Type Description boxs.errors.DataCollision If a data item with the same ids already exists. Source code in boxs/storage.py @abc . abstractmethod def write_info ( self , info ): \"\"\" Write the info for the data item to the storage. Args: info (Dict[str,Any]): The information about the new data item. Raises: boxs.errors.DataCollision: If a data item with the same ids already exists. \"\"\" write_value ( self , value , value_type ) \ud83d\udd17 Write the data content to the storage. Parameters: Name Type Description Default value Any The value that should be written to the writer. required value_type boxs.value_types.ValueType The value type that takes care of actually writing the value and converting it to the correct type. required Source code in boxs/storage.py def write_value ( self , value , value_type ): \"\"\" Write the data content to the storage. Args: value (Any): The value that should be written to the writer. value_type (boxs.value_types.ValueType): The value type that takes care of actually writing the value and converting it to the correct type. \"\"\" value_type . write_value_to_writer ( value , self ) tensorflow \ud83d\udd17 Value type definitions for storing tensorflow specific classes TensorBoardLogDirValueType ( DirectoryValueType ) \ud83d\udd17 Value type for storing tensorbord logs. The necessary tensorflow functions for saving and loading the model to a directory are dynamically loaded, so that the module can be imported WITHOUT tensorflow. Only if one instantiates an instance of the class, the tensorflow package must be available. Source code in boxs/tensorflow.py class TensorBoardLogDirValueType ( DirectoryValueType ): \"\"\" Value type for storing tensorbord logs. The necessary tensorflow functions for saving and loading the model to a directory are dynamically loaded, so that the module can be imported WITHOUT tensorflow. Only if one instantiates an instance of the class, the tensorflow package must be available. \"\"\" def write_value_to_writer ( self , value , writer ): super () . write_value_to_writer ( pathlib . Path ( value ), writer ) writer . meta [ 'dir_content' ] = 'tensorboard-logs' write_value_to_writer ( self , value , writer ) \ud83d\udd17 Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/tensorflow.py def write_value_to_writer ( self , value , writer ): super () . write_value_to_writer ( pathlib . Path ( value ), writer ) writer . meta [ 'dir_content' ] = 'tensorboard-logs' TensorflowKerasModelValueType ( DirectoryValueType ) \ud83d\udd17 Value type for storing tensorflow keras models. The necessary tensorflow functions for saving and loading the model to a directory are dynamically loaded, so that the module can be imported WITHOUT tensorflow. Only if one instantiates an instance of the class, the tensorflow package must be available. Source code in boxs/tensorflow.py class TensorflowKerasModelValueType ( DirectoryValueType ): \"\"\" Value type for storing tensorflow keras models. The necessary tensorflow functions for saving and loading the model to a directory are dynamically loaded, so that the module can be imported WITHOUT tensorflow. Only if one instantiates an instance of the class, the tensorflow package must be available. \"\"\" def __init__ ( self , dir_path = None , default_format = 'tf' ): self . _tf_models_module = importlib . import_module ( 'tensorflow.keras.models' ) self . _default_format = default_format super () . __init__ ( dir_path ) def supports ( self , value ): return False def write_value_to_writer ( self , value , writer ): model_dir_path = pathlib . Path ( tempfile . mkdtemp ()) try : self . _tf_models_module . save_model ( value , filepath = model_dir_path , save_format = self . _default_format ) super () . write_value_to_writer ( model_dir_path , writer ) writer . meta [ 'model_format' ] = self . _default_format finally : shutil . rmtree ( model_dir_path ) def read_value_from_reader ( self , reader ): model_dir_path = super () . read_value_from_reader ( reader ) try : result = self . _tf_models_module . load_model ( filepath = model_dir_path ) finally : if self . _dir_path is None : shutil . rmtree ( model_dir_path ) return result def _get_parameter_string ( self ): return self . _default_format @classmethod def _from_parameter_string ( cls , parameters ): return cls ( default_format = parameters ) read_value_from_reader ( self , reader ) \ud83d\udd17 Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/tensorflow.py def read_value_from_reader ( self , reader ): model_dir_path = super () . read_value_from_reader ( reader ) try : result = self . _tf_models_module . load_model ( filepath = model_dir_path ) finally : if self . _dir_path is None : shutil . rmtree ( model_dir_path ) return result supports ( self , value ) \ud83d\udd17 Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/tensorflow.py def supports ( self , value ): return False write_value_to_writer ( self , value , writer ) \ud83d\udd17 Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/tensorflow.py def write_value_to_writer ( self , value , writer ): model_dir_path = pathlib . Path ( tempfile . mkdtemp ()) try : self . _tf_models_module . save_model ( value , filepath = model_dir_path , save_format = self . _default_format ) super () . write_value_to_writer ( model_dir_path , writer ) writer . meta [ 'model_format' ] = self . _default_format finally : shutil . rmtree ( model_dir_path ) transform \ud83d\udd17 Transforming data items DelegatingReader ( Reader ) \ud83d\udd17 Reader class that delegates all calls to a wrapped reader. Source code in boxs/transform.py class DelegatingReader ( Reader ): \"\"\" Reader class that delegates all calls to a wrapped reader. \"\"\" def __init__ ( self , delegate ): \"\"\" Create a new DelegatingReader. Args: delegate (boxs.storage.Reader): The reader to which all calls are delegated. \"\"\" super () . __init__ ( delegate . item ) self . delegate = delegate @property def info ( self ): return self . delegate . info @property def meta ( self ): return self . delegate . meta def read_value ( self , value_type ): return self . delegate . read_value ( value_type ) def as_stream ( self ): return self . delegate . as_stream () info property readonly \ud83d\udd17 Dictionary containing information about the data. meta property readonly \ud83d\udd17 Dictionary containing the meta-data about the data. __init__ ( self , delegate ) special \ud83d\udd17 Create a new DelegatingReader. Parameters: Name Type Description Default delegate boxs.storage.Reader The reader to which all calls are delegated. required Source code in boxs/transform.py def __init__ ( self , delegate ): \"\"\" Create a new DelegatingReader. Args: delegate (boxs.storage.Reader): The reader to which all calls are delegated. \"\"\" super () . __init__ ( delegate . item ) self . delegate = delegate as_stream ( self ) \ud83d\udd17 Return a stream from which the data content can be read. Returns: Type Description io.RawIOBase A stream instance from which the data can be read. Source code in boxs/transform.py def as_stream ( self ): return self . delegate . as_stream () read_value ( self , value_type ) \ud83d\udd17 Read the value and return it. Parameters: Name Type Description Default value_type boxs.value_types.ValueType The value type that reads the value from the reader and converts it to the correct type. required Returns: Type Description Any The returned value from the value_type . Source code in boxs/transform.py def read_value ( self , value_type ): return self . delegate . read_value ( value_type ) DelegatingWriter ( Writer ) \ud83d\udd17 Writer that delegates all call to a wrapped writer. Source code in boxs/transform.py class DelegatingWriter ( Writer ): \"\"\" Writer that delegates all call to a wrapped writer. \"\"\" def __init__ ( self , delegate ): self . delegate = delegate super () . __init__ ( delegate . item , delegate . name , delegate . tags ) @property def meta ( self ): return self . delegate . meta def write_value ( self , value , value_type ): self . delegate . write_value ( value , value_type ) def write_info ( self , info ): return self . delegate . write_info ( info ) def as_stream ( self ): return self . delegate . as_stream () meta property readonly \ud83d\udd17 Returns a dictionary which contains meta-data of the item. This allows either ValueTypes or Transformers to add additional meta-data for the data item. as_stream ( self ) \ud83d\udd17 Return a stream to which the data content should be written. This method can be used by the ValueType to actually transfer the data. Returns: Type Description io.RawIOBase The binary io-stream. Exceptions: Type Description boxs.errors.DataCollision If a data item with the same ids already exists. Source code in boxs/transform.py def as_stream ( self ): return self . delegate . as_stream () write_info ( self , info ) \ud83d\udd17 Write the info for the data item to the storage. Parameters: Name Type Description Default info Dict[str,Any] The information about the new data item. required Exceptions: Type Description boxs.errors.DataCollision If a data item with the same ids already exists. Source code in boxs/transform.py def write_info ( self , info ): return self . delegate . write_info ( info ) write_value ( self , value , value_type ) \ud83d\udd17 Write the data content to the storage. Parameters: Name Type Description Default value Any The value that should be written to the writer. required value_type boxs.value_types.ValueType The value type that takes care of actually writing the value and converting it to the correct type. required Source code in boxs/transform.py def write_value ( self , value , value_type ): self . delegate . write_value ( value , value_type ) Transformer \ud83d\udd17 Base class for transformers Transformers allow modifying content and meta-data of a DataItem during store and load by wrapping the writer and reader that are used for accessing them from the storage. This can be useful for e.g. adding new meta-data, filtering content or implementing encryption. Source code in boxs/transform.py class Transformer : # pylint: disable=no-self-use \"\"\" Base class for transformers Transformers allow modifying content and meta-data of a DataItem during store and load by wrapping the writer and reader that are used for accessing them from the storage. This can be useful for e.g. adding new meta-data, filtering content or implementing encryption. \"\"\" def transform_writer ( self , writer ): \"\"\" Transform a given writer. Args: writer (boxs.storage.Writer): Writer object that is used for writing new data content and meta-data. Returns: boxs.storage.Writer: A modified writer that will be used instead. \"\"\" return writer def transform_reader ( self , reader ): \"\"\" Transform a given reader. Args: reader (boxs.storage.Reader): Reader object that is used for reading data content and meta-data. Returns: boxs.storage.Reader: A modified reader that will be used instead. \"\"\" return reader transform_reader ( self , reader ) \ud83d\udd17 Transform a given reader. Parameters: Name Type Description Default reader boxs.storage.Reader Reader object that is used for reading data content and meta-data. required Returns: Type Description boxs.storage.Reader A modified reader that will be used instead. Source code in boxs/transform.py def transform_reader ( self , reader ): \"\"\" Transform a given reader. Args: reader (boxs.storage.Reader): Reader object that is used for reading data content and meta-data. Returns: boxs.storage.Reader: A modified reader that will be used instead. \"\"\" return reader transform_writer ( self , writer ) \ud83d\udd17 Transform a given writer. Parameters: Name Type Description Default writer boxs.storage.Writer Writer object that is used for writing new data content and meta-data. required Returns: Type Description boxs.storage.Writer A modified writer that will be used instead. Source code in boxs/transform.py def transform_writer ( self , writer ): \"\"\" Transform a given writer. Args: writer (boxs.storage.Writer): Writer object that is used for writing new data content and meta-data. Returns: boxs.storage.Writer: A modified writer that will be used instead. \"\"\" return writer value_types \ud83d\udd17 Types for reading and writing of different value types BytesValueType ( ValueType ) \ud83d\udd17 A ValueType for reading and writing bytes/bytearray values. Source code in boxs/value_types.py class BytesValueType ( ValueType ): \"\"\" A ValueType for reading and writing bytes/bytearray values. \"\"\" def supports ( self , value ): return isinstance ( value , ( bytes , bytearray )) def write_value_to_writer ( self , value , writer ): source_stream = io . BytesIO ( value ) with writer . as_stream () as destination_stream : shutil . copyfileobj ( source_stream , destination_stream ) def read_value_from_reader ( self , reader ): with reader . as_stream () as stream : return stream . read () read_value_from_reader ( self , reader ) \ud83d\udd17 Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): with reader . as_stream () as stream : return stream . read () supports ( self , value ) \ud83d\udd17 Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , ( bytes , bytearray )) write_value_to_writer ( self , value , writer ) \ud83d\udd17 Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): source_stream = io . BytesIO ( value ) with writer . as_stream () as destination_stream : shutil . copyfileobj ( source_stream , destination_stream ) DirectoryValueType ( ValueType ) \ud83d\udd17 A ValueType for reading and writing directories. The values have to be instances of pathlib.Path and must point to an existing directory. Everything within this directory is then added to a new zip archive, that is written to the storage. Source code in boxs/value_types.py class DirectoryValueType ( ValueType ): \"\"\" A ValueType for reading and writing directories. The values have to be instances of `pathlib.Path` and must point to an existing directory. Everything within this directory is then added to a new zip archive, that is written to the storage. \"\"\" def __init__ ( self , dir_path = None ): self . _dir_path = dir_path super () . __init__ () def supports ( self , value ): return isinstance ( value , pathlib . Path ) and value . exists () and value . is_dir () def write_value_to_writer ( self , value , writer ): def _add_directory ( root , directory , _zip_file ): for path in directory . iterdir (): if path . is_file (): _zip_file . write ( path , arcname = path . relative_to ( root )) if path . is_dir (): _add_directory ( root , path , _zip_file ) with writer . as_stream () as destination_stream , zipfile . ZipFile ( destination_stream , mode = 'w' ) as zip_file : _add_directory ( value , value , zip_file ) def read_value_from_reader ( self , reader ): dir_path = self . _dir_path if self . _dir_path is None : dir_path = tempfile . mkdtemp () dir_path = pathlib . Path ( dir_path ) self . _logger . debug ( \"Directory will be stored in %s \" , dir_path ) with reader . as_stream () as read_stream , zipfile . ZipFile ( read_stream , 'r' ) as zip_file : for zip_info in zip_file . infolist (): target_path = dir_path / zip_info . filename self . _logger . debug ( \"Extracting %s to %s \" , zip_info . filename , target_path ) zip_file . extract ( zip_info , target_path ) return dir_path read_value_from_reader ( self , reader ) \ud83d\udd17 Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): dir_path = self . _dir_path if self . _dir_path is None : dir_path = tempfile . mkdtemp () dir_path = pathlib . Path ( dir_path ) self . _logger . debug ( \"Directory will be stored in %s \" , dir_path ) with reader . as_stream () as read_stream , zipfile . ZipFile ( read_stream , 'r' ) as zip_file : for zip_info in zip_file . infolist (): target_path = dir_path / zip_info . filename self . _logger . debug ( \"Extracting %s to %s \" , zip_info . filename , target_path ) zip_file . extract ( zip_info , target_path ) return dir_path supports ( self , value ) \ud83d\udd17 Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , pathlib . Path ) and value . exists () and value . is_dir () write_value_to_writer ( self , value , writer ) \ud83d\udd17 Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): def _add_directory ( root , directory , _zip_file ): for path in directory . iterdir (): if path . is_file (): _zip_file . write ( path , arcname = path . relative_to ( root )) if path . is_dir (): _add_directory ( root , path , _zip_file ) with writer . as_stream () as destination_stream , zipfile . ZipFile ( destination_stream , mode = 'w' ) as zip_file : _add_directory ( value , value , zip_file ) FileValueType ( ValueType ) \ud83d\udd17 A ValueType for reading and writing files. The values have to be instances of pathlib.Path . Source code in boxs/value_types.py class FileValueType ( ValueType ): \"\"\" A ValueType for reading and writing files. The values have to be instances of `pathlib.Path`. \"\"\" def __init__ ( self , file_path = None ): self . _file_path = file_path super () . __init__ () def supports ( self , value ): return isinstance ( value , pathlib . Path ) and value . exists () and value . is_file () def write_value_to_writer ( self , value , writer ): with value . open ( 'rb' ) as file_reader , writer . as_stream () as destination_stream : shutil . copyfileobj ( file_reader , destination_stream ) def read_value_from_reader ( self , reader ): if hasattr ( reader , 'as_file' ): self . _logger . debug ( \"Reader has as_file()\" ) if self . _file_path : self . _logger . debug ( \"Copying file directly\" ) shutil . copyfile ( str ( reader . as_file ()), str ( self . _file_path )) return self . _file_path return reader . as_file () file_path = self . _file_path if self . _file_path is None : file_path = tempfile . mktemp () file_path = pathlib . Path ( file_path ) with reader . as_stream () as read_stream , io . FileIO ( file_path , 'w' ) as file_stream : self . _logger . debug ( \"Writing file from stream\" ) shutil . copyfileobj ( read_stream , file_stream ) return file_path read_value_from_reader ( self , reader ) \ud83d\udd17 Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): if hasattr ( reader , 'as_file' ): self . _logger . debug ( \"Reader has as_file()\" ) if self . _file_path : self . _logger . debug ( \"Copying file directly\" ) shutil . copyfile ( str ( reader . as_file ()), str ( self . _file_path )) return self . _file_path return reader . as_file () file_path = self . _file_path if self . _file_path is None : file_path = tempfile . mktemp () file_path = pathlib . Path ( file_path ) with reader . as_stream () as read_stream , io . FileIO ( file_path , 'w' ) as file_stream : self . _logger . debug ( \"Writing file from stream\" ) shutil . copyfileobj ( read_stream , file_stream ) return file_path supports ( self , value ) \ud83d\udd17 Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , pathlib . Path ) and value . exists () and value . is_file () write_value_to_writer ( self , value , writer ) \ud83d\udd17 Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): with value . open ( 'rb' ) as file_reader , writer . as_stream () as destination_stream : shutil . copyfileobj ( file_reader , destination_stream ) JsonValueType ( ValueType ) \ud83d\udd17 ValueType for storing values as JSON. Source code in boxs/value_types.py class JsonValueType ( ValueType ): \"\"\" ValueType for storing values as JSON. \"\"\" def supports ( self , value ): return isinstance ( value , ( dict , list )) def write_value_to_writer ( self , value , writer ): writer . meta [ 'media_type' ] = 'application/json' with writer . as_stream () as destination_stream , io . TextIOWrapper ( destination_stream ) as text_writer : json . dump ( value , text_writer , sort_keys = True , separators = ( ',' , ':' )) def read_value_from_reader ( self , reader ): with reader . as_stream () as stream : return json . load ( stream ) read_value_from_reader ( self , reader ) \ud83d\udd17 Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): with reader . as_stream () as stream : return json . load ( stream ) supports ( self , value ) \ud83d\udd17 Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , ( dict , list )) write_value_to_writer ( self , value , writer ) \ud83d\udd17 Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): writer . meta [ 'media_type' ] = 'application/json' with writer . as_stream () as destination_stream , io . TextIOWrapper ( destination_stream ) as text_writer : json . dump ( value , text_writer , sort_keys = True , separators = ( ',' , ':' )) StreamValueType ( ValueType ) \ud83d\udd17 A ValueType for reading and writing from and to a stream. Source code in boxs/value_types.py class StreamValueType ( ValueType ): \"\"\" A ValueType for reading and writing from and to a stream. \"\"\" def supports ( self , value ): return isinstance ( value , io . IOBase ) def write_value_to_writer ( self , value , writer ): with writer . as_stream () as destination_stream : shutil . copyfileobj ( value , destination_stream ) def read_value_from_reader ( self , reader ): return reader . as_stream () read_value_from_reader ( self , reader ) \ud83d\udd17 Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): return reader . as_stream () supports ( self , value ) \ud83d\udd17 Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , io . IOBase ) write_value_to_writer ( self , value , writer ) \ud83d\udd17 Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): with writer . as_stream () as destination_stream : shutil . copyfileobj ( value , destination_stream ) StringValueType ( ValueType ) \ud83d\udd17 A ValueType for reading and writing string values. The ValueType can use different encodings via its constructor argument, but defaults to 'utf-8'. Source code in boxs/value_types.py class StringValueType ( ValueType ): \"\"\" A ValueType for reading and writing string values. The ValueType can use different encodings via its constructor argument, but defaults to 'utf-8'. \"\"\" def __init__ ( self , default_encoding = 'utf-8' ): self . _default_encoding = default_encoding super () . __init__ () def supports ( self , value ): return isinstance ( value , str ) def write_value_to_writer ( self , value , writer ): source_stream = io . BytesIO ( value . encode ( self . _default_encoding )) writer . meta [ 'encoding' ] = self . _default_encoding with writer . as_stream () as destination_stream : shutil . copyfileobj ( source_stream , destination_stream ) def read_value_from_reader ( self , reader ): encoding = reader . meta . get ( 'encoding' , self . _default_encoding ) self . _logger . debug ( \"Reading string with encoding %s \" , encoding ) with reader . as_stream () as stream , io . TextIOWrapper ( stream , encoding = encoding ) as text_reader : return text_reader . read () def _get_parameter_string ( self ): return self . _default_encoding @classmethod def _from_parameter_string ( cls , parameters ): return cls ( default_encoding = parameters ) read_value_from_reader ( self , reader ) \ud83d\udd17 Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): encoding = reader . meta . get ( 'encoding' , self . _default_encoding ) self . _logger . debug ( \"Reading string with encoding %s \" , encoding ) with reader . as_stream () as stream , io . TextIOWrapper ( stream , encoding = encoding ) as text_reader : return text_reader . read () supports ( self , value ) \ud83d\udd17 Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , str ) write_value_to_writer ( self , value , writer ) \ud83d\udd17 Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): source_stream = io . BytesIO ( value . encode ( self . _default_encoding )) writer . meta [ 'encoding' ] = self . _default_encoding with writer . as_stream () as destination_stream : shutil . copyfileobj ( source_stream , destination_stream ) ValueType ( ABC ) \ud83d\udd17 Base class for implementing the type depending reading and writing of values to and from Readers and Writers. Source code in boxs/value_types.py class ValueType ( abc . ABC ): \"\"\" Base class for implementing the type depending reading and writing of values to and from Readers and Writers. \"\"\" def __init__ ( self ): self . _logger = logging . getLogger ( str ( self . __class__ )) def supports ( self , value ): # pylint: disable=unused-argument,no-self-use \"\"\" Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Args: value (Any): The value for which the value type should be checked. Returns: bool: `True` if the value type supports this value, otherwise `False`. The default implementation just returns `False`. \"\"\" return False @abc . abstractmethod def write_value_to_writer ( self , value , writer ): \"\"\" Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Args: value (Any): The value that should be written. writer (boxs.storage.Writer): The writer into which the value should be written. \"\"\" @abc . abstractmethod def read_value_from_reader ( self , reader ): \"\"\" Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Args: reader (boxs.storage.Reader): The reader from which the value should be read. Returns: Any: The value that was read from the reader. \"\"\" def get_specification ( self ): \"\"\" Returns a string that specifies this ValueType. Returns: str: The specification that can be used for recreating this specific ValueType. \"\"\" module_name = self . __class__ . __module__ class_name = self . __class__ . __qualname__ parameter_string = self . _get_parameter_string () return ':' . join ([ module_name , class_name , parameter_string ]) @classmethod def from_specification ( cls , specification ): \"\"\" Create a new ValueType instance from its specification string. Args: specification (str): The specification string that specifies the ValueType thate should be instantiated. Returns: ValueType: The specified ValueType instance. \"\"\" logger . debug ( \"Recreating value type from specification %s \" , specification ) module_name , class_name , parameter_string = specification . split ( ':' , maxsplit = 2 ) module = importlib . import_module ( module_name ) class_ = getattr ( module , class_name ) value_type = class_ . _from_parameter_string ( # pylint: disable=protected-access parameter_string , ) return value_type def _get_parameter_string ( self ): # pylint: disable=no-self-use \"\"\" Return a string encoding the ValueType specific parameters. This method needs to be overridden by subclasses, that use parameters. Returns: str: The string containing the parameters. \"\"\" return '' @classmethod def _from_parameter_string ( cls , parameters ): # pylint: disable=unused-argument \"\"\" Return a new instance of a specific ValueType from its parameter string. This method needs to be overridden by subclasses, that use parameters. Returns: ValueType: The specified ValueType instance. \"\"\" return cls () def __repr__ ( self ): return self . get_specification () def __str__ ( self ): return self . get_specification () from_specification ( specification ) classmethod \ud83d\udd17 Create a new ValueType instance from its specification string. Parameters: Name Type Description Default specification str The specification string that specifies the ValueType thate should be instantiated. required Returns: Type Description ValueType The specified ValueType instance. Source code in boxs/value_types.py @classmethod def from_specification ( cls , specification ): \"\"\" Create a new ValueType instance from its specification string. Args: specification (str): The specification string that specifies the ValueType thate should be instantiated. Returns: ValueType: The specified ValueType instance. \"\"\" logger . debug ( \"Recreating value type from specification %s \" , specification ) module_name , class_name , parameter_string = specification . split ( ':' , maxsplit = 2 ) module = importlib . import_module ( module_name ) class_ = getattr ( module , class_name ) value_type = class_ . _from_parameter_string ( # pylint: disable=protected-access parameter_string , ) return value_type get_specification ( self ) \ud83d\udd17 Returns a string that specifies this ValueType. Returns: Type Description str The specification that can be used for recreating this specific ValueType. Source code in boxs/value_types.py def get_specification ( self ): \"\"\" Returns a string that specifies this ValueType. Returns: str: The specification that can be used for recreating this specific ValueType. \"\"\" module_name = self . __class__ . __module__ class_name = self . __class__ . __qualname__ parameter_string = self . _get_parameter_string () return ':' . join ([ module_name , class_name , parameter_string ]) read_value_from_reader ( self , reader ) \ud83d\udd17 Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py @abc . abstractmethod def read_value_from_reader ( self , reader ): \"\"\" Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Args: reader (boxs.storage.Reader): The reader from which the value should be read. Returns: Any: The value that was read from the reader. \"\"\" supports ( self , value ) \ud83d\udd17 Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): # pylint: disable=unused-argument,no-self-use \"\"\" Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Args: value (Any): The value for which the value type should be checked. Returns: bool: `True` if the value type supports this value, otherwise `False`. The default implementation just returns `False`. \"\"\" return False write_value_to_writer ( self , value , writer ) \ud83d\udd17 Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py @abc . abstractmethod def write_value_to_writer ( self , value , writer ): \"\"\" Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Args: value (Any): The value that should be written. writer (boxs.storage.Writer): The writer into which the value should be written. \"\"\"","title":"API"},{"location":"api/#boxs.api","text":"API to be used by users","title":"api"},{"location":"api/#boxs.api.info","text":"Load info from a reference to an item. Parameters: Name Type Description Default data_ref boxs.data.DataRef Data reference that points to the data whose info is requested. required Returns: Type Description boxs.data.DataInfo The info about the data. Exceptions: Type Description boxs.errors.BoxNotDefined If the data is stored in an unknown box. boxs.errors.DataNotFound If no data with the specific ids are stored in this box. Source code in boxs/api.py def info ( data_ref ): \"\"\" Load info from a reference to an item. Args: data_ref (boxs.data.DataRef): Data reference that points to the data whose info is requested. Returns: boxs.data.DataInfo: The info about the data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in this box. \"\"\" box_id = data_ref . box_id box = get_box ( box_id ) logger . debug ( \"Getting info about value %s from box %s \" , data_ref . uri , box . box_id ) return box . info ( data_ref )","title":"info()"},{"location":"api/#boxs.api.load","text":"Load the content of the data item. Parameters: Name Type Description Default data Union[boxs.data.DataRef,boxs.data.DataInfo] DataInfo or DataRef that points to the data that should be loaded. required value_type boxs.value_types.ValueType The value type to use when loading the data. Defaults to None , in which case the same value type will be used that was used when the data was initially stored. None Returns: Type Description Any The loaded data. Exceptions: Type Description boxs.errors.BoxNotDefined If the data is stored in an unknown box. boxs.errors.DataNotFound If no data with the specific ids are stored in the referenced box. Source code in boxs/api.py def load ( data , value_type = None ): \"\"\" Load the content of the data item. Args: data (Union[boxs.data.DataRef,boxs.data.DataInfo]): DataInfo or DataRef that points to the data that should be loaded. value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in the referenced box. \"\"\" box_id = data . box_id box = get_box ( box_id ) logger . debug ( \"Loading value %s from box %s \" , data . uri , box . box_id ) return box . load ( data , value_type = value_type )","title":"load()"},{"location":"api/#boxs.api.store","text":"Store new data in this box. Parameters: Name Type Description Default value Any A value that should be stored. required *parents Union[boxs.data.DataInfo,boxs.data.DataRef] Parent data refs, that this data depends on. () origin Union[str,Callable] A string or callable returning a string, that is used as an origin for deriving the data's id. Defaults to a callable, that takes the name of the function, from which store is being called as origin. ORIGIN_FROM_FUNCTION_NAME name str An optional user-defined name, that can be used for looking up data manually. None tags Dict[str,str] A dictionary of tags that can be used for grouping multiple data together. Keys and values have to be strings. None meta Dict[str, Any] Additional meta-data about this data. This can be used for arbitrary information that might be useful, e.g. information about type or format of the data, timestamps, user info etc. None value_type boxs.value_types.ValueType The value_type to use for writing this value to the storage. Defaults to None in which case a suitable value type is taken from the list of predefined values types. None run_id str The id of the run when the data was stored. Defaults to the current global run_id (see get_run_id() ). None box Union[str,boxs.box.Box] The box in which the data should be stored. The box can be either given as Box instance, or by its box_id . None Returns: Type Description boxs.data.DataInfo Data instance that contains information about the data and allows referring to it. Exceptions: Type Description ValueError If no box or no origin was provided. boxs.errors.BoxNotDefined If no box with the given box id is defined. Source code in boxs/api.py def store ( value , * parents , name = None , origin = ORIGIN_FROM_FUNCTION_NAME , tags = None , meta = None , value_type = None , run_id = None , box = None ): \"\"\" Store new data in this box. Args: value (Any): A value that should be stored. *parents (Union[boxs.data.DataInfo,boxs.data.DataRef]): Parent data refs, that this data depends on. origin (Union[str,Callable]): A string or callable returning a string, that is used as an origin for deriving the data's id. Defaults to a callable, that takes the name of the function, from which `store` is being called as origin. name (str): An optional user-defined name, that can be used for looking up data manually. tags (Dict[str,str]): A dictionary of tags that can be used for grouping multiple data together. Keys and values have to be strings. meta (Dict[str, Any]): Additional meta-data about this data. This can be used for arbitrary information that might be useful, e.g. information about type or format of the data, timestamps, user info etc. value_type (boxs.value_types.ValueType): The value_type to use for writing this value to the storage. Defaults to `None` in which case a suitable value type is taken from the list of predefined values types. run_id (str): The id of the run when the data was stored. Defaults to the current global run_id (see `get_run_id()`). box (Union[str,boxs.box.Box]): The box in which the data should be stored. The box can be either given as Box instance, or by its `box_id`. Returns: boxs.data.DataInfo: Data instance that contains information about the data and allows referring to it. Raises: ValueError: If no box or no origin was provided. boxs.errors.BoxNotDefined: If no box with the given box id is defined. \"\"\" if box is None : box = get_config () . default_box logger . debug ( \"No box defined, using default_box %s from config\" , box ) if box is None : raise ValueError ( \"'box' must be set.\" ) if isinstance ( box , str ): box = get_box ( box ) origin = determine_origin ( origin , name = name , tags = tags , level = 3 ) return box . store ( value , * parents , name = name , origin = origin , tags = tags , meta = meta , value_type = value_type , run_id = run_id )","title":"store()"},{"location":"api/#boxs.box","text":"Boxes to store items in","title":"box"},{"location":"api/#boxs.box.Box","text":"Box that allows to store and load data. Attributes: Name Type Description box_id str The id that uniquely identifies this Box. storage boxs.storage.Storage The storage that actually writes and reads the data. transformers boxs.storage.Transformer A tuple with transformers, that add additional meta-data and transform the data stored and loaded. Source code in boxs/box.py class Box : \"\"\"Box that allows to store and load data. Attributes: box_id (str): The id that uniquely identifies this Box. storage (boxs.storage.Storage): The storage that actually writes and reads the data. transformers (boxs.storage.Transformer): A tuple with transformers, that add additional meta-data and transform the data stored and loaded. \"\"\" def __init__ ( self , box_id , storage , * transformers ): self . box_id = box_id self . storage = storage self . transformers = transformers self . value_types = [ BytesValueType (), StreamValueType (), StringValueType (), FileValueType (), JsonValueType (), ] register_box ( self ) def add_value_type ( self , value_type ): \"\"\" Add a new value type. The value type is added at the beginning of the list, so that it takes precedence over the already added value types. Args: value_type (boxs.value_types.ValueType): The new value type to add. \"\"\" self . value_types . insert ( 0 , value_type ) def store ( self , value , * parents , origin = ORIGIN_FROM_FUNCTION_NAME , name = None , tags = None , meta = None , value_type = None , run_id = None , ): \"\"\" Store new data in this box. Args: value (Any): A value that should be stored. *parents (Union[boxs.data.DataInfo, boxs.data.DataRef]): Parent data refs, that this data depends on. origin (Union[str,Callable]): A string or callable returning a string, that is used as an origin for deriving the data's id. Defaults to a callable, that takes the name of the function, from which `store` is being called as origin. name (str): An optional user-defined name, that can be used for looking up data manually. tags (Dict[str,str]): A dictionary of tags that can be used for grouping multiple data together. Keys and values have to be strings. meta (Dict[str, Any]): Additional meta-data about this data. This can be used for arbitrary information that might be useful, e.g. information about type or format of the data, timestamps, user info etc. value_type (boxs.value_types.ValueType): The value_type to use for writing this value to the storage. Defaults to `None` in which case a suitable value type is taken from the list of predefined values types. run_id (str): The id of the run when the data was stored. Returns: boxs.data.DataInfo: Data instance that contains information about the data and allows referring to it. \"\"\" if tags is None : tags = {} if meta is None : meta = {} else : meta = dict ( meta ) origin = determine_origin ( origin , name = name , tags = tags , level = 3 ) logger . info ( \"Storing value in box %s with origin %s \" , self . box_id , origin ) parent_ids = tuple ( p . data_id for p in parents ) data_id = calculate_data_id ( origin , parent_ids = parent_ids , name = name ) logger . debug ( \"Calculate data_id %s from origin %s with parents %s \" , data_id , origin , parent_ids , ) if run_id is None : run_id = get_run_id () ref = DataRef ( self . box_id , data_id , run_id ) writer = self . storage . create_writer ( ref , name , tags ) logger . debug ( \"Created writer %s for data %s \" , writer , ref ) writer = self . _apply_transformers_to_writer ( writer ) if value_type is None : value_type = self . _find_suitable_value_type ( value ) if value_type is None : raise MissingValueType ( value ) logger . debug ( \"Write value for data %s with value type %s \" , ref . uri , value_type . get_specification (), ) writer . write_value ( value , value_type ) meta [ 'value_type' ] = value_type . get_specification () meta = dict ( meta ) meta . update ( writer . meta ) data_info = DataInfo ( DataRef . from_item ( writer . item ), origin = origin , parents = parents , name = name , tags = tags , meta = meta , ) logger . debug ( \"Write info for data %s \" , ref . uri ) writer . write_info ( data_info . value_info ()) return data_info def _find_suitable_value_type ( self , value ): value_type = None for configured_value_type in self . value_types : if configured_value_type . supports ( value ): value_type = configured_value_type logger . debug ( \"Automatically chose value type %s \" , value_type . get_specification (), ) return value_type def _apply_transformers_to_writer ( self , writer ): for transformer in self . transformers : logger . debug ( \"Applying transformer %s \" , transformer ) writer = transformer . transform_writer ( writer ) return writer def load ( self , data_ref , value_type = None ): \"\"\" Load data from the box. Args: data_ref (Union[boxs.data.DataRef,boxs.data.DataInfo]): Data reference that points to the data content to be loaded. value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.DataNotFound: If no data with the specific ids are stored in this box. ValueError: If the data refers to a different box by its box_id. \"\"\" if data_ref . box_id != self . box_id : raise ValueError ( \"Data references different box id\" ) logger . info ( \"Loading value %s from box %s \" , data_ref . uri , self . box_id ) info = data_ref . info if value_type is None : value_type = self . _get_value_type_from_meta_data ( info ) reader = self . storage . create_reader ( data_ref ) logger . debug ( \"Created reader %s for data %s \" , reader , data_ref ) reader = self . _apply_transformers_to_reader ( reader ) logger . debug ( \"Read value from data %s with value type %s \" , data_ref . uri , value_type . get_specification (), ) return reader . read_value ( value_type ) @staticmethod def _get_value_type_from_meta_data ( info ): value_type_specification = info . meta [ 'value_type' ] value_type = ValueType . from_specification ( value_type_specification ) logger . debug ( \"Use value type %s taken from meta-data\" , value_type . get_specification (), ) return value_type def _apply_transformers_to_reader ( self , reader ): for transformer in reversed ( self . transformers ): logger . debug ( \"Applying transformer %s \" , transformer ) reader = transformer . transform_reader ( reader ) return reader def info ( self , data_ref ): \"\"\" Load info from the box. Args: data_ref (boxs.data.DataRef): Data reference that points to the data whose info is requested. Returns: boxs.data.DataInfo: The info about the data. Raises: boxs.errors.DataNotFound: If no data with the specific ids are stored in this box. ValueError: If the data refers to a different box by its box_id. \"\"\" if data_ref . box_id != self . box_id : raise ValueError ( \"Data references different box id\" ) logger . info ( \"Getting info for value %s from box %s \" , data_ref . uri , self . box_id ) reader = self . storage . create_reader ( data_ref ) logger . debug ( \"Created reader %s for data %s \" , reader , data_ref ) return DataInfo . from_value_info ( reader . info )","title":"Box"},{"location":"api/#boxs.box.Box.add_value_type","text":"Add a new value type. The value type is added at the beginning of the list, so that it takes precedence over the already added value types. Parameters: Name Type Description Default value_type boxs.value_types.ValueType The new value type to add. required Source code in boxs/box.py def add_value_type ( self , value_type ): \"\"\" Add a new value type. The value type is added at the beginning of the list, so that it takes precedence over the already added value types. Args: value_type (boxs.value_types.ValueType): The new value type to add. \"\"\" self . value_types . insert ( 0 , value_type )","title":"add_value_type()"},{"location":"api/#boxs.box.Box.info","text":"Load info from the box. Parameters: Name Type Description Default data_ref boxs.data.DataRef Data reference that points to the data whose info is requested. required Returns: Type Description boxs.data.DataInfo The info about the data. Exceptions: Type Description boxs.errors.DataNotFound If no data with the specific ids are stored in this box. ValueError If the data refers to a different box by its box_id. Source code in boxs/box.py def info ( self , data_ref ): \"\"\" Load info from the box. Args: data_ref (boxs.data.DataRef): Data reference that points to the data whose info is requested. Returns: boxs.data.DataInfo: The info about the data. Raises: boxs.errors.DataNotFound: If no data with the specific ids are stored in this box. ValueError: If the data refers to a different box by its box_id. \"\"\" if data_ref . box_id != self . box_id : raise ValueError ( \"Data references different box id\" ) logger . info ( \"Getting info for value %s from box %s \" , data_ref . uri , self . box_id ) reader = self . storage . create_reader ( data_ref ) logger . debug ( \"Created reader %s for data %s \" , reader , data_ref ) return DataInfo . from_value_info ( reader . info )","title":"info()"},{"location":"api/#boxs.box.Box.load","text":"Load data from the box. Parameters: Name Type Description Default data_ref Union[boxs.data.DataRef,boxs.data.DataInfo] Data reference that points to the data content to be loaded. required value_type boxs.value_types.ValueType The value type to use when loading the data. Defaults to None , in which case the same value type will be used that was used when the data was initially stored. None Returns: Type Description Any The loaded data. Exceptions: Type Description boxs.errors.DataNotFound If no data with the specific ids are stored in this box. ValueError If the data refers to a different box by its box_id. Source code in boxs/box.py def load ( self , data_ref , value_type = None ): \"\"\" Load data from the box. Args: data_ref (Union[boxs.data.DataRef,boxs.data.DataInfo]): Data reference that points to the data content to be loaded. value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.DataNotFound: If no data with the specific ids are stored in this box. ValueError: If the data refers to a different box by its box_id. \"\"\" if data_ref . box_id != self . box_id : raise ValueError ( \"Data references different box id\" ) logger . info ( \"Loading value %s from box %s \" , data_ref . uri , self . box_id ) info = data_ref . info if value_type is None : value_type = self . _get_value_type_from_meta_data ( info ) reader = self . storage . create_reader ( data_ref ) logger . debug ( \"Created reader %s for data %s \" , reader , data_ref ) reader = self . _apply_transformers_to_reader ( reader ) logger . debug ( \"Read value from data %s with value type %s \" , data_ref . uri , value_type . get_specification (), ) return reader . read_value ( value_type )","title":"load()"},{"location":"api/#boxs.box.Box.store","text":"Store new data in this box. Parameters: Name Type Description Default value Any A value that should be stored. required *parents Union[boxs.data.DataInfo, boxs.data.DataRef] Parent data refs, that this data depends on. () origin Union[str,Callable] A string or callable returning a string, that is used as an origin for deriving the data's id. Defaults to a callable, that takes the name of the function, from which store is being called as origin. ORIGIN_FROM_FUNCTION_NAME name str An optional user-defined name, that can be used for looking up data manually. None tags Dict[str,str] A dictionary of tags that can be used for grouping multiple data together. Keys and values have to be strings. None meta Dict[str, Any] Additional meta-data about this data. This can be used for arbitrary information that might be useful, e.g. information about type or format of the data, timestamps, user info etc. None value_type boxs.value_types.ValueType The value_type to use for writing this value to the storage. Defaults to None in which case a suitable value type is taken from the list of predefined values types. None run_id str The id of the run when the data was stored. None Returns: Type Description boxs.data.DataInfo Data instance that contains information about the data and allows referring to it. Source code in boxs/box.py def store ( self , value , * parents , origin = ORIGIN_FROM_FUNCTION_NAME , name = None , tags = None , meta = None , value_type = None , run_id = None , ): \"\"\" Store new data in this box. Args: value (Any): A value that should be stored. *parents (Union[boxs.data.DataInfo, boxs.data.DataRef]): Parent data refs, that this data depends on. origin (Union[str,Callable]): A string or callable returning a string, that is used as an origin for deriving the data's id. Defaults to a callable, that takes the name of the function, from which `store` is being called as origin. name (str): An optional user-defined name, that can be used for looking up data manually. tags (Dict[str,str]): A dictionary of tags that can be used for grouping multiple data together. Keys and values have to be strings. meta (Dict[str, Any]): Additional meta-data about this data. This can be used for arbitrary information that might be useful, e.g. information about type or format of the data, timestamps, user info etc. value_type (boxs.value_types.ValueType): The value_type to use for writing this value to the storage. Defaults to `None` in which case a suitable value type is taken from the list of predefined values types. run_id (str): The id of the run when the data was stored. Returns: boxs.data.DataInfo: Data instance that contains information about the data and allows referring to it. \"\"\" if tags is None : tags = {} if meta is None : meta = {} else : meta = dict ( meta ) origin = determine_origin ( origin , name = name , tags = tags , level = 3 ) logger . info ( \"Storing value in box %s with origin %s \" , self . box_id , origin ) parent_ids = tuple ( p . data_id for p in parents ) data_id = calculate_data_id ( origin , parent_ids = parent_ids , name = name ) logger . debug ( \"Calculate data_id %s from origin %s with parents %s \" , data_id , origin , parent_ids , ) if run_id is None : run_id = get_run_id () ref = DataRef ( self . box_id , data_id , run_id ) writer = self . storage . create_writer ( ref , name , tags ) logger . debug ( \"Created writer %s for data %s \" , writer , ref ) writer = self . _apply_transformers_to_writer ( writer ) if value_type is None : value_type = self . _find_suitable_value_type ( value ) if value_type is None : raise MissingValueType ( value ) logger . debug ( \"Write value for data %s with value type %s \" , ref . uri , value_type . get_specification (), ) writer . write_value ( value , value_type ) meta [ 'value_type' ] = value_type . get_specification () meta = dict ( meta ) meta . update ( writer . meta ) data_info = DataInfo ( DataRef . from_item ( writer . item ), origin = origin , parents = parents , name = name , tags = tags , meta = meta , ) logger . debug ( \"Write info for data %s \" , ref . uri ) writer . write_info ( data_info . value_info ()) return data_info","title":"store()"},{"location":"api/#boxs.box.calculate_data_id","text":"Derive a data_id from origin and parent_ids Parameters: Name Type Description Default origin str The origin of the data. required parent_ids tuple[str] A tuple of data_ids of \"parent\" data, that this data is derived from. () Returns: Type Description str The data_id. Source code in boxs/box.py def calculate_data_id ( origin , parent_ids = tuple (), name = None ): \"\"\" Derive a data_id from origin and parent_ids Args: origin (str): The origin of the data. parent_ids (tuple[str]): A tuple of data_ids of \"parent\" data, that this data is derived from. Returns: str: The data_id. \"\"\" id_origin_data = ':' . join ( [ origin , name or '' , ] + sorted ( parent_ids ) ) return hashlib . blake2b ( id_origin_data . encode ( 'utf-8' ), digest_size = 8 ) . hexdigest ()","title":"calculate_data_id()"},{"location":"api/#boxs.box_registry","text":"Registry of boxes","title":"box_registry"},{"location":"api/#boxs.box_registry.get_box","text":"Return the box with the given box_id. Parameters: Name Type Description Default box_id Optional[str] The id of the box that should be returned. Defaults to None in which case the default box is taken from the config and returned. None Returns: Type Description boxs.box.Box The box with the given box_id . Exceptions: Type Description boxs.errors.BoxNotDefined If no box with the given id is defined. Source code in boxs/box_registry.py def get_box ( box_id = None ): \"\"\" Return the box with the given box_id. Args: box_id (Optional[str]): The id of the box that should be returned. Defaults to `None` in which case the default box is taken from the config and returned. Returns: boxs.box.Box: The box with the given `box_id`. Raises: boxs.errors.BoxNotDefined: If no box with the given id is defined. \"\"\" logger . debug ( \"Getting box %s \" , box_id ) if box_id is None : box_id = get_config () . default_box logger . debug ( \"Using default_box %s from config\" , box_id ) if box_id not in _BOX_REGISTRY : raise BoxNotDefined ( box_id ) return _BOX_REGISTRY [ box_id ]","title":"get_box()"},{"location":"api/#boxs.box_registry.register_box","text":"Registers a new box. Parameters: Name Type Description Default box boxs.box.Box The box that should be registered. required Exceptions: Type Description boxs.errors.BoxAlreadyDefined If a box with the same id is already registered. Source code in boxs/box_registry.py def register_box ( box ): \"\"\" Registers a new box. Args: box (boxs.box.Box): The box that should be registered. Raises: boxs.errors.BoxAlreadyDefined: If a box with the same id is already registered. \"\"\" box_id = box . box_id logger . info ( \"Registering box %s \" , box_id ) if box_id in _BOX_REGISTRY : raise BoxAlreadyDefined ( box_id ) _BOX_REGISTRY [ box . box_id ] = box","title":"register_box()"},{"location":"api/#boxs.box_registry.unregister_box","text":"Unregisters the box with the given box_id. Parameters: Name Type Description Default box_id str The id of the box that should be removed. required Exceptions: Type Description boxs.errors.BoxNotDefined If no box with the given id is defined. Source code in boxs/box_registry.py def unregister_box ( box_id ): \"\"\" Unregisters the box with the given box_id. Args: box_id (str): The id of the box that should be removed. Raises: boxs.errors.BoxNotDefined: If no box with the given id is defined. \"\"\" logger . info ( \"Unregistering box %s \" , box_id ) if box_id not in _BOX_REGISTRY : raise BoxNotDefined ( box_id ) del _BOX_REGISTRY [ box_id ]","title":"unregister_box()"},{"location":"api/#boxs.checksum","text":"Checksum data to detect errors","title":"checksum"},{"location":"api/#boxs.checksum.ChecksumTransformer","text":"Transformer that calculates and verifies the checksums of data. The transformer adds three values to the data's meta data: - 'checksum_digest': The hex-string representation of the checksum. - 'checksum_digest_size': The size in bytes of the checksum (not its representation). - 'checksum_algorithm': The hashing algorithm which is used for calculating the checksum. Currently, only 'blake2b' is supported. Source code in boxs/checksum.py class ChecksumTransformer ( Transformer ): \"\"\" Transformer that calculates and verifies the checksums of data. The transformer adds three values to the data's meta data: - 'checksum_digest': The hex-string representation of the checksum. - 'checksum_digest_size': The size in bytes of the checksum (not its representation). - 'checksum_algorithm': The hashing algorithm which is used for calculating the checksum. Currently, only 'blake2b' is supported. \"\"\" def __init__ ( self , digest_size = 32 ): \"\"\" Create a new ChecksumTransformer. Args: digest_size (int): Length of the checksum in bytes. Defaults to `32`. Since a checksum is represented as a hex-string, where a single byte is represented by two characters, the length of the resulting checksum string will be twice of the `digest_size`. \"\"\" self . digest_size = digest_size def transform_reader ( self , reader ): return _ChecksumReader ( reader , default_digest_size = self . digest_size ) def transform_writer ( self , writer ): return _ChecksumWriter ( writer , digest_size = self . digest_size )","title":"ChecksumTransformer"},{"location":"api/#boxs.checksum.ChecksumTransformer.__init__","text":"Create a new ChecksumTransformer. Parameters: Name Type Description Default digest_size int Length of the checksum in bytes. Defaults to 32 . Since a checksum is represented as a hex-string, where a single byte is represented by two characters, the length of the resulting checksum string will be twice of the digest_size . 32 Source code in boxs/checksum.py def __init__ ( self , digest_size = 32 ): \"\"\" Create a new ChecksumTransformer. Args: digest_size (int): Length of the checksum in bytes. Defaults to `32`. Since a checksum is represented as a hex-string, where a single byte is represented by two characters, the length of the resulting checksum string will be twice of the `digest_size`. \"\"\" self . digest_size = digest_size","title":"__init__()"},{"location":"api/#boxs.checksum.ChecksumTransformer.transform_reader","text":"Transform a given reader. Parameters: Name Type Description Default reader boxs.storage.Reader Reader object that is used for reading data content and meta-data. required Returns: Type Description boxs.storage.Reader A modified reader that will be used instead. Source code in boxs/checksum.py def transform_reader ( self , reader ): return _ChecksumReader ( reader , default_digest_size = self . digest_size )","title":"transform_reader()"},{"location":"api/#boxs.checksum.ChecksumTransformer.transform_writer","text":"Transform a given writer. Parameters: Name Type Description Default writer boxs.storage.Writer Writer object that is used for writing new data content and meta-data. required Returns: Type Description boxs.storage.Writer A modified writer that will be used instead. Source code in boxs/checksum.py def transform_writer ( self , writer ): return _ChecksumWriter ( writer , digest_size = self . digest_size )","title":"transform_writer()"},{"location":"api/#boxs.checksum.DataChecksumMismatch","text":"Exception that is raised if a checksum doesn't match. Attributes: Name Type Description item boxs.storage.Item The item where the mismatch occurred. expected str Checksum that was expected. calculated str Checksum that was actually calculated. Source code in boxs/checksum.py class DataChecksumMismatch ( DataError ): \"\"\" Exception that is raised if a checksum doesn't match. Attributes: item (boxs.storage.Item): The item where the mismatch occurred. expected (str): Checksum that was expected. calculated (str): Checksum that was actually calculated. \"\"\" def __init__ ( self , item , expected , calculated ): self . item = item self . expected = expected self . calculated = calculated super () . __init__ ( f \" { self . item } has wrong checksum ' { self . calculated } '\" f \", expected ' { self . expected } '\" )","title":"DataChecksumMismatch"},{"location":"api/#boxs.cli","text":"Command line interface","title":"cli"},{"location":"api/#boxs.cli.clean_runs_command","text":"Function that removes old runs. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def clean_runs_command ( args ): \"\"\" Function that removes old runs. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" box = get_box () storage = box . storage logger . info ( \"Removing runs in box %s \" , box . box_id ) runs = storage . list_runs ( box . box_id ) runs_to_keep = set ( runs [: args . count ]) if not args . remove_named : _keep_runs_with_name ( runs , runs_to_keep ) if not args . ignore_dependencies : _keep_runs_that_are_dependencies ( runs_to_keep , storage ) runs_to_delete = [ run for run in runs if run not in runs_to_keep ] _print_result ( \"Delete runs\" , runs_to_delete , args ) if runs_to_delete : if not args . quiet : if not _confirm ( \"Really delete all listed runs? (y/N)\" ): return for run in runs_to_delete : box . storage . delete_run ( run . box_id , run . run_id )","title":"clean_runs_command()"},{"location":"api/#boxs.cli.delete_run_command","text":"Command that allows to delete a specific run. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def delete_run_command ( args ): \"\"\" Command that allows to delete a specific run. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" box = get_box () storage = box . storage run = _get_run_from_args ( args ) if run is None : return logger . info ( \"Deleting run %s in box %s \" , run . run_id , box . box_id , ) if not args . quiet : if not _confirm ( f \"Really delete the run { run . run_id } ? There might be other \" f \"runs referencing data from it. (y/N)\" ): return storage . delete_run ( box . box_id , run . run_id ) _print_result ( f \"Run { run . run_id } deleted.\" , [ run ], args )","title":"delete_run_command()"},{"location":"api/#boxs.cli.diff_command","text":"Command that compares two runs or data items. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def diff_command ( args ): \"\"\" Command that compares two runs or data items. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" def _get_data_item_as_file ( ref ): return ref . load ( value_type = FileValueType ()) results = [] for obj_string in args . queries : item_query = _parse_query ( obj_string ) box = get_box ( item_query . box ) item_query . box = box . box_id results . append ( box . storage . list_items ( item_query )) if len ( results [ 0 ]) == 1 and len ( results [ 1 ]) == 1 : first_ref = DataRef . from_item ( results [ 0 ][ 0 ]) second_ref = DataRef . from_item ( results [ 1 ][ 0 ]) logger . info ( \"Showing diff between items %s and %s \" , first_ref . uri , second_ref . uri , ) first_file_path = _get_data_item_as_file ( first_ref ) first_label = args . queries [ 0 ] second_file_path = _get_data_item_as_file ( second_ref ) second_label = args . queries [ 1 ] command = [ args . diff , str ( first_file_path ), str ( second_file_path )] if args . labels : command . extend ( [ '--label' , first_label , '--label' , second_label , ] ) command . extend ( args . diff_args ) logger . info ( \"Calling diff %s \" , command ) subprocess . run ( command , stdout = sys . stdout , stderr = sys . stderr , check = False ) else : _print_error ( \"Ambiguous values to diff.\" , args )","title":"diff_command()"},{"location":"api/#boxs.cli.export_command","text":"Command that exports a data item to a file. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def export_command ( args ): \"\"\" Command that exports a data item to a file. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" def _export_item_as_file ( ref , file_path ): return ref . load ( value_type = FileValueType ( file_path = file_path )) item_query = _parse_query ( args . query ) box = get_box ( item_query . box ) item_query . box = box . box_id items = box . storage . list_items ( item_query ) if len ( items ) == 0 : _print_error ( f \"No item found for { args . query } .\" , args ) elif len ( items ) > 1 : _print_error ( f \"Multiple items found for { args . query } .\" , args ) _print_result ( '' , items , args ) else : ref = DataRef . from_item ( items [ 0 ]) export_file_path = pathlib . Path ( args . file ) logger . info ( \"Exporting item %s to file %s \" , ref . uri , export_file_path ) _export_item_as_file ( ref , export_file_path ) _print_result ( f \" { args . query } successfully exported to { args . file } \" , [], args )","title":"export_command()"},{"location":"api/#boxs.cli.graph_command","text":"Command that creates a graph out of data items. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def graph_command ( args ): \"\"\" Command that creates a graph out of data items. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" item_query = _parse_query ( args . query ) if item_query . box is None : item_query . box = get_config () . default_box box = get_box ( item_query . box ) items = box . storage . list_items ( item_query ) refs = [ DataRef . from_item ( item ) for item in items ] if args . file == '-' : writer = sys . stdout else : writer = io . FileIO ( args . file , 'w' ) writer = codecs . getwriter ( 'utf-8' )( writer ) with writer : write_graph_of_refs ( writer , refs )","title":"graph_command()"},{"location":"api/#boxs.cli.info_command","text":"Command that shows the information about a data item. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def info_command ( args ): \"\"\" Command that shows the information about a data item. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" item_query = _parse_query ( args . query [ 0 ]) box = get_box ( item_query . box ) item_query . box = box . box_id items = box . storage . list_items ( item_query ) if len ( items ) == 0 : _print_error ( f \"No item found by query { args . query [ 0 ] } \" , args ) return if len ( items ) > 1 : _print_error ( f \"Multiple items found by query { args . query [ 0 ] } \" , args ) _print_result ( '' , items , args ) return item = items [ 0 ] logger . info ( \"Showing info about item %s from run %s in box %s \" , item . data_id , item . run_id , item . box_id , ) info = box . storage . create_reader ( DataRef . from_item ( item )) . info _print_result ( f \"Info { item . data_id } { item . run_id } \" , info , args )","title":"info_command()"},{"location":"api/#boxs.cli.list_command","text":"Function that lists the data items of a specific run. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def list_command ( args ): \"\"\" Function that lists the data items of a specific run. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" item_query = _parse_query ( args . query [ 0 ]) logger . info ( \"Listing items by query %s \" , item_query ) box = get_box ( item_query . box ) item_query . box = box . box_id items = box . storage . list_items ( item_query ) if len ( items ) == 0 : _print_error ( f \"No items found by query { args . query [ 0 ] } \" , args ) return _print_result ( f \"List items { item_query } \" , items , args )","title":"list_command()"},{"location":"api/#boxs.cli.list_runs_command","text":"Function that lists runs. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def list_runs_command ( args ): \"\"\" Function that lists runs. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" box = get_box () storage = box . storage logger . info ( \"Listing all runs in box %s \" , box . box_id ) runs = storage . list_runs ( box . box_id , name_filter = args . filter , limit = args . limit ) _print_result ( \"List runs\" , runs , args )","title":"list_runs_command()"},{"location":"api/#boxs.cli.main","text":"main() method of our command line interface. Parameters: Name Type Description Default argv List[str] Command line arguments given to the function. If None , the arguments are taken from sys.argv . None Source code in boxs/cli.py def main ( argv = None ): \"\"\" main() method of our command line interface. Args: argv (List[str]): Command line arguments given to the function. If `None`, the arguments are taken from `sys.argv`. \"\"\" argv = argv or sys . argv [ 1 :] boxs_home_dir = pathlib . Path . home () / '.boxs' boxs_home_dir . mkdir ( exist_ok = True ) file_handler = logging . FileHandler ( boxs_home_dir / 'cli.log' ) file_handler . level = logging . DEBUG file_handler . setFormatter ( logging . Formatter ( fmt = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) ) logging . basicConfig ( level = logging . DEBUG , handlers = [ file_handler ], ) logger . debug ( \"Command line arguments: %s \" , argv ) parser = argparse . ArgumentParser ( prog = 'boxs' , description = \"Allows to inspect and manipulate boxes that are used for \" \"storing data items using the python 'boxs' library.\" , ) parser . set_defaults ( command = lambda _ : parser . print_help ()) parser . add_argument ( '-b' , '--default-box' , metavar = 'BOX' , dest = 'default_box' , help = \"The id of the default box to use. If not set, the default is taken \" \"from the BOXS_DEFAULT_BOX environment variable.\" , ) parser . add_argument ( '-i' , '--init-module' , dest = 'init_module' , help = \"A python module that should be automatically loaded. If not set, the \" \"default is taken from the BOXS_INIT_MODULE environment variable.\" , ) parser . add_argument ( '-j' , '--json' , dest = 'json' , action = 'store_true' , help = \"Print output as json\" , ) subparsers = parser . add_subparsers ( help = \"Commands\" ) _add_list_runs_command ( subparsers ) _add_name_run_command ( subparsers ) _add_delete_run_command ( subparsers ) _add_clean_runs_command ( subparsers ) _add_list_command ( subparsers ) _add_info_command ( subparsers ) _add_diff_command ( subparsers ) _add_export_command ( subparsers ) _add_graph_command ( subparsers ) args = parser . parse_args ( argv ) config = get_config () if args . default_box : config . default_box = args . default_box if args . init_module : config . init_module = args . init_module try : args . command ( args ) except BoxsError as error : _print_error ( error , args )","title":"main()"},{"location":"api/#boxs.cli.name_run_command","text":"Command that allows to set a name for a specific run. Parameters: Name Type Description Default args argparse.Namespace The parsed arguments from command line. required Source code in boxs/cli.py def name_run_command ( args ): \"\"\" Command that allows to set a name for a specific run. Args: args (argparse.Namespace): The parsed arguments from command line. \"\"\" box = get_box () storage = box . storage run = _get_run_from_args ( args ) if run is None : return logger . info ( \"Setting name of run %s in box %s to %s \" , run . run_id , box . box_id , args . name , ) run = storage . set_run_name ( box . box_id , run . run_id , args . name ) _print_result ( f \"Run name set { run . run_id } \" , [ run ], args )","title":"name_run_command()"},{"location":"api/#boxs.config","text":"Configuration for Boxs","title":"config"},{"location":"api/#boxs.config.Configuration","text":"Class that contains the individual config values. Attributes: Name Type Description default_box str The id of a box that should be used, no other box id is specified. Will be initialized from the BOXS_DEFAULT_BOX environment variable if defined, otherwise is initialized to None . init_module str The name of a python module, that should be automatically loaded at initialization time. Ideally, the loading of this module should trigger the definition of all boxes that are used, so that they can be found if needed. Setting this to a new module name will lead to an import of the module. Will be initialized from the BOXS_INIT_MODULE environment variable if defined, otherwise is initialized to None . Source code in boxs/config.py class Configuration : \"\"\" Class that contains the individual config values. Attributes: default_box (str): The id of a box that should be used, no other box id is specified. Will be initialized from the `BOXS_DEFAULT_BOX` environment variable if defined, otherwise is initialized to `None`. init_module (str): The name of a python module, that should be automatically loaded at initialization time. Ideally, the loading of this module should trigger the definition of all boxes that are used, so that they can be found if needed. Setting this to a new module name will lead to an import of the module. Will be initialized from the `BOXS_INIT_MODULE` environment variable if defined, otherwise is initialized to `None`. \"\"\" def __init__ ( self ): self . _initialized = False self . default_box = os . environ . get ( 'BOXS_DEFAULT_BOX' , None ) logger . info ( \"Setting default_box to %s \" , self . default_box ) self . init_module = os . environ . get ( 'BOXS_INIT_MODULE' , None ) logger . info ( \"Setting init_module to %s \" , self . init_module ) @property def default_box ( self ): \"\"\" Returns the id of the default box. Returns: str: The id of the id of the default box. \"\"\" return self . _default_box @default_box . setter def default_box ( self , default_box ): \"\"\" Set the id of the default box. Args: default_box (str): The ix of the box that should be used if no box is specified. \"\"\" self . _default_box = default_box @property def init_module ( self ): \"\"\" Returns the name of the init_module that is used in this configuration. Returns: str: The name of the init_module that is used. \"\"\" return self . _init_module @init_module . setter def init_module ( self , init_module ): \"\"\" Set the name of the init_module. Setting this value might lead to the module being imported, if boxs is properly initialized. Args: init_module (str): The name of the module to use for initialization. \"\"\" self . _init_module = init_module self . _load_init_module () @property def initialized ( self ): \"\"\" Returns if boxs is completely initialized. Returns: bool: `True` if the boxs library is initialized, otherwise `False`. \"\"\" return self . _initialized @initialized . setter def initialized ( self , initialized ): \"\"\" Set the initialization status of boxs. Setting this value to `True` might lead to the init_module being imported, if `init_module` is set. Args: initialized (bool): If the library is fully initialized. \"\"\" if self . _initialized and not initialized : self . _initialized = False if not self . _initialized and initialized : self . _initialized = True self . _load_init_module () def _load_init_module ( self ): if self . init_module is not None and self . initialized : logger . info ( \"Import init_module %s \" , self . init_module ) try : importlib . import_module ( self . init_module ) except ImportError as import_error : self . initialized = False raise import_error","title":"Configuration"},{"location":"api/#boxs.config.Configuration.default_box","text":"Returns the id of the default box. Returns: Type Description str The id of the id of the default box.","title":"default_box"},{"location":"api/#boxs.config.Configuration.init_module","text":"Returns the name of the init_module that is used in this configuration. Returns: Type Description str The name of the init_module that is used.","title":"init_module"},{"location":"api/#boxs.config.Configuration.initialized","text":"Returns if boxs is completely initialized. Returns: Type Description bool True if the boxs library is initialized, otherwise False .","title":"initialized"},{"location":"api/#boxs.config.get_config","text":"Returns the configuration. Returns: Type Description boxs.config.Configuration The configuration. Source code in boxs/config.py def get_config (): \"\"\" Returns the configuration. Returns: boxs.config.Configuration: The configuration. \"\"\" global _CONFIG # pylint: disable=global-statement if _CONFIG is None : logger . info ( \"Create new configuration\" ) _CONFIG = Configuration () _CONFIG . initialized = True return _CONFIG","title":"get_config()"},{"location":"api/#boxs.data","text":"Classes representing data items and references","title":"data"},{"location":"api/#boxs.data.DataInfo","text":"Class representing a stored data item. Attributes: Name Type Description ref boxs.data.DataRef Reference to this item. origin str The origin of the data. parents Tuple[boxs.data.DataItem] A tuple containing other data items from which this item was derived. name Optional[str] A string that can be used to refer to this item by an user. Defaults to None . tags Dict[str,str] A dictionary containing string keys and values, that can be used for grouping multiple items together. Defaults to an empty dict. meta Dict[str,Any] A dictionary containing meta-data. This meta-data can have arbitrary values as long as they can be serialized to JSON. Defaults to an empty dict. Source code in boxs/data.py class DataInfo : \"\"\" Class representing a stored data item. Attributes: ref (boxs.data.DataRef): Reference to this item. origin (str): The origin of the data. parents (Tuple[boxs.data.DataItem]): A tuple containing other data items from which this item was derived. name (Optional[str]): A string that can be used to refer to this item by an user. Defaults to `None`. tags (Dict[str,str]): A dictionary containing string keys and values, that can be used for grouping multiple items together. Defaults to an empty dict. meta (Dict[str,Any]): A dictionary containing meta-data. This meta-data can have arbitrary values as long as they can be serialized to JSON. Defaults to an empty dict. \"\"\" __slots__ = [ 'ref' , 'origin' , 'name' , 'parents' , 'tags' , 'meta' , ] def __init__ ( self , ref , origin , parents = tuple (), name = None , tags = None , meta = None , ): # pylint: disable=too-many-arguments self . ref = ref self . origin = origin self . parents = parents self . name = name self . tags = tags or {} self . meta = meta or {} @property def data_id ( self ): \"\"\"Returns the data_id.\"\"\" return self . ref . data_id @property def box_id ( self ): \"\"\"Returns the box_id.\"\"\" return self . ref . box_id @property def run_id ( self ): \"\"\"Returns the run_id.\"\"\" return self . ref . run_id @property def uri ( self ): \"\"\"Returns the uri.\"\"\" return self . ref . uri @property def info ( self ): \"\"\"Returns the info. This is to be compatible with DataRef\"\"\" return self def load ( self , value_type = None ): \"\"\" Load the content of the data item. Args: value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in the referenced box. \"\"\" return load ( self , value_type = value_type ) def value_info ( self ): \"\"\" Returns information about this data item. Returns: Dict[str,str]: A dict containing information about this reference. \"\"\" value_info = { 'ref' : self . ref . value_info (), 'origin' : self . origin , 'name' : self . name , 'tags' : self . tags , 'parents' : [ parent . value_info () for parent in self . parents ], 'meta' : self . meta , } return value_info @classmethod def from_value_info ( cls , value_info ): \"\"\" Recreate a DataInfo from its value_info. Args: value_info (Dict[str,str]): A dictionary containing the info. Returns: boxs.data.DataInfo: The information about the data item. Raises: KeyError: If necessary attributes are missing from the `value_info`. \"\"\" if 'ref' not in value_info : return DataRef . from_value_info ( value_info ) data_ref = DataRef . from_value_info ( value_info [ 'ref' ]) origin = value_info [ 'origin' ] name = value_info [ 'name' ] tags = value_info [ 'tags' ] meta = value_info [ 'meta' ] parents = tuple ( DataInfo . from_value_info ( parent_info ) for parent_info in value_info [ 'parents' ] ) return DataInfo ( data_ref , origin , parents , name = name , tags = tags , meta = meta , ) def __str__ ( self ): return self . uri","title":"DataInfo"},{"location":"api/#boxs.data.DataInfo.box_id","text":"Returns the box_id.","title":"box_id"},{"location":"api/#boxs.data.DataInfo.data_id","text":"Returns the data_id.","title":"data_id"},{"location":"api/#boxs.data.DataInfo.info","text":"Returns the info. This is to be compatible with DataRef","title":"info"},{"location":"api/#boxs.data.DataInfo.run_id","text":"Returns the run_id.","title":"run_id"},{"location":"api/#boxs.data.DataInfo.uri","text":"Returns the uri.","title":"uri"},{"location":"api/#boxs.data.DataInfo.from_value_info","text":"Recreate a DataInfo from its value_info. Parameters: Name Type Description Default value_info Dict[str,str] A dictionary containing the info. required Returns: Type Description boxs.data.DataInfo The information about the data item. Exceptions: Type Description KeyError If necessary attributes are missing from the value_info . Source code in boxs/data.py @classmethod def from_value_info ( cls , value_info ): \"\"\" Recreate a DataInfo from its value_info. Args: value_info (Dict[str,str]): A dictionary containing the info. Returns: boxs.data.DataInfo: The information about the data item. Raises: KeyError: If necessary attributes are missing from the `value_info`. \"\"\" if 'ref' not in value_info : return DataRef . from_value_info ( value_info ) data_ref = DataRef . from_value_info ( value_info [ 'ref' ]) origin = value_info [ 'origin' ] name = value_info [ 'name' ] tags = value_info [ 'tags' ] meta = value_info [ 'meta' ] parents = tuple ( DataInfo . from_value_info ( parent_info ) for parent_info in value_info [ 'parents' ] ) return DataInfo ( data_ref , origin , parents , name = name , tags = tags , meta = meta , )","title":"from_value_info()"},{"location":"api/#boxs.data.DataInfo.load","text":"Load the content of the data item. Parameters: Name Type Description Default value_type boxs.value_types.ValueType The value type to use when loading the data. Defaults to None , in which case the same value type will be used that was used when the data was initially stored. None Returns: Type Description Any The loaded data. Exceptions: Type Description boxs.errors.BoxNotDefined If the data is stored in an unknown box. boxs.errors.DataNotFound If no data with the specific ids are stored in the referenced box. Source code in boxs/data.py def load ( self , value_type = None ): \"\"\" Load the content of the data item. Args: value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in the referenced box. \"\"\" return load ( self , value_type = value_type )","title":"load()"},{"location":"api/#boxs.data.DataInfo.value_info","text":"Returns information about this data item. Returns: Type Description Dict[str,str] A dict containing information about this reference. Source code in boxs/data.py def value_info ( self ): \"\"\" Returns information about this data item. Returns: Dict[str,str]: A dict containing information about this reference. \"\"\" value_info = { 'ref' : self . ref . value_info (), 'origin' : self . origin , 'name' : self . name , 'tags' : self . tags , 'parents' : [ parent . value_info () for parent in self . parents ], 'meta' : self . meta , } return value_info","title":"value_info()"},{"location":"api/#boxs.data.DataRef","text":"Reference to a DataInfo. Source code in boxs/data.py class DataRef : \"\"\" Reference to a DataInfo. \"\"\" __slots__ = [ 'box_id' , 'data_id' , 'run_id' , '_info' , ] def __init__ ( self , box_id , data_id , run_id ): self . box_id = box_id self . data_id = data_id self . run_id = run_id self . _info = None def value_info ( self ): \"\"\" Returns information about this reference. Returns: Dict[str,str]: A dict containing information about this reference. \"\"\" value_info = { 'box_id' : self . box_id , 'data_id' : self . data_id , 'run_id' : self . run_id , } return value_info @classmethod def from_value_info ( cls , value_info ): \"\"\" Recreate a DataRef from its value_info. Args: value_info (Dict[str,str]): A dictionary containing the ids. Returns: boxs.data.DataRef: The DataRef referencing the data. Raises: KeyError: If necessary attributes are missing from the `value_info`. \"\"\" box_id = value_info [ 'box_id' ] data_id = value_info [ 'data_id' ] run_id = value_info [ 'run_id' ] data = DataRef ( box_id , data_id , run_id ) return data @property def uri ( self ): \"\"\"Return the URI of the data item referenced.\"\"\" return f 'boxs:// { self . box_id } / { self . data_id } / { self . run_id } ' @classmethod def from_uri ( cls , uri ): \"\"\" Recreate a DataRef from a URI. Args: uri (str): URI in the format 'box://<box-id>/<data-id>/<run-id>'. Returns: DataRef: The DataRef referencing the data. Raises: ValueError: If the URI doesn't follow the expected format. \"\"\" url_parts = urllib . parse . urlparse ( uri ) if url_parts . scheme != 'boxs' : raise ValueError ( \"Invalid scheme\" ) box_id = url_parts . hostname data_id , run_id = url_parts . path [ 1 :] . split ( '/' , 1 ) data = DataRef ( box_id , data_id , run_id ) return data @classmethod def from_item ( cls , item ): \"\"\" Recreate a DataRef from an Item. Args: item (boxs.storage.Item): The item which describes the data we want to refer to. Returns: DataRef: The DataRef referencing the data. \"\"\" return DataRef ( item . box_id , item . data_id , item . run_id ) @property def info ( self ): \"\"\" Returns the info object describing the referenced data item. Returns: boxs.data.DataInfo: The info about the data item referenced. \"\"\" if self . _info is None : self . _info = info ( self ) return self . _info def load ( self , value_type = None ): \"\"\" Load the content of the data item. Args: value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in the referenced box. \"\"\" return self . info . load ( value_type = value_type ) def __eq__ ( self , other ): if not isinstance ( other , type ( self )): return False return ( self . box_id == other . box_id and self . data_id == other . data_id and self . run_id == other . run_id ) def __hash__ ( self ): return hash (( self . box_id , self . data_id , self . run_id )) def __str__ ( self ): return self . uri","title":"DataRef"},{"location":"api/#boxs.data.DataRef.info","text":"Returns the info object describing the referenced data item. Returns: Type Description boxs.data.DataInfo The info about the data item referenced.","title":"info"},{"location":"api/#boxs.data.DataRef.uri","text":"Return the URI of the data item referenced.","title":"uri"},{"location":"api/#boxs.data.DataRef.from_item","text":"Recreate a DataRef from an Item. Parameters: Name Type Description Default item boxs.storage.Item The item which describes the data we want to refer to. required Returns: Type Description DataRef The DataRef referencing the data. Source code in boxs/data.py @classmethod def from_item ( cls , item ): \"\"\" Recreate a DataRef from an Item. Args: item (boxs.storage.Item): The item which describes the data we want to refer to. Returns: DataRef: The DataRef referencing the data. \"\"\" return DataRef ( item . box_id , item . data_id , item . run_id )","title":"from_item()"},{"location":"api/#boxs.data.DataRef.from_uri","text":"Recreate a DataRef from a URI. Parameters: Name Type Description Default uri str URI in the format 'box:// / / '. required Returns: Type Description DataRef The DataRef referencing the data. Exceptions: Type Description ValueError If the URI doesn't follow the expected format. Source code in boxs/data.py @classmethod def from_uri ( cls , uri ): \"\"\" Recreate a DataRef from a URI. Args: uri (str): URI in the format 'box://<box-id>/<data-id>/<run-id>'. Returns: DataRef: The DataRef referencing the data. Raises: ValueError: If the URI doesn't follow the expected format. \"\"\" url_parts = urllib . parse . urlparse ( uri ) if url_parts . scheme != 'boxs' : raise ValueError ( \"Invalid scheme\" ) box_id = url_parts . hostname data_id , run_id = url_parts . path [ 1 :] . split ( '/' , 1 ) data = DataRef ( box_id , data_id , run_id ) return data","title":"from_uri()"},{"location":"api/#boxs.data.DataRef.from_value_info","text":"Recreate a DataRef from its value_info. Parameters: Name Type Description Default value_info Dict[str,str] A dictionary containing the ids. required Returns: Type Description boxs.data.DataRef The DataRef referencing the data. Exceptions: Type Description KeyError If necessary attributes are missing from the value_info . Source code in boxs/data.py @classmethod def from_value_info ( cls , value_info ): \"\"\" Recreate a DataRef from its value_info. Args: value_info (Dict[str,str]): A dictionary containing the ids. Returns: boxs.data.DataRef: The DataRef referencing the data. Raises: KeyError: If necessary attributes are missing from the `value_info`. \"\"\" box_id = value_info [ 'box_id' ] data_id = value_info [ 'data_id' ] run_id = value_info [ 'run_id' ] data = DataRef ( box_id , data_id , run_id ) return data","title":"from_value_info()"},{"location":"api/#boxs.data.DataRef.load","text":"Load the content of the data item. Parameters: Name Type Description Default value_type boxs.value_types.ValueType The value type to use when loading the data. Defaults to None , in which case the same value type will be used that was used when the data was initially stored. None Returns: Type Description Any The loaded data. Exceptions: Type Description boxs.errors.BoxNotDefined If the data is stored in an unknown box. boxs.errors.DataNotFound If no data with the specific ids are stored in the referenced box. Source code in boxs/data.py def load ( self , value_type = None ): \"\"\" Load the content of the data item. Args: value_type (boxs.value_types.ValueType): The value type to use when loading the data. Defaults to `None`, in which case the same value type will be used that was used when the data was initially stored. Returns: Any: The loaded data. Raises: boxs.errors.BoxNotDefined: If the data is stored in an unknown box. boxs.errors.DataNotFound: If no data with the specific ids are stored in the referenced box. \"\"\" return self . info . load ( value_type = value_type )","title":"load()"},{"location":"api/#boxs.data.DataRef.value_info","text":"Returns information about this reference. Returns: Type Description Dict[str,str] A dict containing information about this reference. Source code in boxs/data.py def value_info ( self ): \"\"\" Returns information about this reference. Returns: Dict[str,str]: A dict containing information about this reference. \"\"\" value_info = { 'box_id' : self . box_id , 'data_id' : self . data_id , 'run_id' : self . run_id , } return value_info","title":"value_info()"},{"location":"api/#boxs.errors","text":"Errors in boxs","title":"errors"},{"location":"api/#boxs.errors.BoxAlreadyDefined","text":"Error that is raised if multiple boxes are defined using the same box id. Attributes: Name Type Description box_id str The id of the box. Source code in boxs/errors.py class BoxAlreadyDefined ( BoxError ): \"\"\" Error that is raised if multiple boxes are defined using the same box id. Attributes: box_id (str): The id of the box. \"\"\" def __init__ ( self , box_id ): self . box_id = box_id super () . __init__ ( f \"Box with box id { self . box_id } already defined\" )","title":"BoxAlreadyDefined"},{"location":"api/#boxs.errors.BoxError","text":"Base class for all errors related to boxes Source code in boxs/errors.py class BoxError ( BoxsError ): \"\"\"Base class for all errors related to boxes\"\"\"","title":"BoxError"},{"location":"api/#boxs.errors.BoxNotDefined","text":"Error that is raised if a box id refers to a non-defined box. Attributes: Name Type Description box_id str The id of the box. Source code in boxs/errors.py class BoxNotDefined ( BoxError ): \"\"\" Error that is raised if a box id refers to a non-defined box. Attributes: box_id (str): The id of the box. \"\"\" def __init__ ( self , box_id ): self . box_id = box_id super () . __init__ ( f \"Box with box id { self . box_id } not defined\" )","title":"BoxNotDefined"},{"location":"api/#boxs.errors.BoxNotFound","text":"Error that is raised if a box can't be found. Attributes: Name Type Description box_id str The id of the box which should contain the data item. Source code in boxs/errors.py class BoxNotFound ( BoxError ): \"\"\" Error that is raised if a box can't be found. Attributes: box_id (str): The id of the box which should contain the data item. \"\"\" def __init__ ( self , box_id ): self . box_id = box_id super () . __init__ ( f \"Box { self . box_id } does not exist in storage.\" )","title":"BoxNotFound"},{"location":"api/#boxs.errors.BoxsError","text":"Base class for all boxs specific errors Source code in boxs/errors.py class BoxsError ( Exception ): \"\"\"Base class for all boxs specific errors\"\"\"","title":"BoxsError"},{"location":"api/#boxs.errors.DataCollision","text":"Error that is raised if a newly created data item already exists. Attributes: Name Type Description box_id str The id of the box containing the data item. data_id str The id of the data item. run_id str The id of the run when the data was created. Source code in boxs/errors.py class DataCollision ( DataError ): \"\"\" Error that is raised if a newly created data item already exists. Attributes: box_id (str): The id of the box containing the data item. data_id (str): The id of the data item. run_id (str): The id of the run when the data was created. \"\"\" def __init__ ( self , box_id , data_id , run_id ): self . box_id = box_id self . data_id = data_id self . run_id = run_id super () . __init__ ( f \"Data { self . data_id } from run { self . run_id } \" f \"already exists in box { self . box_id } \" )","title":"DataCollision"},{"location":"api/#boxs.errors.DataError","text":"Base class for all boxs specific errors related to data Source code in boxs/errors.py class DataError ( BoxsError ): \"\"\"Base class for all boxs specific errors related to data\"\"\"","title":"DataError"},{"location":"api/#boxs.errors.DataNotFound","text":"Error that is raised if a data item can't be found. Attributes: Name Type Description box_id str The id of the box which should contain the data item. data_id str The id of the data item. run_id str The id of the run when the data was created. Source code in boxs/errors.py class DataNotFound ( DataError ): \"\"\" Error that is raised if a data item can't be found. Attributes: box_id (str): The id of the box which should contain the data item. data_id (str): The id of the data item. run_id (str): The id of the run when the data was created. \"\"\" def __init__ ( self , box_id , data_id , run_id ): self . box_id = box_id self . data_id = data_id self . run_id = run_id super () . __init__ ( f \"Data { self . data_id } from run { self . run_id } \" f \"does not exist in box { self . box_id } \" )","title":"DataNotFound"},{"location":"api/#boxs.errors.MissingValueType","text":"Error that is raised if no ValueType can be found that supports the value. Attributes: Name Type Description box_id str The id of the box. Source code in boxs/errors.py class MissingValueType ( ValueTypeError ): \"\"\" Error that is raised if no ValueType can be found that supports the value. Attributes: box_id (str): The id of the box. \"\"\" def __init__ ( self , value ): self . value = value super () . __init__ ( f \"No value type found for ' { self . value } '.\" )","title":"MissingValueType"},{"location":"api/#boxs.errors.NameCollision","text":"Error that is raised if a data item with the same name already exists. Attributes: Name Type Description box_id str The id of the box containing the data item. data_id str The id of the data item. run_id str The id of the run when the data was created. name str The name of the data item that is used twice. Source code in boxs/errors.py class NameCollision ( DataError ): \"\"\" Error that is raised if a data item with the same name already exists. Attributes: box_id (str): The id of the box containing the data item. data_id (str): The id of the data item. run_id (str): The id of the run when the data was created. name (str): The name of the data item that is used twice. \"\"\" def __init__ ( self , box_id , data_id , run_id , name ): self . box_id = box_id self . data_id = data_id self . run_id = run_id self . name = name super () . __init__ ( f \"There already exists a data item in run { self . run_id } with the \" f \"name { self . name } in box { self . box_id } \" )","title":"NameCollision"},{"location":"api/#boxs.errors.RunError","text":"Base class for all run specific errors Source code in boxs/errors.py class RunError ( BoxsError ): \"\"\"Base class for all run specific errors\"\"\"","title":"RunError"},{"location":"api/#boxs.errors.RunNotFound","text":"Error that is raised if a run can't be found. Attributes: Name Type Description box_id str The id of the box which should contain the run. run_id str The id of the run. Source code in boxs/errors.py class RunNotFound ( RunError ): \"\"\" Error that is raised if a run can't be found. Attributes: box_id (str): The id of the box which should contain the run. run_id (str): The id of the run. \"\"\" def __init__ ( self , box_id , run_id ): self . box_id = box_id self . run_id = run_id super () . __init__ ( f \"Run { self . run_id } does not exist in box { self . box_id } \" )","title":"RunNotFound"},{"location":"api/#boxs.errors.ValueTypeError","text":"Base class for all boxs specific errors related to value types Source code in boxs/errors.py class ValueTypeError ( BoxsError ): \"\"\"Base class for all boxs specific errors related to value types\"\"\"","title":"ValueTypeError"},{"location":"api/#boxs.filesystem","text":"Store data in a local filesystem","title":"filesystem"},{"location":"api/#boxs.filesystem.FileSystemStorage","text":"Storage implementation that stores data items and meta-data in a directory. Source code in boxs/filesystem.py class FileSystemStorage ( Storage ): \"\"\"Storage implementation that stores data items and meta-data in a directory.\"\"\" def __init__ ( self , directory ): \"\"\" Create the storage. Args: directory (Union[str,pathlib.Path]): The path to the directory where the data will be stored. \"\"\" self . root_directory = pathlib . Path ( directory ) def _data_file_paths ( self , item ): base_path = ( self . root_directory / item . box_id / 'data' / item . data_id / item . run_id ) return base_path . with_suffix ( '.data' ), base_path . with_suffix ( '.info' ) def _run_file_path ( self , item ): return self . _runs_directory_path ( item . box_id ) / item . run_id / item . data_id def _runs_directory_path ( self , box_id ): path = self . root_directory / box_id / 'runs' path . mkdir ( parents = True , exist_ok = True ) return path def _runs_names_directory_path ( self , box_id ): path = self . _runs_directory_path ( box_id ) / '_named' path . mkdir ( parents = True , exist_ok = True ) return path def _run_directory_path ( self , box_id , run_id ): return self . _runs_directory_path ( box_id ) / run_id def _box_directory_path ( self , box_id ): return self . root_directory / box_id def list_runs ( self , box_id , limit = None , name_filter = None ): box_directory = self . _box_directory_path ( box_id ) logger . debug ( \"List runs from directory %s \" , box_directory ) if not box_directory . exists (): raise BoxNotFound ( box_id ) runs = self . _list_runs_in_box ( box_id ) runs = sorted ( runs , key = lambda x : x . time , reverse = True ) if name_filter is not None : runs = list ( filter ( lambda x : ( x . name or '' ) . startswith ( name_filter ), runs )) if limit is not None : runs = runs [: limit ] return runs def _list_runs_in_box ( self , box_id ): runs_directory = self . _runs_directory_path ( box_id ) runs = [ self . _create_run_from_run_path ( box_id , path ) for path in runs_directory . iterdir () if path . is_dir () and path != self . _runs_names_directory_path ( box_id ) ] return runs def list_items ( self , item_query ): box_id = item_query . box box_directory = self . _box_directory_path ( box_id ) if not box_directory . exists (): raise BoxNotFound ( box_id ) logger . debug ( \"List items with query %s \" , item_query ) runs = self . _list_runs_in_box ( box_id ) if item_query . run : runs = [ run for run in runs if run . run_id . startswith ( item_query . run or '' ) or ( run . name or '' ) . startswith ( item_query . run or '' ) ] runs = sorted ( runs , key = lambda x : x . time ) all_items = [] for run in runs : items = self . _get_items_in_run ( box_id , run . run_id ) items = sorted ( items , key = lambda x : x . time ) all_items . extend ( ( item for item in items if item . data_id . startswith ( item_query . data or '' ) or ( item . name or '' ) . startswith ( item_query . data or '' ) ) ) return all_items def set_run_name ( self , box_id , run_id , name ): logger . debug ( \"Set name of run %s in box %s to %s \" , run_id , box_id , name ) box_directory = self . _box_directory_path ( box_id ) if not box_directory . exists (): raise BoxNotFound ( box_id ) run_directory = self . _run_directory_path ( box_id , run_id ) if not run_directory . exists (): raise RunNotFound ( box_id , run_id ) run_path = self . _run_directory_path ( box_id , run_id ) self . _remove_name_for_run ( box_id , run_id ) if name is not None : self . _set_name_for_run_path ( box_id , name , run_path ) run = self . _create_run_from_run_path ( box_id , run_path ) return run def delete_run ( self , box_id , run_id ): run_directory = self . _run_directory_path ( box_id , run_id ) if not run_directory . exists (): raise RunNotFound ( box_id , run_id ) items = self . _get_items_in_run ( box_id , run_id ) for item in items : data_file , info_file = self . _data_file_paths ( item ) data_file . unlink () info_file . unlink () shutil . rmtree ( run_directory ) def create_writer ( self , item , name = None , tags = None ): logger . debug ( \"Create writer for %s \" , item ) tags = tags or {} data_file , info_file = self . _data_file_paths ( item ) run_file = self . _run_file_path ( item ) return _FileSystemWriter ( item , name , tags , data_file , info_file , run_file ) def create_reader ( self , item ): logger . debug ( \"Create reader for %s \" , item ) data_file , info_file = self . _data_file_paths ( item ) return _FileSystemReader ( item , data_file , info_file ) def _get_run_names ( self , box_id ): name_directory = self . _runs_names_directory_path ( box_id ) run_names = {} for named_link_file in name_directory . iterdir (): name = named_link_file . name resolved_run_dir = named_link_file . resolve () run_id = resolved_run_dir . name run_names [ run_id ] = name return run_names def _set_name_for_run_path ( self , box_id , name , run_path ): name_dir = self . _runs_names_directory_path ( box_id ) name_dir . mkdir ( exist_ok = True ) name_symlink_file = name_dir / name symlink_path = os . path . relpath ( run_path , name_dir ) name_symlink_file . symlink_to ( symlink_path ) def _remove_name_for_run ( self , box_id , run_id ): run_names = self . _get_run_names ( box_id ) if run_id in run_names : name_dir = self . _runs_names_directory_path ( box_id ) name_symlink_file = name_dir / run_names [ run_id ] name_symlink_file . unlink () def _get_items_in_run ( self , box_id , run_id ): named_items = self . _get_item_names_in_run ( box_id , run_id ) items = [ Item ( box_id , path . name , run_id , named_items . get ( path . name , '' ), datetime . datetime . fromtimestamp ( path . stat () . st_mtime , tz = datetime . timezone . utc , ), ) for path in self . _run_directory_path ( box_id , run_id ) . iterdir () if path . is_file () ] return items def _get_item_names_in_run ( self , box_id , run_id ): name_directory = self . _run_directory_path ( box_id , run_id ) / '_named' named_items = {} if name_directory . exists (): for named_link_file in name_directory . iterdir (): name = named_link_file . name resolved_info_file = named_link_file . resolve () data_id = resolved_info_file . name named_items [ data_id ] = name return named_items def _create_run_from_run_path ( self , box_id , run_path ): run_names = self . _get_run_names ( box_id ) run_id = run_path . name return Run ( box_id , run_id , run_names . get ( run_id ), datetime . datetime . fromtimestamp ( run_path . stat () . st_mtime , tz = datetime . timezone . utc , ), )","title":"FileSystemStorage"},{"location":"api/#boxs.filesystem.FileSystemStorage.__init__","text":"Create the storage. Parameters: Name Type Description Default directory Union[str,pathlib.Path] The path to the directory where the data will be stored. required Source code in boxs/filesystem.py def __init__ ( self , directory ): \"\"\" Create the storage. Args: directory (Union[str,pathlib.Path]): The path to the directory where the data will be stored. \"\"\" self . root_directory = pathlib . Path ( directory )","title":"__init__()"},{"location":"api/#boxs.filesystem.FileSystemStorage.create_reader","text":"Creates a Reader instance, that allows to load existing data. Parameters: Name Type Description Default item boxs.storage.Item The item that should be read. required Returns: Type Description boxs.storage.Reader The reader that will load the data from the storage. Source code in boxs/filesystem.py def create_reader ( self , item ): logger . debug ( \"Create reader for %s \" , item ) data_file , info_file = self . _data_file_paths ( item ) return _FileSystemReader ( item , data_file , info_file )","title":"create_reader()"},{"location":"api/#boxs.filesystem.FileSystemStorage.create_writer","text":"Creates a Writer instance, that allows to store new data. Parameters: Name Type Description Default item boxs.storage.Item The new data item. required name str An optional name, that can be used for referring to this item within the run. Defaults to None . None tags Dict[str,str] A dictionary containing tags that can be used for grouping multiple items together. Defaults to an empty dictionary. None Returns: Type Description boxs.storage.Writer The writer that will write the data into the storage. Source code in boxs/filesystem.py def create_writer ( self , item , name = None , tags = None ): logger . debug ( \"Create writer for %s \" , item ) tags = tags or {} data_file , info_file = self . _data_file_paths ( item ) run_file = self . _run_file_path ( item ) return _FileSystemWriter ( item , name , tags , data_file , info_file , run_file )","title":"create_writer()"},{"location":"api/#boxs.filesystem.FileSystemStorage.delete_run","text":"Delete all the data of the specified run. Args; box_id (str): box_id of the box in which the run is stored. run_id (str): Run id of the run which should be deleted. Source code in boxs/filesystem.py def delete_run ( self , box_id , run_id ): run_directory = self . _run_directory_path ( box_id , run_id ) if not run_directory . exists (): raise RunNotFound ( box_id , run_id ) items = self . _get_items_in_run ( box_id , run_id ) for item in items : data_file , info_file = self . _data_file_paths ( item ) data_file . unlink () info_file . unlink () shutil . rmtree ( run_directory )","title":"delete_run()"},{"location":"api/#boxs.filesystem.FileSystemStorage.list_items","text":"List all items that match a given query. The item query can contain parts of box id, run id or run name and data id or data name. If a query value is not set ( == None ) it is not used as a filter criteria. Parameters: Name Type Description Default item_query boxs.storage.ItemQuery The query which defines which items should be listed. required Returns: Type Description List[box.storage.Item] The runs. Source code in boxs/filesystem.py def list_items ( self , item_query ): box_id = item_query . box box_directory = self . _box_directory_path ( box_id ) if not box_directory . exists (): raise BoxNotFound ( box_id ) logger . debug ( \"List items with query %s \" , item_query ) runs = self . _list_runs_in_box ( box_id ) if item_query . run : runs = [ run for run in runs if run . run_id . startswith ( item_query . run or '' ) or ( run . name or '' ) . startswith ( item_query . run or '' ) ] runs = sorted ( runs , key = lambda x : x . time ) all_items = [] for run in runs : items = self . _get_items_in_run ( box_id , run . run_id ) items = sorted ( items , key = lambda x : x . time ) all_items . extend ( ( item for item in items if item . data_id . startswith ( item_query . data or '' ) or ( item . name or '' ) . startswith ( item_query . data or '' ) ) ) return all_items","title":"list_items()"},{"location":"api/#boxs.filesystem.FileSystemStorage.list_runs","text":"List the runs within a box stored in this storage. The runs should be returned in descending order of their start time. Parameters: Name Type Description Default box_id str box_id of the box in which to look for runs. required limit Optional[int] Limits the returned runs to maximum limit number. Defaults to None in which case all runs are returned. None name_filter Optional[str] If set, only include runs which have names that have the filter as prefix. Defaults to None in which case all runs are returned. None Returns: Type Description List[box.storage.Run] The runs. Source code in boxs/filesystem.py def list_runs ( self , box_id , limit = None , name_filter = None ): box_directory = self . _box_directory_path ( box_id ) logger . debug ( \"List runs from directory %s \" , box_directory ) if not box_directory . exists (): raise BoxNotFound ( box_id ) runs = self . _list_runs_in_box ( box_id ) runs = sorted ( runs , key = lambda x : x . time , reverse = True ) if name_filter is not None : runs = list ( filter ( lambda x : ( x . name or '' ) . startswith ( name_filter ), runs )) if limit is not None : runs = runs [: limit ] return runs","title":"list_runs()"},{"location":"api/#boxs.filesystem.FileSystemStorage.set_run_name","text":"Set the name of a run. The name can be updated and removed by providing None . Args; box_id (str): box_id of the box in which the run is stored. run_id (str): Run id of the run which should be named. name (Optional[str]): New name of the run. If None , an existing name will be removed. Returns: Type Description box.storage.Run The run with its new name. Source code in boxs/filesystem.py def set_run_name ( self , box_id , run_id , name ): logger . debug ( \"Set name of run %s in box %s to %s \" , run_id , box_id , name ) box_directory = self . _box_directory_path ( box_id ) if not box_directory . exists (): raise BoxNotFound ( box_id ) run_directory = self . _run_directory_path ( box_id , run_id ) if not run_directory . exists (): raise RunNotFound ( box_id , run_id ) run_path = self . _run_directory_path ( box_id , run_id ) self . _remove_name_for_run ( box_id , run_id ) if name is not None : self . _set_name_for_run_path ( box_id , name , run_path ) run = self . _create_run_from_run_path ( box_id , run_path ) return run","title":"set_run_name()"},{"location":"api/#boxs.graph","text":"Functions for creating dependency graphs","title":"graph"},{"location":"api/#boxs.graph.write_graph_of_refs","text":"Write the dependency graph in DOT format for the given refs to the writer. Parameters: Name Type Description Default writer io.TextIO A text stream, to which the graph definition will be written. required refs list[boxs.data.DataRef] A list of DataRef instances for which the dependency graph will be created. required Source code in boxs/graph.py def write_graph_of_refs ( writer , refs ): \"\"\" Write the dependency graph in DOT format for the given refs to the writer. Args: writer (io.TextIO): A text stream, to which the graph definition will be written. refs (list[boxs.data.DataRef]): A list of DataRef instances for which the dependency graph will be created. \"\"\" writer . write ( \"digraph { \\n \" ) infos_by_run = collections . defaultdict ( list ) visited = set () queue = collections . deque () queue . extend ( refs ) while queue : ref = queue . popleft () if ref . uri in visited : continue info = ref . info infos_by_run [ ref . run_id ] . append ( info ) for parent in info . parents : queue . appendleft ( parent ) visited . add ( ref . uri ) for run_id , infos in infos_by_run . items (): writer . write ( f ' subgraph \"cluster_ { run_id } \" {{\\n ' ) writer . write ( f ' label=\"Run { run_id } \"; \\n ' ) _write_nodes_for_infos ( infos , writer ) writer . write ( \" } \\n \" ) for run_id , infos in infos_by_run . items (): _write_edges_to_parents_for_infos ( infos , writer ) writer . write ( \"} \\n \" )","title":"write_graph_of_refs()"},{"location":"api/#boxs.io","text":"Functions for I/O of data","title":"io"},{"location":"api/#boxs.io.DelegatingStream","text":"Stream that delegates to another stream. Source code in boxs/io.py class DelegatingStream ( io . RawIOBase ): \"\"\"Stream that delegates to another stream.\"\"\" def __init__ ( self , delegate ): \"\"\" Creates a new DelegatingStream. Args: delegate (io.RawIOBase): The delegate stream. \"\"\" self . delegate = delegate super () . __init__ () def close ( self ): self . delegate . close () @property def closed ( self ): \"\"\"Property that returns if a stream is closed.\"\"\" return self . delegate . closed def flush ( self ): self . delegate . flush () def seek ( self , offset , whence = io . SEEK_SET ): return self . delegate . seek ( offset , whence ) def seekable ( self ): return self . delegate . seekable () def tell ( self ): return self . delegate . tell () def truncate ( self , size = None ): return self . delegate . truncate ( size ) def writable ( self ): return self . delegate . writable () def readinto ( self , byte_buffer ): return self . delegate . readinto ( byte_buffer ) def write ( self , byte_buffer ): return self . delegate . write ( byte_buffer )","title":"DelegatingStream"},{"location":"api/#boxs.io.DelegatingStream.closed","text":"Property that returns if a stream is closed.","title":"closed"},{"location":"api/#boxs.io.DelegatingStream.__init__","text":"Creates a new DelegatingStream. Parameters: Name Type Description Default delegate io.RawIOBase The delegate stream. required Source code in boxs/io.py def __init__ ( self , delegate ): \"\"\" Creates a new DelegatingStream. Args: delegate (io.RawIOBase): The delegate stream. \"\"\" self . delegate = delegate super () . __init__ ()","title":"__init__()"},{"location":"api/#boxs.io.DelegatingStream.close","text":"Flush and close the IO object. This method has no effect if the file is already closed. Source code in boxs/io.py def close ( self ): self . delegate . close ()","title":"close()"},{"location":"api/#boxs.io.DelegatingStream.flush","text":"Flush write buffers, if applicable. This is not implemented for read-only and non-blocking streams. Source code in boxs/io.py def flush ( self ): self . delegate . flush ()","title":"flush()"},{"location":"api/#boxs.io.DelegatingStream.seek","text":"Change stream position. Change the stream position to the given byte offset. The offset is interpreted relative to the position indicated by whence. Values for whence are: 0 -- start of stream (the default); offset should be zero or positive 1 -- current stream position; offset may be negative 2 -- end of stream; offset is usually negative Return the new absolute position. Source code in boxs/io.py def seek ( self , offset , whence = io . SEEK_SET ): return self . delegate . seek ( offset , whence )","title":"seek()"},{"location":"api/#boxs.io.DelegatingStream.seekable","text":"Return whether object supports random access. If False, seek(), tell() and truncate() will raise OSError. This method may need to do a test seek(). Source code in boxs/io.py def seekable ( self ): return self . delegate . seekable ()","title":"seekable()"},{"location":"api/#boxs.io.DelegatingStream.tell","text":"Return current stream position. Source code in boxs/io.py def tell ( self ): return self . delegate . tell ()","title":"tell()"},{"location":"api/#boxs.io.DelegatingStream.truncate","text":"Truncate file to size bytes. File pointer is left unchanged. Size defaults to the current IO position as reported by tell(). Returns the new size. Source code in boxs/io.py def truncate ( self , size = None ): return self . delegate . truncate ( size )","title":"truncate()"},{"location":"api/#boxs.io.DelegatingStream.writable","text":"Return whether object was opened for writing. If False, write() will raise OSError. Source code in boxs/io.py def writable ( self ): return self . delegate . writable ()","title":"writable()"},{"location":"api/#boxs.origin","text":"Origins of data","title":"origin"},{"location":"api/#boxs.origin.ORIGIN_FROM_FUNCTION_NAME","text":"OriginMappingFunction that uses the function_name as origin.","title":"ORIGIN_FROM_FUNCTION_NAME"},{"location":"api/#boxs.origin.ORIGIN_FROM_NAME","text":"OriginMappingFunction that uses the name as origin.","title":"ORIGIN_FROM_NAME"},{"location":"api/#boxs.origin.ORIGIN_FROM_TAGS","text":"OriginMappingFunction that uses the tags in JSON format as origin.","title":"ORIGIN_FROM_TAGS"},{"location":"api/#boxs.origin.OriginMappingFunction","text":"A function that takes a OriginContext and returns the origin as string. Parameters: Name Type Description Default context boxs.origin.OriginContext The context from which to derive the origin. required Returns: Type Description str The origin.","title":"OriginMappingFunction"},{"location":"api/#boxs.origin.OriginContext","text":"Context from which an origin mapping function can derive the origin. Attributes: Name Type Description function_name str The name of the function that called. arg_info inspect.ArgInfo A data structure that contains the arguments of the function which called. name str The name that was given to store() . tags Dict[str,str] The tags this item will be assigned to. Source code in boxs/origin.py class OriginContext : \"\"\" Context from which an origin mapping function can derive the origin. Attributes: function_name (str): The name of the function that called. arg_info (inspect.ArgInfo): A data structure that contains the arguments of the function which called. name (str): The name that was given to `store()`. tags (Dict[str,str]): The tags this item will be assigned to. \"\"\" def __init__ ( self , name , tags , level = 2 ): frame = inspect . currentframe () for _ in range ( level ): frame = frame . f_back self . function_name = frame . f_code . co_name self . arg_info = inspect . getargvalues ( frame ) self . name = name self . tags = tags","title":"OriginContext"},{"location":"api/#boxs.origin.determine_origin","text":"Determine an origin. If the given origin is a callable, we run it and take its return value as new origin. Parameters: Name Type Description Default origin Union[str, OriginMappingFunction, Callable[[],str]] A string or a callable that returns a string. The callable can either have no arguments or a single argument of type boxs.origin.OriginContext . required name str Name that will be available in the OriginContext if needed. None tags Dict[str,str] Tags that will be available in the context if needed. None level int The levels on the stack that we should go back. Defaults to 2 which selects the calling frame of determine_origin(). 2 Returns: Type Description str The origin as string. Source code in boxs/origin.py def determine_origin ( origin , name = None , tags = None , level = 2 ): \"\"\" Determine an origin. If the given origin is a callable, we run it and take its return value as new origin. Args: origin (Union[str, OriginMappingFunction, Callable[[],str]]): A string or a callable that returns a string. The callable can either have no arguments or a single argument of type `boxs.origin.OriginContext`. name (str): Name that will be available in the OriginContext if needed. tags (Dict[str,str]): Tags that will be available in the context if needed. level (int): The levels on the stack that we should go back. Defaults to 2 which selects the calling frame of determine_origin(). Returns: str: The origin as string. \"\"\" if callable ( origin ): if inspect . signature ( origin ) . parameters : context = OriginContext ( name , tags , level = level ) origin = origin ( context ) else : origin = origin () if origin is None : raise ValueError ( \"No origin given (is 'None').\" ) return origin","title":"determine_origin()"},{"location":"api/#boxs.pandas","text":"Value type definitions for pandas specific classes","title":"pandas"},{"location":"api/#boxs.pandas.PandasDataFrameCsvValueType","text":"A value type for storing and loading pandas DataFrame. Source code in boxs/pandas.py class PandasDataFrameCsvValueType ( StringValueType ): \"\"\" A value type for storing and loading pandas DataFrame. \"\"\" def supports ( self , value ): return isinstance ( value , pandas . DataFrame ) def write_value_to_writer ( self , value , writer ): with writer . as_stream () as stream , io . TextIOWrapper ( stream , encoding = self . _default_encoding ) as text_writer : value . to_csv ( text_writer ) writer . meta [ 'encoding' ] = self . _default_encoding def read_value_from_reader ( self , reader ): encoding = reader . meta . get ( 'encoding' , self . _default_encoding ) with reader . as_stream () as stream : text_stream = codecs . getreader ( encoding )( stream ) setattr ( text_stream , 'mode' , 'r' ) result = pandas . read_csv ( text_stream , encoding = encoding ) return result","title":"PandasDataFrameCsvValueType"},{"location":"api/#boxs.pandas.PandasDataFrameCsvValueType.read_value_from_reader","text":"Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/pandas.py def read_value_from_reader ( self , reader ): encoding = reader . meta . get ( 'encoding' , self . _default_encoding ) with reader . as_stream () as stream : text_stream = codecs . getreader ( encoding )( stream ) setattr ( text_stream , 'mode' , 'r' ) result = pandas . read_csv ( text_stream , encoding = encoding ) return result","title":"read_value_from_reader()"},{"location":"api/#boxs.pandas.PandasDataFrameCsvValueType.supports","text":"Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/pandas.py def supports ( self , value ): return isinstance ( value , pandas . DataFrame )","title":"supports()"},{"location":"api/#boxs.pandas.PandasDataFrameCsvValueType.write_value_to_writer","text":"Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/pandas.py def write_value_to_writer ( self , value , writer ): with writer . as_stream () as stream , io . TextIOWrapper ( stream , encoding = self . _default_encoding ) as text_writer : value . to_csv ( text_writer ) writer . meta [ 'encoding' ] = self . _default_encoding","title":"write_value_to_writer()"},{"location":"api/#boxs.run","text":"Functions for managing the run id.","title":"run"},{"location":"api/#boxs.run.get_run_id","text":"Returns the run id. The run id is a unique identifier that is specific to an individual run of a workflow. It stays the same across all task executions and can be used for tracking metrics and differentiating between different runs of the same workflow where task_id and run_id stay the same. Returns: Type Description str The unique run id. Source code in boxs/run.py def get_run_id (): \"\"\" Returns the run id. The run id is a unique identifier that is specific to an individual run of a workflow. It stays the same across all task executions and can be used for tracking metrics and differentiating between different runs of the same workflow where task_id and run_id stay the same. Returns: str: The unique run id. \"\"\" if _RUN_ID is None : set_run_id ( str ( uuid . uuid1 ())) return _RUN_ID","title":"get_run_id()"},{"location":"api/#boxs.run.set_run_id","text":"Sets the run id. Setting the run id explicitly is usually not necessary. The function is mainly used when task executions are run in a different process to make sure the run id is consistent with the spawning process, but it can be used e.g. if an external system provides a unique identifier for a specific workflow run. When set_run_id(run_id) is being used, it must be run before the first tasks are actually defined. Exceptions: Type Description RuntimeError If the run id was already set before. Source code in boxs/run.py def set_run_id ( run_id ): \"\"\" Sets the run id. Setting the run id explicitly is usually not necessary. The function is mainly used when task executions are run in a different process to make sure the run id is consistent with the spawning process, but it can be used e.g. if an external system provides a unique identifier for a specific workflow run. When `set_run_id(run_id)` is being used, it must be run before the first tasks are actually defined. Raises: RuntimeError: If the run id was already set before. \"\"\" global _RUN_ID # pylint: disable=global-statement if _RUN_ID is not None : logger . error ( \"run_id already set to %s when trying to set again\" , _RUN_ID ) raise RuntimeError ( \"Run ID was already set\" ) logger . info ( \"Set run_id to %s \" , run_id ) _RUN_ID = run_id","title":"set_run_id()"},{"location":"api/#boxs.statistics","text":"Collecting statistics about data","title":"statistics"},{"location":"api/#boxs.statistics.StatisticsTransformer","text":"Transformer that collects statistics about data items. This transformer gathers statistics like size of the data, number of lines in the data or time when it was stored and adds those as additional values in the data's meta-data. The following meta-data values are set: 'size_in_bytes' as int 'number_of_lines' as int 'store_start' Timestamp in ISO-format when the storing of the data started. 'store_end' Timestamp in ISO-format when the storing of the data finished. Source code in boxs/statistics.py class StatisticsTransformer ( Transformer ): \"\"\" Transformer that collects statistics about data items. This transformer gathers statistics like size of the data, number of lines in the data or time when it was stored and adds those as additional values in the data's meta-data. The following meta-data values are set: - 'size_in_bytes' as int - 'number_of_lines' as int - 'store_start' Timestamp in ISO-format when the storing of the data started. - 'store_end' Timestamp in ISO-format when the storing of the data finished. \"\"\" def transform_writer ( self , writer ): return _StatisticsWriter ( writer )","title":"StatisticsTransformer"},{"location":"api/#boxs.statistics.StatisticsTransformer.transform_writer","text":"Transform a given writer. Parameters: Name Type Description Default writer boxs.storage.Writer Writer object that is used for writing new data content and meta-data. required Returns: Type Description boxs.storage.Writer A modified writer that will be used instead. Source code in boxs/statistics.py def transform_writer ( self , writer ): return _StatisticsWriter ( writer )","title":"transform_writer()"},{"location":"api/#boxs.storage","text":"Interface to backend storage","title":"storage"},{"location":"api/#boxs.storage.Item","text":"A class representing a data item. Source code in boxs/storage.py class Item ( collections . namedtuple ( 'Item' , 'box_id data_id run_id name time' )): \"\"\" A class representing a data item. \"\"\" __slots__ = () def __str__ ( self ): return f \"Item(boxs:// { self . box_id } / { self . data_id } / { self . run_id } )\"","title":"Item"},{"location":"api/#boxs.storage.ItemQuery","text":"Query object that allows to query a Storage for items. The query is build from a string with up to 3 components separated by ':'. The individual components are the : : . A query doesn't have to contain all components, but it needs to contain at least one with its trailing ':'. All components are treated as prefixes, so one doesn't have to write the full ids. Examples:","title":"ItemQuery"},{"location":"api/#boxs.storage.ItemQuery--query-all-items-in-a-specific-run","text":">>> ItemQuery ( 'my-run-id' ) # or with written separators >>> ItemQuery ( '::my-run-id' )","title":"Query all items in a specific run"},{"location":"api/#boxs.storage.ItemQuery--query-all-items-with-the-same-data-id-in-all-runs","text":">>> ItemQuery ( 'my-data-id:' )","title":"Query all items with the same data-id in all runs"},{"location":"api/#boxs.storage.ItemQuery--query-all-items-with-the-same-data-id-in-specific-runs-with-a-shared-prefix","text":">>> ItemQuery ( 'my-data-id:my-run' ) # for multiple runs like e.g. my-run-1 and my-run-2","title":"Query all items with the same data-id in specific runs with a shared prefix"},{"location":"api/#boxs.storage.ItemQuery--query-everything-in-a-specific-box","text":">>> ItemQuery ( 'box-id::' ) Attributes: Name Type Description box Optional[str] The optional box id. data Optional[str] The optional prefix for data ids or names. run Optional[str] The optional prefix for run ids or names. Source code in boxs/storage.py class ItemQuery : \"\"\" Query object that allows to query a Storage for items. The query is build from a string with up to 3 components separated by ':'. The individual components are the <box-id>:<data-id>:<run-id>. A query doesn't have to contain all components, but it needs to contain at least one with its trailing ':'. All components are treated as prefixes, so one doesn't have to write the full ids. Examples: # Query all items in a specific run >>> ItemQuery('my-run-id') # or with written separators >>> ItemQuery('::my-run-id') # Query all items with the same data-id in all runs >>> ItemQuery('my-data-id:') # Query all items with the same data-id in specific runs with a shared prefix >>> ItemQuery('my-data-id:my-run') # for multiple runs like e.g. my-run-1 and my-run-2 # Query everything in a specific box: >>> ItemQuery('box-id::') Attributes: box (Optional[str]): The optional box id. data (Optional[str]): The optional prefix for data ids or names. run (Optional[str]): The optional prefix for run ids or names. \"\"\" def __init__ ( self , string ): parts = list ( reversed ( string . strip () . rsplit ( ':' ))) self . run = parts [ 0 ] or None if len ( parts ) > 1 : self . data = parts [ 1 ] or None else : self . data = None if len ( parts ) > 2 : self . box = parts [ 2 ] or None else : self . box = None if len ( parts ) > 3 : raise ValueError ( \"Invalid query, must be in format '<box>:<data>:<run>'.\" ) if self . run is None and self . data is None and self . box is None : raise ValueError ( \"Neither, box, data or run is specified.\" ) @classmethod def from_fields ( cls , box = None , data = None , run = None ): \"\"\" Create an ItemQuery from the individual fields of the query. Args: box (Optional[str]): The search string for boxes. Defaults to `None` matching all boxes. data (Optional[str]): The search string for data items. Defaults to `None` matching all data items. run (Optional[str]): The search string for run. Defaults to `None` matching all runs. Returns: ItemQuery: The new item query with the given search fields. \"\"\" return ItemQuery ( ':' . join ([ box or '' , data or '' , run or '' ])) def __str__ ( self ): return ':' . join ([ self . box or '' , self . data or '' , self . run or '' ])","title":"Query everything in a specific box:"},{"location":"api/#boxs.storage.ItemQuery.from_fields","text":"Create an ItemQuery from the individual fields of the query. Parameters: Name Type Description Default box Optional[str] The search string for boxes. Defaults to None matching all boxes. None data Optional[str] The search string for data items. Defaults to None matching all data items. None run Optional[str] The search string for run. Defaults to None matching all runs. None Returns: Type Description ItemQuery The new item query with the given search fields. Source code in boxs/storage.py @classmethod def from_fields ( cls , box = None , data = None , run = None ): \"\"\" Create an ItemQuery from the individual fields of the query. Args: box (Optional[str]): The search string for boxes. Defaults to `None` matching all boxes. data (Optional[str]): The search string for data items. Defaults to `None` matching all data items. run (Optional[str]): The search string for run. Defaults to `None` matching all runs. Returns: ItemQuery: The new item query with the given search fields. \"\"\" return ItemQuery ( ':' . join ([ box or '' , data or '' , run or '' ]))","title":"from_fields()"},{"location":"api/#boxs.storage.Reader","text":"Base class for the storage specific reader implementations. Source code in boxs/storage.py class Reader ( abc . ABC ): \"\"\" Base class for the storage specific reader implementations. \"\"\" def __init__ ( self , item ): \"\"\" Creates a `Reader` instance, that allows to load existing data. Args: item (boxs.storage.Item): The `item` with the data that should be loaded. \"\"\" self . _item = item @property def item ( self ): \"\"\"The item of the data that this reader can read.\"\"\" return self . _item def read_value ( self , value_type ): \"\"\" Read the value and return it. Args: value_type (boxs.value_types.ValueType): The value type that reads the value from the reader and converts it to the correct type. Returns: Any: The returned value from the `value_type`. \"\"\" return value_type . read_value_from_reader ( self ) @property @abc . abstractmethod def info ( self ): \"\"\"Dictionary containing information about the data.\"\"\" @property def meta ( self ): \"\"\"Dictionary containing the meta-data about the data.\"\"\" return self . info [ 'meta' ] @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream from which the data content can be read. Returns: io.RawIOBase: A stream instance from which the data can be read. \"\"\"","title":"Reader"},{"location":"api/#boxs.storage.Reader.info","text":"Dictionary containing information about the data.","title":"info"},{"location":"api/#boxs.storage.Reader.item","text":"The item of the data that this reader can read.","title":"item"},{"location":"api/#boxs.storage.Reader.meta","text":"Dictionary containing the meta-data about the data.","title":"meta"},{"location":"api/#boxs.storage.Reader.__init__","text":"Creates a Reader instance, that allows to load existing data. Parameters: Name Type Description Default item boxs.storage.Item The item with the data that should be loaded. required Source code in boxs/storage.py def __init__ ( self , item ): \"\"\" Creates a `Reader` instance, that allows to load existing data. Args: item (boxs.storage.Item): The `item` with the data that should be loaded. \"\"\" self . _item = item","title":"__init__()"},{"location":"api/#boxs.storage.Reader.as_stream","text":"Return a stream from which the data content can be read. Returns: Type Description io.RawIOBase A stream instance from which the data can be read. Source code in boxs/storage.py @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream from which the data content can be read. Returns: io.RawIOBase: A stream instance from which the data can be read. \"\"\"","title":"as_stream()"},{"location":"api/#boxs.storage.Reader.read_value","text":"Read the value and return it. Parameters: Name Type Description Default value_type boxs.value_types.ValueType The value type that reads the value from the reader and converts it to the correct type. required Returns: Type Description Any The returned value from the value_type . Source code in boxs/storage.py def read_value ( self , value_type ): \"\"\" Read the value and return it. Args: value_type (boxs.value_types.ValueType): The value type that reads the value from the reader and converts it to the correct type. Returns: Any: The returned value from the `value_type`. \"\"\" return value_type . read_value_from_reader ( self )","title":"read_value()"},{"location":"api/#boxs.storage.Run","text":"A class representing a run. Source code in boxs/storage.py class Run ( collections . namedtuple ( 'Run' , 'box_id run_id name time' )): \"\"\" A class representing a run. \"\"\" __slots__ = () def __str__ ( self ): return f \"Run( { self . box_id } / { self . run_id } )\" def __eq__ ( self , o ): return ( self . box_id , self . run_id ) == ( o . box_id , o . run_id ) def __hash__ ( self ): return hash (( self . box_id , self . run_id ))","title":"Run"},{"location":"api/#boxs.storage.Storage","text":"Backend that allows a box to store and load data in arbitrary storage locations. This abstract base class defines the interface, that is used by Box to store and load data. The data items between Box and Storage are always identified by their box_id , data_id and run_id . The functionality to store data is provided by the Writer object, that is created by the create_writer() method. Similarly, loading data is implemented in a separate Reader object that is created by create_reader() . Source code in boxs/storage.py class Storage ( abc . ABC ): \"\"\" Backend that allows a box to store and load data in arbitrary storage locations. This abstract base class defines the interface, that is used by `Box` to store and load data. The data items between `Box` and `Storage` are always identified by their `box_id`, `data_id` and `run_id`. The functionality to store data is provided by the `Writer` object, that is created by the `create_writer()` method. Similarly, loading data is implemented in a separate `Reader` object that is created by `create_reader()`. \"\"\" @abc . abstractmethod def create_reader ( self , item ): \"\"\" Creates a `Reader` instance, that allows to load existing data. Args: item (boxs.storage.Item): The item that should be read. Returns: boxs.storage.Reader: The reader that will load the data from the storage. \"\"\" @abc . abstractmethod def create_writer ( self , item , name = None , tags = None ): \"\"\" Creates a `Writer` instance, that allows to store new data. Args: item (boxs.storage.Item): The new data item. name (str): An optional name, that can be used for referring to this item within the run. Defaults to `None`. tags (Dict[str,str]): A dictionary containing tags that can be used for grouping multiple items together. Defaults to an empty dictionary. Returns: boxs.storage.Writer: The writer that will write the data into the storage. \"\"\" @abc . abstractmethod def list_runs ( self , box_id , limit = None , name_filter = None ): \"\"\" List the runs within a box stored in this storage. The runs should be returned in descending order of their start time. Args: box_id (str): `box_id` of the box in which to look for runs. limit (Optional[int]): Limits the returned runs to maximum `limit` number. Defaults to `None` in which case all runs are returned. name_filter (Optional[str]): If set, only include runs which have names that have the filter as prefix. Defaults to `None` in which case all runs are returned. Returns: List[box.storage.Run]: The runs. \"\"\" @abc . abstractmethod def list_items ( self , item_query ): \"\"\" List all items that match a given query. The item query can contain parts of box id, run id or run name and data id or data name. If a query value is not set (`== None`) it is not used as a filter criteria. Args: item_query (boxs.storage.ItemQuery): The query which defines which items should be listed. Returns: List[box.storage.Item]: The runs. \"\"\" @abc . abstractmethod def set_run_name ( self , box_id , run_id , name ): \"\"\" Set the name of a run. The name can be updated and removed by providing `None`. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be named. name (Optional[str]): New name of the run. If `None`, an existing name will be removed. Returns: box.storage.Run: The run with its new name. \"\"\" @abc . abstractmethod def delete_run ( self , box_id , run_id ): \"\"\" Delete all the data of the specified run. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be deleted. \"\"\"","title":"Storage"},{"location":"api/#boxs.storage.Storage.create_reader","text":"Creates a Reader instance, that allows to load existing data. Parameters: Name Type Description Default item boxs.storage.Item The item that should be read. required Returns: Type Description boxs.storage.Reader The reader that will load the data from the storage. Source code in boxs/storage.py @abc . abstractmethod def create_reader ( self , item ): \"\"\" Creates a `Reader` instance, that allows to load existing data. Args: item (boxs.storage.Item): The item that should be read. Returns: boxs.storage.Reader: The reader that will load the data from the storage. \"\"\"","title":"create_reader()"},{"location":"api/#boxs.storage.Storage.create_writer","text":"Creates a Writer instance, that allows to store new data. Parameters: Name Type Description Default item boxs.storage.Item The new data item. required name str An optional name, that can be used for referring to this item within the run. Defaults to None . None tags Dict[str,str] A dictionary containing tags that can be used for grouping multiple items together. Defaults to an empty dictionary. None Returns: Type Description boxs.storage.Writer The writer that will write the data into the storage. Source code in boxs/storage.py @abc . abstractmethod def create_writer ( self , item , name = None , tags = None ): \"\"\" Creates a `Writer` instance, that allows to store new data. Args: item (boxs.storage.Item): The new data item. name (str): An optional name, that can be used for referring to this item within the run. Defaults to `None`. tags (Dict[str,str]): A dictionary containing tags that can be used for grouping multiple items together. Defaults to an empty dictionary. Returns: boxs.storage.Writer: The writer that will write the data into the storage. \"\"\"","title":"create_writer()"},{"location":"api/#boxs.storage.Storage.delete_run","text":"Delete all the data of the specified run. Args; box_id (str): box_id of the box in which the run is stored. run_id (str): Run id of the run which should be deleted. Source code in boxs/storage.py @abc . abstractmethod def delete_run ( self , box_id , run_id ): \"\"\" Delete all the data of the specified run. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be deleted. \"\"\"","title":"delete_run()"},{"location":"api/#boxs.storage.Storage.list_items","text":"List all items that match a given query. The item query can contain parts of box id, run id or run name and data id or data name. If a query value is not set ( == None ) it is not used as a filter criteria. Parameters: Name Type Description Default item_query boxs.storage.ItemQuery The query which defines which items should be listed. required Returns: Type Description List[box.storage.Item] The runs. Source code in boxs/storage.py @abc . abstractmethod def list_items ( self , item_query ): \"\"\" List all items that match a given query. The item query can contain parts of box id, run id or run name and data id or data name. If a query value is not set (`== None`) it is not used as a filter criteria. Args: item_query (boxs.storage.ItemQuery): The query which defines which items should be listed. Returns: List[box.storage.Item]: The runs. \"\"\"","title":"list_items()"},{"location":"api/#boxs.storage.Storage.list_runs","text":"List the runs within a box stored in this storage. The runs should be returned in descending order of their start time. Parameters: Name Type Description Default box_id str box_id of the box in which to look for runs. required limit Optional[int] Limits the returned runs to maximum limit number. Defaults to None in which case all runs are returned. None name_filter Optional[str] If set, only include runs which have names that have the filter as prefix. Defaults to None in which case all runs are returned. None Returns: Type Description List[box.storage.Run] The runs. Source code in boxs/storage.py @abc . abstractmethod def list_runs ( self , box_id , limit = None , name_filter = None ): \"\"\" List the runs within a box stored in this storage. The runs should be returned in descending order of their start time. Args: box_id (str): `box_id` of the box in which to look for runs. limit (Optional[int]): Limits the returned runs to maximum `limit` number. Defaults to `None` in which case all runs are returned. name_filter (Optional[str]): If set, only include runs which have names that have the filter as prefix. Defaults to `None` in which case all runs are returned. Returns: List[box.storage.Run]: The runs. \"\"\"","title":"list_runs()"},{"location":"api/#boxs.storage.Storage.set_run_name","text":"Set the name of a run. The name can be updated and removed by providing None . Args; box_id (str): box_id of the box in which the run is stored. run_id (str): Run id of the run which should be named. name (Optional[str]): New name of the run. If None , an existing name will be removed. Returns: Type Description box.storage.Run The run with its new name. Source code in boxs/storage.py @abc . abstractmethod def set_run_name ( self , box_id , run_id , name ): \"\"\" Set the name of a run. The name can be updated and removed by providing `None`. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be named. name (Optional[str]): New name of the run. If `None`, an existing name will be removed. Returns: box.storage.Run: The run with its new name. \"\"\"","title":"set_run_name()"},{"location":"api/#boxs.storage.Writer","text":"Base class for the storage specific writer implementations. Source code in boxs/storage.py class Writer ( abc . ABC ): \"\"\" Base class for the storage specific writer implementations. \"\"\" def __init__ ( self , item , name , tags ): \"\"\" Creates a `Writer` instance, that allows to store new data. Args: item (boxs.storage.Item): The new item. \"\"\" self . _item = item self . _name = name self . _tags = tags self . _meta = {} @property def item ( self ): \"\"\"Returns the item which this writer writes to.\"\"\" return self . _item @property def name ( self ): \"\"\"Returns the name of the new data item.\"\"\" return self . _name @property def tags ( self ): \"\"\"Returns the tags of the new data item.\"\"\" return self . _tags @property def meta ( self ): \"\"\" Returns a dictionary which contains meta-data of the item. This allows either ValueTypes or Transformers to add additional meta-data for the data item. \"\"\" return self . _meta def write_value ( self , value , value_type ): \"\"\" Write the data content to the storage. Args: value (Any): The value that should be written to the writer. value_type (boxs.value_types.ValueType): The value type that takes care of actually writing the value and converting it to the correct type. \"\"\" value_type . write_value_to_writer ( value , self ) @abc . abstractmethod def write_info ( self , info ): \"\"\" Write the info for the data item to the storage. Args: info (Dict[str,Any]): The information about the new data item. Raises: boxs.errors.DataCollision: If a data item with the same ids already exists. \"\"\" @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream to which the data content should be written. This method can be used by the ValueType to actually transfer the data. Returns: io.RawIOBase: The binary io-stream. Raises: boxs.errors.DataCollision: If a data item with the same ids already exists. \"\"\"","title":"Writer"},{"location":"api/#boxs.storage.Writer.item","text":"Returns the item which this writer writes to.","title":"item"},{"location":"api/#boxs.storage.Writer.meta","text":"Returns a dictionary which contains meta-data of the item. This allows either ValueTypes or Transformers to add additional meta-data for the data item.","title":"meta"},{"location":"api/#boxs.storage.Writer.name","text":"Returns the name of the new data item.","title":"name"},{"location":"api/#boxs.storage.Writer.tags","text":"Returns the tags of the new data item.","title":"tags"},{"location":"api/#boxs.storage.Writer.__init__","text":"Creates a Writer instance, that allows to store new data. Parameters: Name Type Description Default item boxs.storage.Item The new item. required Source code in boxs/storage.py def __init__ ( self , item , name , tags ): \"\"\" Creates a `Writer` instance, that allows to store new data. Args: item (boxs.storage.Item): The new item. \"\"\" self . _item = item self . _name = name self . _tags = tags self . _meta = {}","title":"__init__()"},{"location":"api/#boxs.storage.Writer.as_stream","text":"Return a stream to which the data content should be written. This method can be used by the ValueType to actually transfer the data. Returns: Type Description io.RawIOBase The binary io-stream. Exceptions: Type Description boxs.errors.DataCollision If a data item with the same ids already exists. Source code in boxs/storage.py @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream to which the data content should be written. This method can be used by the ValueType to actually transfer the data. Returns: io.RawIOBase: The binary io-stream. Raises: boxs.errors.DataCollision: If a data item with the same ids already exists. \"\"\"","title":"as_stream()"},{"location":"api/#boxs.storage.Writer.write_info","text":"Write the info for the data item to the storage. Parameters: Name Type Description Default info Dict[str,Any] The information about the new data item. required Exceptions: Type Description boxs.errors.DataCollision If a data item with the same ids already exists. Source code in boxs/storage.py @abc . abstractmethod def write_info ( self , info ): \"\"\" Write the info for the data item to the storage. Args: info (Dict[str,Any]): The information about the new data item. Raises: boxs.errors.DataCollision: If a data item with the same ids already exists. \"\"\"","title":"write_info()"},{"location":"api/#boxs.storage.Writer.write_value","text":"Write the data content to the storage. Parameters: Name Type Description Default value Any The value that should be written to the writer. required value_type boxs.value_types.ValueType The value type that takes care of actually writing the value and converting it to the correct type. required Source code in boxs/storage.py def write_value ( self , value , value_type ): \"\"\" Write the data content to the storage. Args: value (Any): The value that should be written to the writer. value_type (boxs.value_types.ValueType): The value type that takes care of actually writing the value and converting it to the correct type. \"\"\" value_type . write_value_to_writer ( value , self )","title":"write_value()"},{"location":"api/#boxs.tensorflow","text":"Value type definitions for storing tensorflow specific classes","title":"tensorflow"},{"location":"api/#boxs.tensorflow.TensorBoardLogDirValueType","text":"Value type for storing tensorbord logs. The necessary tensorflow functions for saving and loading the model to a directory are dynamically loaded, so that the module can be imported WITHOUT tensorflow. Only if one instantiates an instance of the class, the tensorflow package must be available. Source code in boxs/tensorflow.py class TensorBoardLogDirValueType ( DirectoryValueType ): \"\"\" Value type for storing tensorbord logs. The necessary tensorflow functions for saving and loading the model to a directory are dynamically loaded, so that the module can be imported WITHOUT tensorflow. Only if one instantiates an instance of the class, the tensorflow package must be available. \"\"\" def write_value_to_writer ( self , value , writer ): super () . write_value_to_writer ( pathlib . Path ( value ), writer ) writer . meta [ 'dir_content' ] = 'tensorboard-logs'","title":"TensorBoardLogDirValueType"},{"location":"api/#boxs.tensorflow.TensorBoardLogDirValueType.write_value_to_writer","text":"Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/tensorflow.py def write_value_to_writer ( self , value , writer ): super () . write_value_to_writer ( pathlib . Path ( value ), writer ) writer . meta [ 'dir_content' ] = 'tensorboard-logs'","title":"write_value_to_writer()"},{"location":"api/#boxs.tensorflow.TensorflowKerasModelValueType","text":"Value type for storing tensorflow keras models. The necessary tensorflow functions for saving and loading the model to a directory are dynamically loaded, so that the module can be imported WITHOUT tensorflow. Only if one instantiates an instance of the class, the tensorflow package must be available. Source code in boxs/tensorflow.py class TensorflowKerasModelValueType ( DirectoryValueType ): \"\"\" Value type for storing tensorflow keras models. The necessary tensorflow functions for saving and loading the model to a directory are dynamically loaded, so that the module can be imported WITHOUT tensorflow. Only if one instantiates an instance of the class, the tensorflow package must be available. \"\"\" def __init__ ( self , dir_path = None , default_format = 'tf' ): self . _tf_models_module = importlib . import_module ( 'tensorflow.keras.models' ) self . _default_format = default_format super () . __init__ ( dir_path ) def supports ( self , value ): return False def write_value_to_writer ( self , value , writer ): model_dir_path = pathlib . Path ( tempfile . mkdtemp ()) try : self . _tf_models_module . save_model ( value , filepath = model_dir_path , save_format = self . _default_format ) super () . write_value_to_writer ( model_dir_path , writer ) writer . meta [ 'model_format' ] = self . _default_format finally : shutil . rmtree ( model_dir_path ) def read_value_from_reader ( self , reader ): model_dir_path = super () . read_value_from_reader ( reader ) try : result = self . _tf_models_module . load_model ( filepath = model_dir_path ) finally : if self . _dir_path is None : shutil . rmtree ( model_dir_path ) return result def _get_parameter_string ( self ): return self . _default_format @classmethod def _from_parameter_string ( cls , parameters ): return cls ( default_format = parameters )","title":"TensorflowKerasModelValueType"},{"location":"api/#boxs.tensorflow.TensorflowKerasModelValueType.read_value_from_reader","text":"Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/tensorflow.py def read_value_from_reader ( self , reader ): model_dir_path = super () . read_value_from_reader ( reader ) try : result = self . _tf_models_module . load_model ( filepath = model_dir_path ) finally : if self . _dir_path is None : shutil . rmtree ( model_dir_path ) return result","title":"read_value_from_reader()"},{"location":"api/#boxs.tensorflow.TensorflowKerasModelValueType.supports","text":"Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/tensorflow.py def supports ( self , value ): return False","title":"supports()"},{"location":"api/#boxs.tensorflow.TensorflowKerasModelValueType.write_value_to_writer","text":"Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/tensorflow.py def write_value_to_writer ( self , value , writer ): model_dir_path = pathlib . Path ( tempfile . mkdtemp ()) try : self . _tf_models_module . save_model ( value , filepath = model_dir_path , save_format = self . _default_format ) super () . write_value_to_writer ( model_dir_path , writer ) writer . meta [ 'model_format' ] = self . _default_format finally : shutil . rmtree ( model_dir_path )","title":"write_value_to_writer()"},{"location":"api/#boxs.transform","text":"Transforming data items","title":"transform"},{"location":"api/#boxs.transform.DelegatingReader","text":"Reader class that delegates all calls to a wrapped reader. Source code in boxs/transform.py class DelegatingReader ( Reader ): \"\"\" Reader class that delegates all calls to a wrapped reader. \"\"\" def __init__ ( self , delegate ): \"\"\" Create a new DelegatingReader. Args: delegate (boxs.storage.Reader): The reader to which all calls are delegated. \"\"\" super () . __init__ ( delegate . item ) self . delegate = delegate @property def info ( self ): return self . delegate . info @property def meta ( self ): return self . delegate . meta def read_value ( self , value_type ): return self . delegate . read_value ( value_type ) def as_stream ( self ): return self . delegate . as_stream ()","title":"DelegatingReader"},{"location":"api/#boxs.transform.DelegatingReader.info","text":"Dictionary containing information about the data.","title":"info"},{"location":"api/#boxs.transform.DelegatingReader.meta","text":"Dictionary containing the meta-data about the data.","title":"meta"},{"location":"api/#boxs.transform.DelegatingReader.__init__","text":"Create a new DelegatingReader. Parameters: Name Type Description Default delegate boxs.storage.Reader The reader to which all calls are delegated. required Source code in boxs/transform.py def __init__ ( self , delegate ): \"\"\" Create a new DelegatingReader. Args: delegate (boxs.storage.Reader): The reader to which all calls are delegated. \"\"\" super () . __init__ ( delegate . item ) self . delegate = delegate","title":"__init__()"},{"location":"api/#boxs.transform.DelegatingReader.as_stream","text":"Return a stream from which the data content can be read. Returns: Type Description io.RawIOBase A stream instance from which the data can be read. Source code in boxs/transform.py def as_stream ( self ): return self . delegate . as_stream ()","title":"as_stream()"},{"location":"api/#boxs.transform.DelegatingReader.read_value","text":"Read the value and return it. Parameters: Name Type Description Default value_type boxs.value_types.ValueType The value type that reads the value from the reader and converts it to the correct type. required Returns: Type Description Any The returned value from the value_type . Source code in boxs/transform.py def read_value ( self , value_type ): return self . delegate . read_value ( value_type )","title":"read_value()"},{"location":"api/#boxs.transform.DelegatingWriter","text":"Writer that delegates all call to a wrapped writer. Source code in boxs/transform.py class DelegatingWriter ( Writer ): \"\"\" Writer that delegates all call to a wrapped writer. \"\"\" def __init__ ( self , delegate ): self . delegate = delegate super () . __init__ ( delegate . item , delegate . name , delegate . tags ) @property def meta ( self ): return self . delegate . meta def write_value ( self , value , value_type ): self . delegate . write_value ( value , value_type ) def write_info ( self , info ): return self . delegate . write_info ( info ) def as_stream ( self ): return self . delegate . as_stream ()","title":"DelegatingWriter"},{"location":"api/#boxs.transform.DelegatingWriter.meta","text":"Returns a dictionary which contains meta-data of the item. This allows either ValueTypes or Transformers to add additional meta-data for the data item.","title":"meta"},{"location":"api/#boxs.transform.DelegatingWriter.as_stream","text":"Return a stream to which the data content should be written. This method can be used by the ValueType to actually transfer the data. Returns: Type Description io.RawIOBase The binary io-stream. Exceptions: Type Description boxs.errors.DataCollision If a data item with the same ids already exists. Source code in boxs/transform.py def as_stream ( self ): return self . delegate . as_stream ()","title":"as_stream()"},{"location":"api/#boxs.transform.DelegatingWriter.write_info","text":"Write the info for the data item to the storage. Parameters: Name Type Description Default info Dict[str,Any] The information about the new data item. required Exceptions: Type Description boxs.errors.DataCollision If a data item with the same ids already exists. Source code in boxs/transform.py def write_info ( self , info ): return self . delegate . write_info ( info )","title":"write_info()"},{"location":"api/#boxs.transform.DelegatingWriter.write_value","text":"Write the data content to the storage. Parameters: Name Type Description Default value Any The value that should be written to the writer. required value_type boxs.value_types.ValueType The value type that takes care of actually writing the value and converting it to the correct type. required Source code in boxs/transform.py def write_value ( self , value , value_type ): self . delegate . write_value ( value , value_type )","title":"write_value()"},{"location":"api/#boxs.transform.Transformer","text":"Base class for transformers Transformers allow modifying content and meta-data of a DataItem during store and load by wrapping the writer and reader that are used for accessing them from the storage. This can be useful for e.g. adding new meta-data, filtering content or implementing encryption. Source code in boxs/transform.py class Transformer : # pylint: disable=no-self-use \"\"\" Base class for transformers Transformers allow modifying content and meta-data of a DataItem during store and load by wrapping the writer and reader that are used for accessing them from the storage. This can be useful for e.g. adding new meta-data, filtering content or implementing encryption. \"\"\" def transform_writer ( self , writer ): \"\"\" Transform a given writer. Args: writer (boxs.storage.Writer): Writer object that is used for writing new data content and meta-data. Returns: boxs.storage.Writer: A modified writer that will be used instead. \"\"\" return writer def transform_reader ( self , reader ): \"\"\" Transform a given reader. Args: reader (boxs.storage.Reader): Reader object that is used for reading data content and meta-data. Returns: boxs.storage.Reader: A modified reader that will be used instead. \"\"\" return reader","title":"Transformer"},{"location":"api/#boxs.transform.Transformer.transform_reader","text":"Transform a given reader. Parameters: Name Type Description Default reader boxs.storage.Reader Reader object that is used for reading data content and meta-data. required Returns: Type Description boxs.storage.Reader A modified reader that will be used instead. Source code in boxs/transform.py def transform_reader ( self , reader ): \"\"\" Transform a given reader. Args: reader (boxs.storage.Reader): Reader object that is used for reading data content and meta-data. Returns: boxs.storage.Reader: A modified reader that will be used instead. \"\"\" return reader","title":"transform_reader()"},{"location":"api/#boxs.transform.Transformer.transform_writer","text":"Transform a given writer. Parameters: Name Type Description Default writer boxs.storage.Writer Writer object that is used for writing new data content and meta-data. required Returns: Type Description boxs.storage.Writer A modified writer that will be used instead. Source code in boxs/transform.py def transform_writer ( self , writer ): \"\"\" Transform a given writer. Args: writer (boxs.storage.Writer): Writer object that is used for writing new data content and meta-data. Returns: boxs.storage.Writer: A modified writer that will be used instead. \"\"\" return writer","title":"transform_writer()"},{"location":"api/#boxs.value_types","text":"Types for reading and writing of different value types","title":"value_types"},{"location":"api/#boxs.value_types.BytesValueType","text":"A ValueType for reading and writing bytes/bytearray values. Source code in boxs/value_types.py class BytesValueType ( ValueType ): \"\"\" A ValueType for reading and writing bytes/bytearray values. \"\"\" def supports ( self , value ): return isinstance ( value , ( bytes , bytearray )) def write_value_to_writer ( self , value , writer ): source_stream = io . BytesIO ( value ) with writer . as_stream () as destination_stream : shutil . copyfileobj ( source_stream , destination_stream ) def read_value_from_reader ( self , reader ): with reader . as_stream () as stream : return stream . read ()","title":"BytesValueType"},{"location":"api/#boxs.value_types.BytesValueType.read_value_from_reader","text":"Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): with reader . as_stream () as stream : return stream . read ()","title":"read_value_from_reader()"},{"location":"api/#boxs.value_types.BytesValueType.supports","text":"Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , ( bytes , bytearray ))","title":"supports()"},{"location":"api/#boxs.value_types.BytesValueType.write_value_to_writer","text":"Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): source_stream = io . BytesIO ( value ) with writer . as_stream () as destination_stream : shutil . copyfileobj ( source_stream , destination_stream )","title":"write_value_to_writer()"},{"location":"api/#boxs.value_types.DirectoryValueType","text":"A ValueType for reading and writing directories. The values have to be instances of pathlib.Path and must point to an existing directory. Everything within this directory is then added to a new zip archive, that is written to the storage. Source code in boxs/value_types.py class DirectoryValueType ( ValueType ): \"\"\" A ValueType for reading and writing directories. The values have to be instances of `pathlib.Path` and must point to an existing directory. Everything within this directory is then added to a new zip archive, that is written to the storage. \"\"\" def __init__ ( self , dir_path = None ): self . _dir_path = dir_path super () . __init__ () def supports ( self , value ): return isinstance ( value , pathlib . Path ) and value . exists () and value . is_dir () def write_value_to_writer ( self , value , writer ): def _add_directory ( root , directory , _zip_file ): for path in directory . iterdir (): if path . is_file (): _zip_file . write ( path , arcname = path . relative_to ( root )) if path . is_dir (): _add_directory ( root , path , _zip_file ) with writer . as_stream () as destination_stream , zipfile . ZipFile ( destination_stream , mode = 'w' ) as zip_file : _add_directory ( value , value , zip_file ) def read_value_from_reader ( self , reader ): dir_path = self . _dir_path if self . _dir_path is None : dir_path = tempfile . mkdtemp () dir_path = pathlib . Path ( dir_path ) self . _logger . debug ( \"Directory will be stored in %s \" , dir_path ) with reader . as_stream () as read_stream , zipfile . ZipFile ( read_stream , 'r' ) as zip_file : for zip_info in zip_file . infolist (): target_path = dir_path / zip_info . filename self . _logger . debug ( \"Extracting %s to %s \" , zip_info . filename , target_path ) zip_file . extract ( zip_info , target_path ) return dir_path","title":"DirectoryValueType"},{"location":"api/#boxs.value_types.DirectoryValueType.read_value_from_reader","text":"Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): dir_path = self . _dir_path if self . _dir_path is None : dir_path = tempfile . mkdtemp () dir_path = pathlib . Path ( dir_path ) self . _logger . debug ( \"Directory will be stored in %s \" , dir_path ) with reader . as_stream () as read_stream , zipfile . ZipFile ( read_stream , 'r' ) as zip_file : for zip_info in zip_file . infolist (): target_path = dir_path / zip_info . filename self . _logger . debug ( \"Extracting %s to %s \" , zip_info . filename , target_path ) zip_file . extract ( zip_info , target_path ) return dir_path","title":"read_value_from_reader()"},{"location":"api/#boxs.value_types.DirectoryValueType.supports","text":"Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , pathlib . Path ) and value . exists () and value . is_dir ()","title":"supports()"},{"location":"api/#boxs.value_types.DirectoryValueType.write_value_to_writer","text":"Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): def _add_directory ( root , directory , _zip_file ): for path in directory . iterdir (): if path . is_file (): _zip_file . write ( path , arcname = path . relative_to ( root )) if path . is_dir (): _add_directory ( root , path , _zip_file ) with writer . as_stream () as destination_stream , zipfile . ZipFile ( destination_stream , mode = 'w' ) as zip_file : _add_directory ( value , value , zip_file )","title":"write_value_to_writer()"},{"location":"api/#boxs.value_types.FileValueType","text":"A ValueType for reading and writing files. The values have to be instances of pathlib.Path . Source code in boxs/value_types.py class FileValueType ( ValueType ): \"\"\" A ValueType for reading and writing files. The values have to be instances of `pathlib.Path`. \"\"\" def __init__ ( self , file_path = None ): self . _file_path = file_path super () . __init__ () def supports ( self , value ): return isinstance ( value , pathlib . Path ) and value . exists () and value . is_file () def write_value_to_writer ( self , value , writer ): with value . open ( 'rb' ) as file_reader , writer . as_stream () as destination_stream : shutil . copyfileobj ( file_reader , destination_stream ) def read_value_from_reader ( self , reader ): if hasattr ( reader , 'as_file' ): self . _logger . debug ( \"Reader has as_file()\" ) if self . _file_path : self . _logger . debug ( \"Copying file directly\" ) shutil . copyfile ( str ( reader . as_file ()), str ( self . _file_path )) return self . _file_path return reader . as_file () file_path = self . _file_path if self . _file_path is None : file_path = tempfile . mktemp () file_path = pathlib . Path ( file_path ) with reader . as_stream () as read_stream , io . FileIO ( file_path , 'w' ) as file_stream : self . _logger . debug ( \"Writing file from stream\" ) shutil . copyfileobj ( read_stream , file_stream ) return file_path","title":"FileValueType"},{"location":"api/#boxs.value_types.FileValueType.read_value_from_reader","text":"Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): if hasattr ( reader , 'as_file' ): self . _logger . debug ( \"Reader has as_file()\" ) if self . _file_path : self . _logger . debug ( \"Copying file directly\" ) shutil . copyfile ( str ( reader . as_file ()), str ( self . _file_path )) return self . _file_path return reader . as_file () file_path = self . _file_path if self . _file_path is None : file_path = tempfile . mktemp () file_path = pathlib . Path ( file_path ) with reader . as_stream () as read_stream , io . FileIO ( file_path , 'w' ) as file_stream : self . _logger . debug ( \"Writing file from stream\" ) shutil . copyfileobj ( read_stream , file_stream ) return file_path","title":"read_value_from_reader()"},{"location":"api/#boxs.value_types.FileValueType.supports","text":"Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , pathlib . Path ) and value . exists () and value . is_file ()","title":"supports()"},{"location":"api/#boxs.value_types.FileValueType.write_value_to_writer","text":"Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): with value . open ( 'rb' ) as file_reader , writer . as_stream () as destination_stream : shutil . copyfileobj ( file_reader , destination_stream )","title":"write_value_to_writer()"},{"location":"api/#boxs.value_types.JsonValueType","text":"ValueType for storing values as JSON. Source code in boxs/value_types.py class JsonValueType ( ValueType ): \"\"\" ValueType for storing values as JSON. \"\"\" def supports ( self , value ): return isinstance ( value , ( dict , list )) def write_value_to_writer ( self , value , writer ): writer . meta [ 'media_type' ] = 'application/json' with writer . as_stream () as destination_stream , io . TextIOWrapper ( destination_stream ) as text_writer : json . dump ( value , text_writer , sort_keys = True , separators = ( ',' , ':' )) def read_value_from_reader ( self , reader ): with reader . as_stream () as stream : return json . load ( stream )","title":"JsonValueType"},{"location":"api/#boxs.value_types.JsonValueType.read_value_from_reader","text":"Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): with reader . as_stream () as stream : return json . load ( stream )","title":"read_value_from_reader()"},{"location":"api/#boxs.value_types.JsonValueType.supports","text":"Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , ( dict , list ))","title":"supports()"},{"location":"api/#boxs.value_types.JsonValueType.write_value_to_writer","text":"Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): writer . meta [ 'media_type' ] = 'application/json' with writer . as_stream () as destination_stream , io . TextIOWrapper ( destination_stream ) as text_writer : json . dump ( value , text_writer , sort_keys = True , separators = ( ',' , ':' ))","title":"write_value_to_writer()"},{"location":"api/#boxs.value_types.StreamValueType","text":"A ValueType for reading and writing from and to a stream. Source code in boxs/value_types.py class StreamValueType ( ValueType ): \"\"\" A ValueType for reading and writing from and to a stream. \"\"\" def supports ( self , value ): return isinstance ( value , io . IOBase ) def write_value_to_writer ( self , value , writer ): with writer . as_stream () as destination_stream : shutil . copyfileobj ( value , destination_stream ) def read_value_from_reader ( self , reader ): return reader . as_stream ()","title":"StreamValueType"},{"location":"api/#boxs.value_types.StreamValueType.read_value_from_reader","text":"Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): return reader . as_stream ()","title":"read_value_from_reader()"},{"location":"api/#boxs.value_types.StreamValueType.supports","text":"Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , io . IOBase )","title":"supports()"},{"location":"api/#boxs.value_types.StreamValueType.write_value_to_writer","text":"Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): with writer . as_stream () as destination_stream : shutil . copyfileobj ( value , destination_stream )","title":"write_value_to_writer()"},{"location":"api/#boxs.value_types.StringValueType","text":"A ValueType for reading and writing string values. The ValueType can use different encodings via its constructor argument, but defaults to 'utf-8'. Source code in boxs/value_types.py class StringValueType ( ValueType ): \"\"\" A ValueType for reading and writing string values. The ValueType can use different encodings via its constructor argument, but defaults to 'utf-8'. \"\"\" def __init__ ( self , default_encoding = 'utf-8' ): self . _default_encoding = default_encoding super () . __init__ () def supports ( self , value ): return isinstance ( value , str ) def write_value_to_writer ( self , value , writer ): source_stream = io . BytesIO ( value . encode ( self . _default_encoding )) writer . meta [ 'encoding' ] = self . _default_encoding with writer . as_stream () as destination_stream : shutil . copyfileobj ( source_stream , destination_stream ) def read_value_from_reader ( self , reader ): encoding = reader . meta . get ( 'encoding' , self . _default_encoding ) self . _logger . debug ( \"Reading string with encoding %s \" , encoding ) with reader . as_stream () as stream , io . TextIOWrapper ( stream , encoding = encoding ) as text_reader : return text_reader . read () def _get_parameter_string ( self ): return self . _default_encoding @classmethod def _from_parameter_string ( cls , parameters ): return cls ( default_encoding = parameters )","title":"StringValueType"},{"location":"api/#boxs.value_types.StringValueType.read_value_from_reader","text":"Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py def read_value_from_reader ( self , reader ): encoding = reader . meta . get ( 'encoding' , self . _default_encoding ) self . _logger . debug ( \"Reading string with encoding %s \" , encoding ) with reader . as_stream () as stream , io . TextIOWrapper ( stream , encoding = encoding ) as text_reader : return text_reader . read ()","title":"read_value_from_reader()"},{"location":"api/#boxs.value_types.StringValueType.supports","text":"Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): return isinstance ( value , str )","title":"supports()"},{"location":"api/#boxs.value_types.StringValueType.write_value_to_writer","text":"Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py def write_value_to_writer ( self , value , writer ): source_stream = io . BytesIO ( value . encode ( self . _default_encoding )) writer . meta [ 'encoding' ] = self . _default_encoding with writer . as_stream () as destination_stream : shutil . copyfileobj ( source_stream , destination_stream )","title":"write_value_to_writer()"},{"location":"api/#boxs.value_types.ValueType","text":"Base class for implementing the type depending reading and writing of values to and from Readers and Writers. Source code in boxs/value_types.py class ValueType ( abc . ABC ): \"\"\" Base class for implementing the type depending reading and writing of values to and from Readers and Writers. \"\"\" def __init__ ( self ): self . _logger = logging . getLogger ( str ( self . __class__ )) def supports ( self , value ): # pylint: disable=unused-argument,no-self-use \"\"\" Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Args: value (Any): The value for which the value type should be checked. Returns: bool: `True` if the value type supports this value, otherwise `False`. The default implementation just returns `False`. \"\"\" return False @abc . abstractmethod def write_value_to_writer ( self , value , writer ): \"\"\" Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Args: value (Any): The value that should be written. writer (boxs.storage.Writer): The writer into which the value should be written. \"\"\" @abc . abstractmethod def read_value_from_reader ( self , reader ): \"\"\" Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Args: reader (boxs.storage.Reader): The reader from which the value should be read. Returns: Any: The value that was read from the reader. \"\"\" def get_specification ( self ): \"\"\" Returns a string that specifies this ValueType. Returns: str: The specification that can be used for recreating this specific ValueType. \"\"\" module_name = self . __class__ . __module__ class_name = self . __class__ . __qualname__ parameter_string = self . _get_parameter_string () return ':' . join ([ module_name , class_name , parameter_string ]) @classmethod def from_specification ( cls , specification ): \"\"\" Create a new ValueType instance from its specification string. Args: specification (str): The specification string that specifies the ValueType thate should be instantiated. Returns: ValueType: The specified ValueType instance. \"\"\" logger . debug ( \"Recreating value type from specification %s \" , specification ) module_name , class_name , parameter_string = specification . split ( ':' , maxsplit = 2 ) module = importlib . import_module ( module_name ) class_ = getattr ( module , class_name ) value_type = class_ . _from_parameter_string ( # pylint: disable=protected-access parameter_string , ) return value_type def _get_parameter_string ( self ): # pylint: disable=no-self-use \"\"\" Return a string encoding the ValueType specific parameters. This method needs to be overridden by subclasses, that use parameters. Returns: str: The string containing the parameters. \"\"\" return '' @classmethod def _from_parameter_string ( cls , parameters ): # pylint: disable=unused-argument \"\"\" Return a new instance of a specific ValueType from its parameter string. This method needs to be overridden by subclasses, that use parameters. Returns: ValueType: The specified ValueType instance. \"\"\" return cls () def __repr__ ( self ): return self . get_specification () def __str__ ( self ): return self . get_specification ()","title":"ValueType"},{"location":"api/#boxs.value_types.ValueType.from_specification","text":"Create a new ValueType instance from its specification string. Parameters: Name Type Description Default specification str The specification string that specifies the ValueType thate should be instantiated. required Returns: Type Description ValueType The specified ValueType instance. Source code in boxs/value_types.py @classmethod def from_specification ( cls , specification ): \"\"\" Create a new ValueType instance from its specification string. Args: specification (str): The specification string that specifies the ValueType thate should be instantiated. Returns: ValueType: The specified ValueType instance. \"\"\" logger . debug ( \"Recreating value type from specification %s \" , specification ) module_name , class_name , parameter_string = specification . split ( ':' , maxsplit = 2 ) module = importlib . import_module ( module_name ) class_ = getattr ( module , class_name ) value_type = class_ . _from_parameter_string ( # pylint: disable=protected-access parameter_string , ) return value_type","title":"from_specification()"},{"location":"api/#boxs.value_types.ValueType.get_specification","text":"Returns a string that specifies this ValueType. Returns: Type Description str The specification that can be used for recreating this specific ValueType. Source code in boxs/value_types.py def get_specification ( self ): \"\"\" Returns a string that specifies this ValueType. Returns: str: The specification that can be used for recreating this specific ValueType. \"\"\" module_name = self . __class__ . __module__ class_name = self . __class__ . __qualname__ parameter_string = self . _get_parameter_string () return ':' . join ([ module_name , class_name , parameter_string ])","title":"get_specification()"},{"location":"api/#boxs.value_types.ValueType.read_value_from_reader","text":"Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default reader boxs.storage.Reader The reader from which the value should be read. required Returns: Type Description Any The value that was read from the reader. Source code in boxs/value_types.py @abc . abstractmethod def read_value_from_reader ( self , reader ): \"\"\" Read a value from the reader. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Args: reader (boxs.storage.Reader): The reader from which the value should be read. Returns: Any: The value that was read from the reader. \"\"\"","title":"read_value_from_reader()"},{"location":"api/#boxs.value_types.ValueType.supports","text":"Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Parameters: Name Type Description Default value Any The value for which the value type should be checked. required Returns: Type Description bool True if the value type supports this value, otherwise False . The default implementation just returns False . Source code in boxs/value_types.py def supports ( self , value ): # pylint: disable=unused-argument,no-self-use \"\"\" Returns if the value type can be used for reading a writing the given value. This method is used to determine if a value can be read and written by a value type. It is only necessary, if the value type should be picked up automatically. If it is only used explicitly, no check is performed. Args: value (Any): The value for which the value type should be checked. Returns: bool: `True` if the value type supports this value, otherwise `False`. The default implementation just returns `False`. \"\"\" return False","title":"supports()"},{"location":"api/#boxs.value_types.ValueType.write_value_to_writer","text":"Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Parameters: Name Type Description Default value Any The value that should be written. required writer boxs.storage.Writer The writer into which the value should be written. required Source code in boxs/value_types.py @abc . abstractmethod def write_value_to_writer ( self , value , writer ): \"\"\" Write the given value to the writer. This method needs to be implemented by the specific value type implementations that take care of the necessary type conversions. Args: value (Any): The value that should be written. writer (boxs.storage.Writer): The writer into which the value should be written. \"\"\"","title":"write_value_to_writer()"},{"location":"changelog/","text":"Changelog \ud83d\udd17 0.1: Initial release of the package. \ud83d\udd17 Simple api in form of boxs.store(), boxs.load() and boxs.info() FileSystemStorage which stores data items in the local file system Value types for storing and loading data from different types Standard python types (str, bytes, streams, files, directories, dicts and list via JSON) Pandas DataFrame Tensorflow Keras model Transformer mechanism for modifying data and meta-data during storing ChecksumTransformer which automatically generates checksums during store and verifies them when loading StatisticsTransformer keeps statistics about size, number of lines or time for storing Command line interface for inspecting data List all data items and runs in which they were created Print information about individual data items Export data items to the local file system Compare data items using diff Generate dependency graph for data items in DOT format Delete no longer used runs","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#01-initial-release-of-the-package","text":"Simple api in form of boxs.store(), boxs.load() and boxs.info() FileSystemStorage which stores data items in the local file system Value types for storing and loading data from different types Standard python types (str, bytes, streams, files, directories, dicts and list via JSON) Pandas DataFrame Tensorflow Keras model Transformer mechanism for modifying data and meta-data during storing ChecksumTransformer which automatically generates checksums during store and verifies them when loading StatisticsTransformer keeps statistics about size, number of lines or time for storing Command line interface for inspecting data List all data items and runs in which they were created Print information about individual data items Export data items to the local file system Compare data items using diff Generate dependency graph for data items in DOT format Delete no longer used runs","title":"0.1: Initial release of the package."},{"location":"cli/","text":"Command line interface \ud83d\udd17 Boxs brings with it a command line interface, that lets the user inspect and manage the data items of a box. Install \ud83d\udd17 When boxs is installed using pip , the command line interface boxs is automatically installed and added to the path: $ pip install boxs ... $ boxs -h usage: boxs [ -h ] [ -b BOX ] [ -i INIT_MODULE ] [ -j ] { list-runs,name-run,delete-run,clean-runs,list,info,diff,export,graph } ... If the boxs package is used from source, the package can be locally installed together with the script by running $ flit install ... $ boxs -h usage: boxs [ -h ] [ -b BOX ] [ -i INIT_MODULE ] [ -j ] { list-runs,name-run,delete-run,clean-runs,list,info,diff,export,graph } ... from the boxs root directory. If flit isn't available, the command line interface can be directly executed using the python interpreter: $ python -m boxs.cli -h usage: boxs [ -h ] [ -b BOX ] [ -i INIT_MODULE ] [ -j ] { list-runs,name-run,delete-run,clean-runs,list,info,diff,export,graph } ... Global options \ud83d\udd17 The command line interface supports a set of global options that are relevant for all commands: optional arguments: -b BOX, --default-box BOX The id of the default box to use. If not set, the default is taken from the BOXS_DEFAULT_BOX environment variable. -i INIT_MODULE, --init-module INIT_MODULE A python module that should be automatically loaded. If not set, the default is taken from the BOXS_INIT_MODULE environment variable. -j, --json Print output as json --default-box, -b \ud83d\udd17 Many commands apply to a single box. This option allows to set the box id of the box, that should be used as a default of no other box is specified. This argument has precedence over the default box defined by the environment variable BOXS_DEFAULT_BOX . See the user guide for more information. --init-module, -i \ud83d\udd17 This option instructs the command line interface to load the specified python module. It is meant for making sure, the box definitions are setup. The argument has precedence over the init_module defined by the environment variable BOXS_INIT_MODULE , but it is possible, that both modules get loaded, if they differ. See the user guide for more information. --json, -j \ud83d\udd17 Often the tools are integrated in some automation. For this, it has the option to print all results in JSON format so that they can be parsed more easily. Commands \ud83d\udd17 list-runs \ud83d\udd17 $ boxs list-runs -h usage: boxs list-runs [ -h ] [ -f FILTER ] [ -l LIMIT ] optional arguments: -h, --help show this help message and exit -f FILTER, --name-filter FILTER Only list runs whose name begins with FILTER. -l LIMIT, --limit LIMIT Only list the <LIMIT> last runs. This commands allows to list the runs that can be found in the default box. Without any other options, all runs are returned and printed in descending order based on the timestamps of the runs. --name-filter, -f \ud83d\udd17 A name can be manually assigned to a run. This option returns only those runs which have a name and whose names start with the specified filter string. --limit, -l \ud83d\udd17 Often older runs are not important, so they can be disregarded. This option limits the total number of runs that are returned. Example \ud83d\udd17 $ boxs list-runs --name-filter release --limit 2 List runs | box_id | run_id | name | time | my-box-id 0e63ad74-8102-11ec-9c51-48f17f64520d release_1.1 2022 -01-29 12 :50:44.422651+00:00 my-box-id 12d03f94-7e0a-11ec-9020-48f17f64520d release_1.0 2022 -01-25 18 :10:35.297825+00:00 name-run \ud83d\udd17 $ boxs name-run -h usage: boxs name-run [ -h ] [ -n NAME ] RUN positional arguments: RUN Run id or name, can be just the first characters. optional arguments: -h, --help show this help message and exit -n NAME, --name NAME The new name of the run, if left out, the current name will be removed. name-run sets the user-defined name of a run. When runs are automatically created, they can only be referenced by their cryptic run-id. These run-ids are hard to keep in mind. Therefore, it is possible to assign a name to a run. RUN \ud83d\udd17 This positional argument is required and contains the id or name of the run, whose name should be modified. The value of argument doesn't have to be the complete name or the complete run id, the beginning is sufficient, as long as it is not ambiguous. --name, -n \ud83d\udd17 The name that should be used for the run. If this argument is provided, the new name will replace any previous name. If the argument is not provided, an existing name will be removed. Example \ud83d\udd17 $ boxs name-run 0e63 -n release_1.1 Run name set 0e63ad74-8102-11ec-9c51-48f17f64520d | box_id | run_id | name | time | my-box-id 0e63ad74-8102-11ec-9c51-48f17f64520d release_1.1 2022 -01-29 12 :50:44.422651+00:00 delete-run \ud83d\udd17 $ boxs delete-run -h usage: boxs delete-run [ -h ] [ -q ] RUN positional arguments: RUN Run id or name, can be just the first characters. optional arguments: -h, --help show this help message and exit -q, --quiet Don ' t ask for confirmation. The delete-run command can be used to remove single runs. Warning This command is potentially dangerous, because it deletes runs without checking for dependencies from other runs. Therefore, deleting a run can lead to inconsistencies! RUN \ud83d\udd17 This positional argument is required and contains the id or name of the run, which should be deleted. The value of argument doesn't have to be the complete name or the complete run id, the beginning is sufficient, as long as it is not ambiguous. --quiet, -q \ud83d\udd17 This option disables the usual confirmation question. Example \ud83d\udd17 $ boxs delete-run cbd Really delete the run cbd0b6dd-7935-11ec-a32c-48f17f64520d? There might be other runs referencing data from it. ( y/N ) clean-runs \ud83d\udd17 $ boxs clean-runs -h usage: boxs clean-runs [ -h ] [ -n ] [ -r COUNT ] [ -d ] [ -q ] optional arguments: -h, --help show this help message and exit -n, --remove-named Delete runs which have names. -r COUNT, --preserve-runs COUNT Preserve the <COUNT> last runs. Defaults to 5 . -d, --ignore-dependencies Delete runs which contain data items referenced by kept runs. -q, --quiet Don ' t ask for confirmation. The clean-runs command can be used to remove runs that are no longer needed. It removes all runs except the latest N. Runs including data items that are referenced by kept runs and runs with names are kept, too, except if overridden. --preserve-runs, -r \ud83d\udd17 This optional argument sets the number of runs that should be kept. If not used, a default value of 5 runs is used. --removed-named, -n \ud83d\udd17 If this option is set, named runs are deleted, too. --ignore-dependencies, -d \ud83d\udd17 With this option being set, no check for dependencies from the kept runs is performed. Warning This option is potentially dangerous, because it deletes runs without checking for dependencies from other runs. This may lead to items with missing ancestors! --quiet, -q \ud83d\udd17 This option disables the usual confirmation question. Example \ud83d\udd17 $ boxs clean-runs -n 3 --ignore-dependencies Delete runs | box_id | run_id | name | time | my-box-id c5caaee0-7d2e-11ec-9020-48f17f64520d 2022 -01-24 16 :00:38.460836+00:00 my-box-id c0b342b4-7c9d-11ec-abee-48f17f64520d 2022 -01-23 22 :42:32.900216+00:00 my-box-id bb157404-7c9c-11ec-abee-48f17f64520d 2022 -01-23 22 :36:59.329551+00:00 Really delete all listed runs? ( y/N ) list \ud83d\udd17 $ boxs list -h usage: boxs list [ -h ] QUERY positional arguments: QUERY The query in format [ <box>:<data>:<run> ] for the items which should be listed. optional arguments: -h, --help show this help message and exit The list command allows to list data items that match a query. QUERY \ud83d\udd17 The query is a string, that can contain a box filter, a data filter and a run filter separated by \":\" in the format \" : : \". box: The box filter matches all data items with a box id that begins with the filter. data: The data filter matches all data items where the data id or the data name begins with the filter. run: The run filter matches all data items with a run id or run name that begins with the filter. Not all filters have to be provided. Preceding \":\" can be left out. The resulting data items listed have to match ALL filters. Examples: - \"my-box::release\" Matches all items in a box that begins with \"my-box\" and whose run names begin with \"release\". - \"train_data:\" Matches all items with the name \"train_data\" in all boxes and all runs. - \"::release-1.0\" or \"release-1.0\" Matches all items in the run with the name \"release-1.0\" Example \ud83d\udd17 $ boxs list ::release List items boat_price::release | box_id | data_id | run_id | name | time | my-box-id d91bf391601f6f53 12d03f94-7e0a-11ec-9020-48f17f64520d trained_model 2022 -01-25 18 :10:35.297825+00:00 my-box-id cf64163dd7c1898c 0e63ad74-8102-11ec-9c51-48f17f64520d train_data 2022 -01-29 12 :50:37.482767+00:00 my-box-id efb03082d67da076 0e63ad74-8102-11ec-9c51-48f17f64520d eval_data 2022 -01-29 12 :50:37.490767+00:00 my-box-id 7473d9676cbc377e 0e63ad74-8102-11ec-9c51-48f17f64520d encoded_train_input 2022 -01-29 12 :50:37.570765+00:00 my-box-id 21bfb27c4a636f4e 0e63ad74-8102-11ec-9c51-48f17f64520d encoded_train_output 2022 -01-29 12 :50:37.582765+00:00 my-box-id 800b5a5c9a972d3e 0e63ad74-8102-11ec-9c51-48f17f64520d encoded_eval_input 2022 -01-29 12 :50:37.606765+00:00 my-box-id ddb065be789696cb 0e63ad74-8102-11ec-9c51-48f17f64520d encoded_eval_output 2022 -01-29 12 :50:37.610765+00:00 my-box-id 15d29183ad09cbfc 0e63ad74-8102-11ec-9c51-48f17f64520d normalized_train_input 2022 -01-29 12 :50:37.734763+00:00 my-box-id 6f31c9a1c68b3b02 0e63ad74-8102-11ec-9c51-48f17f64520d normalized_eval_input 2022 -01-29 12 :50:37.762762+00:00 my-box-id d91bf391601f6f53 0e63ad74-8102-11ec-9c51-48f17f64520d trained_model 2022 -01-29 12 :50:44.418651+00:00 my-box-id b2560fb2c8b88621 0e63ad74-8102-11ec-9c51-48f17f64520d tensorboard_logs 2022 -01-29 12 :50:44.422651+00:00 info \ud83d\udd17 $ boxs list -h usage: boxs info [ -h ] QUERY positional arguments: QUERY The query in format [ <box>:<data>:<run> ] for the item whose info should be printed. optional arguments: -h, --help show this help message and exit The info command allows print information about a single data item identified by a query. QUERY \ud83d\udd17 The query is a string, that can contain a box filter, a data filter and a run filter separated by \":\" in the format \" : : \". Since the command can show only one info at a time, the query has to be unambiguous, returning only a single item. For more information see the description for list Example \ud83d\udd17 $ boxs info :trained_model:release_1.1 Info d91bf391601f6f53 0e63ad74-8102-11ec-9c51-48f17f64520d Property Value ref : box_id : my-box-id data_id : d91bf391601f6f53 run_id : 0e63ad74-8102-11ec-9c51-48f17f64520d origin : train name : trained_model tags : {} parents : [{ 'ref' : { 'box_id' : 'my-box-id' , 'data_id' : '15d29183ad09cbfc' , 'run_id' : '0e63ad74-8102-11ec-9c51-48f17f64520d' } , 'origin' : 'normalize_input_data' , 'name' : 'normalized_train_input' , 'tags' : {} , 'parents' : [{ 'ref' : { 'box_id' : 'boat_price' , 'data_id' :... meta : value_type : boxs.tensorflow:TensorflowKerasModelValueType:tf size_in_bytes : 1963138 number_of_lines : 12482 store_start : 2022 -01-29T12:50:44.413+00:00 store_end : 2022 -01-29T12:50:44.413+00:00 model_format : tf checksum_digest : 8ec304eafb8453f7fe41d7547e7b297b1ef335f855acbf3085aa5a5e95e814e1 checksum_digest_size: 32 checksum_algorithm : blake2b diff \ud83d\udd17 $ boxs diff -h usage: boxs diff [ -h ] [ -d DIFF ] [ -l ] QUERY QUERY [ DIFF-ARG [ DIFF-ARG ... ]] positional arguments: QUERY The queries in format [ <box>:<data>:<run> ] describing the items to compare. DIFF-ARG Arbitrary arguments for the diff command. optional arguments: -h, --help show this help message and exit -d DIFF, --diff-command DIFF The command to use for comparing, defaults to 'diff' . -l, --without-labels Disable the labels. The diff command creates a diff of two data items. It uses the system \"diff\" tool for this, but the command that is called can be configured. QUERY \ud83d\udd17 The query is a string, that can contain a box filter, a data filter and a run filter separated by \":\" in the format \" : : \". Since this command compares two items, it takes two queries, Both queries have to be unambiguous, returning only a single item. For more information see the description for list DIFF-ARG \ud83d\udd17 The command takes arbitrary additional commands that are relayed to the diff tool. --diff-command, -d \ud83d\udd17 This option allows to use a different command for creating the diff. If not specified \"diff\" is used. --without-labels, -l \ud83d\udd17 The command line interface saves the data items to temporary files in order to be able to use diff. When comparing those files, diff prints their temporary paths, which make it hard to know which file is which item. Therefore, the tool adds additional \"--label\" arguments to the diff call, which change the labels to be the item query. Since not all diff tools support these option, \"--without-labels\" disables that those options are added. Example \ud83d\udd17 $ boxs diff :trained_model:release_1.1 :trained_model:release_1.0 Binary files :trained_model:release_1.1 and :trained_model:release_1.0 differ export \ud83d\udd17 $ boxs export -h usage: boxs export [ -h ] QUERY FILE positional arguments: QUERY The query in format [ <box>:<data>:<run> ] describing the item to export. FILE The file path to export to. optional arguments: -h, --help show this help message and exit The export command exports data items to the local file system. QUERY \ud83d\udd17 The query is a string, that can contain a box filter, a data filter and a run filter separated by \":\" in the format \" : : \". Since the command can export only one item at a time, the query has to be unambiguous, returning only a single item. For more information see the description for list FILE \ud83d\udd17 A file path to which the data item should be exported. Example \ud83d\udd17 $ boxs export :trained_model:release_1.1 /tmp/model :trained_model:release_1.1 successfully exported to /tmp/model graph \ud83d\udd17 $ boxs graph -h usage: boxs graph [ -h ] QUERY [ FILE ] positional arguments: QUERY The query describing the items to graph. FILE The file to write the graph to. If left empty, the graph is written to stdout. optional arguments: -h, --help show this help message and exit The graph command creates a representation of the dependency graph in DOT format. It can be either written to a file or printed out to stdout. QUERY \ud83d\udd17 The query is a string, that can contain a box filter, a data filter and a run filter separated by \":\" in the format \" : : \". For more information see the description for list FILE \ud83d\udd17 A file path to which the graph should be written. If the argument is left out, the graph is printed to stdout. Example \ud83d\udd17 $ boxs graph :trained_model:release_1.1 digraph { subgraph \"cluster_0e63ad74-8102-11ec-9c51-48f17f64520d\" { label = \"Run 0e63ad74-8102-11ec-9c51-48f17f64520d\" ; \"boxs://boat_price/d91bf391601f6f53/0e63ad74-8102-11ec-9c51-48f17f64520d\" [ label = \"trained_model\\norigin train\\nsize 1963138\" ] \"boxs://boat_price/ddb065be789696cb/0e63ad74-8102-11ec-9c51-48f17f64520d\" [ label = \"encoded_eval_output\\norigin encode_data\\nsize 32189\" ] \"boxs://boat_price/efb03082d67da076/0e63ad74-8102-11ec-9c51-48f17f64520d\" [ label = \"eval_data\\norigin partition_data\\nsize 189854\" ] \"boxs://boat_price/6f31c9a1c68b3b02/0e63ad74-8102-11ec-9c51-48f17f64520d\" [ label = \"normalized_eval_input\\norigin normalize_input_data\\nsize 327758\" ] \"boxs://boat_price/800b5a5c9a972d3e/0e63ad74-8102-11ec-9c51-48f17f64520d\" [ label = \"encoded_eval_input\\norigin encode_data\\nsize 226617\" ] ...","title":"Command line interface"},{"location":"cli/#command-line-interface","text":"Boxs brings with it a command line interface, that lets the user inspect and manage the data items of a box.","title":"Command line interface"},{"location":"cli/#install","text":"When boxs is installed using pip , the command line interface boxs is automatically installed and added to the path: $ pip install boxs ... $ boxs -h usage: boxs [ -h ] [ -b BOX ] [ -i INIT_MODULE ] [ -j ] { list-runs,name-run,delete-run,clean-runs,list,info,diff,export,graph } ... If the boxs package is used from source, the package can be locally installed together with the script by running $ flit install ... $ boxs -h usage: boxs [ -h ] [ -b BOX ] [ -i INIT_MODULE ] [ -j ] { list-runs,name-run,delete-run,clean-runs,list,info,diff,export,graph } ... from the boxs root directory. If flit isn't available, the command line interface can be directly executed using the python interpreter: $ python -m boxs.cli -h usage: boxs [ -h ] [ -b BOX ] [ -i INIT_MODULE ] [ -j ] { list-runs,name-run,delete-run,clean-runs,list,info,diff,export,graph } ...","title":"Install"},{"location":"cli/#global-options","text":"The command line interface supports a set of global options that are relevant for all commands: optional arguments: -b BOX, --default-box BOX The id of the default box to use. If not set, the default is taken from the BOXS_DEFAULT_BOX environment variable. -i INIT_MODULE, --init-module INIT_MODULE A python module that should be automatically loaded. If not set, the default is taken from the BOXS_INIT_MODULE environment variable. -j, --json Print output as json","title":"Global options"},{"location":"cli/#-default-box-b","text":"Many commands apply to a single box. This option allows to set the box id of the box, that should be used as a default of no other box is specified. This argument has precedence over the default box defined by the environment variable BOXS_DEFAULT_BOX . See the user guide for more information.","title":"--default-box, -b"},{"location":"cli/#-init-module-i","text":"This option instructs the command line interface to load the specified python module. It is meant for making sure, the box definitions are setup. The argument has precedence over the init_module defined by the environment variable BOXS_INIT_MODULE , but it is possible, that both modules get loaded, if they differ. See the user guide for more information.","title":"--init-module, -i"},{"location":"cli/#-json-j","text":"Often the tools are integrated in some automation. For this, it has the option to print all results in JSON format so that they can be parsed more easily.","title":"--json, -j"},{"location":"cli/#commands","text":"","title":"Commands"},{"location":"cli/#list-runs","text":"$ boxs list-runs -h usage: boxs list-runs [ -h ] [ -f FILTER ] [ -l LIMIT ] optional arguments: -h, --help show this help message and exit -f FILTER, --name-filter FILTER Only list runs whose name begins with FILTER. -l LIMIT, --limit LIMIT Only list the <LIMIT> last runs. This commands allows to list the runs that can be found in the default box. Without any other options, all runs are returned and printed in descending order based on the timestamps of the runs.","title":"list-runs"},{"location":"cli/#-name-filter-f","text":"A name can be manually assigned to a run. This option returns only those runs which have a name and whose names start with the specified filter string.","title":"--name-filter, -f"},{"location":"cli/#-limit-l","text":"Often older runs are not important, so they can be disregarded. This option limits the total number of runs that are returned.","title":"--limit, -l"},{"location":"cli/#example","text":"$ boxs list-runs --name-filter release --limit 2 List runs | box_id | run_id | name | time | my-box-id 0e63ad74-8102-11ec-9c51-48f17f64520d release_1.1 2022 -01-29 12 :50:44.422651+00:00 my-box-id 12d03f94-7e0a-11ec-9020-48f17f64520d release_1.0 2022 -01-25 18 :10:35.297825+00:00","title":"Example"},{"location":"cli/#name-run","text":"$ boxs name-run -h usage: boxs name-run [ -h ] [ -n NAME ] RUN positional arguments: RUN Run id or name, can be just the first characters. optional arguments: -h, --help show this help message and exit -n NAME, --name NAME The new name of the run, if left out, the current name will be removed. name-run sets the user-defined name of a run. When runs are automatically created, they can only be referenced by their cryptic run-id. These run-ids are hard to keep in mind. Therefore, it is possible to assign a name to a run.","title":"name-run"},{"location":"cli/#run","text":"This positional argument is required and contains the id or name of the run, whose name should be modified. The value of argument doesn't have to be the complete name or the complete run id, the beginning is sufficient, as long as it is not ambiguous.","title":"RUN"},{"location":"cli/#-name-n","text":"The name that should be used for the run. If this argument is provided, the new name will replace any previous name. If the argument is not provided, an existing name will be removed.","title":"--name, -n"},{"location":"cli/#example_1","text":"$ boxs name-run 0e63 -n release_1.1 Run name set 0e63ad74-8102-11ec-9c51-48f17f64520d | box_id | run_id | name | time | my-box-id 0e63ad74-8102-11ec-9c51-48f17f64520d release_1.1 2022 -01-29 12 :50:44.422651+00:00","title":"Example"},{"location":"cli/#delete-run","text":"$ boxs delete-run -h usage: boxs delete-run [ -h ] [ -q ] RUN positional arguments: RUN Run id or name, can be just the first characters. optional arguments: -h, --help show this help message and exit -q, --quiet Don ' t ask for confirmation. The delete-run command can be used to remove single runs. Warning This command is potentially dangerous, because it deletes runs without checking for dependencies from other runs. Therefore, deleting a run can lead to inconsistencies!","title":"delete-run"},{"location":"cli/#run_1","text":"This positional argument is required and contains the id or name of the run, which should be deleted. The value of argument doesn't have to be the complete name or the complete run id, the beginning is sufficient, as long as it is not ambiguous.","title":"RUN"},{"location":"cli/#-quiet-q","text":"This option disables the usual confirmation question.","title":"--quiet, -q"},{"location":"cli/#example_2","text":"$ boxs delete-run cbd Really delete the run cbd0b6dd-7935-11ec-a32c-48f17f64520d? There might be other runs referencing data from it. ( y/N )","title":"Example"},{"location":"cli/#clean-runs","text":"$ boxs clean-runs -h usage: boxs clean-runs [ -h ] [ -n ] [ -r COUNT ] [ -d ] [ -q ] optional arguments: -h, --help show this help message and exit -n, --remove-named Delete runs which have names. -r COUNT, --preserve-runs COUNT Preserve the <COUNT> last runs. Defaults to 5 . -d, --ignore-dependencies Delete runs which contain data items referenced by kept runs. -q, --quiet Don ' t ask for confirmation. The clean-runs command can be used to remove runs that are no longer needed. It removes all runs except the latest N. Runs including data items that are referenced by kept runs and runs with names are kept, too, except if overridden.","title":"clean-runs"},{"location":"cli/#-preserve-runs-r","text":"This optional argument sets the number of runs that should be kept. If not used, a default value of 5 runs is used.","title":"--preserve-runs, -r"},{"location":"cli/#-removed-named-n","text":"If this option is set, named runs are deleted, too.","title":"--removed-named, -n"},{"location":"cli/#-ignore-dependencies-d","text":"With this option being set, no check for dependencies from the kept runs is performed. Warning This option is potentially dangerous, because it deletes runs without checking for dependencies from other runs. This may lead to items with missing ancestors!","title":"--ignore-dependencies, -d"},{"location":"cli/#-quiet-q_1","text":"This option disables the usual confirmation question.","title":"--quiet, -q"},{"location":"cli/#example_3","text":"$ boxs clean-runs -n 3 --ignore-dependencies Delete runs | box_id | run_id | name | time | my-box-id c5caaee0-7d2e-11ec-9020-48f17f64520d 2022 -01-24 16 :00:38.460836+00:00 my-box-id c0b342b4-7c9d-11ec-abee-48f17f64520d 2022 -01-23 22 :42:32.900216+00:00 my-box-id bb157404-7c9c-11ec-abee-48f17f64520d 2022 -01-23 22 :36:59.329551+00:00 Really delete all listed runs? ( y/N )","title":"Example"},{"location":"cli/#list","text":"$ boxs list -h usage: boxs list [ -h ] QUERY positional arguments: QUERY The query in format [ <box>:<data>:<run> ] for the items which should be listed. optional arguments: -h, --help show this help message and exit The list command allows to list data items that match a query.","title":"list"},{"location":"cli/#query","text":"The query is a string, that can contain a box filter, a data filter and a run filter separated by \":\" in the format \" : : \". box: The box filter matches all data items with a box id that begins with the filter. data: The data filter matches all data items where the data id or the data name begins with the filter. run: The run filter matches all data items with a run id or run name that begins with the filter. Not all filters have to be provided. Preceding \":\" can be left out. The resulting data items listed have to match ALL filters. Examples: - \"my-box::release\" Matches all items in a box that begins with \"my-box\" and whose run names begin with \"release\". - \"train_data:\" Matches all items with the name \"train_data\" in all boxes and all runs. - \"::release-1.0\" or \"release-1.0\" Matches all items in the run with the name \"release-1.0\"","title":"QUERY"},{"location":"cli/#example_4","text":"$ boxs list ::release List items boat_price::release | box_id | data_id | run_id | name | time | my-box-id d91bf391601f6f53 12d03f94-7e0a-11ec-9020-48f17f64520d trained_model 2022 -01-25 18 :10:35.297825+00:00 my-box-id cf64163dd7c1898c 0e63ad74-8102-11ec-9c51-48f17f64520d train_data 2022 -01-29 12 :50:37.482767+00:00 my-box-id efb03082d67da076 0e63ad74-8102-11ec-9c51-48f17f64520d eval_data 2022 -01-29 12 :50:37.490767+00:00 my-box-id 7473d9676cbc377e 0e63ad74-8102-11ec-9c51-48f17f64520d encoded_train_input 2022 -01-29 12 :50:37.570765+00:00 my-box-id 21bfb27c4a636f4e 0e63ad74-8102-11ec-9c51-48f17f64520d encoded_train_output 2022 -01-29 12 :50:37.582765+00:00 my-box-id 800b5a5c9a972d3e 0e63ad74-8102-11ec-9c51-48f17f64520d encoded_eval_input 2022 -01-29 12 :50:37.606765+00:00 my-box-id ddb065be789696cb 0e63ad74-8102-11ec-9c51-48f17f64520d encoded_eval_output 2022 -01-29 12 :50:37.610765+00:00 my-box-id 15d29183ad09cbfc 0e63ad74-8102-11ec-9c51-48f17f64520d normalized_train_input 2022 -01-29 12 :50:37.734763+00:00 my-box-id 6f31c9a1c68b3b02 0e63ad74-8102-11ec-9c51-48f17f64520d normalized_eval_input 2022 -01-29 12 :50:37.762762+00:00 my-box-id d91bf391601f6f53 0e63ad74-8102-11ec-9c51-48f17f64520d trained_model 2022 -01-29 12 :50:44.418651+00:00 my-box-id b2560fb2c8b88621 0e63ad74-8102-11ec-9c51-48f17f64520d tensorboard_logs 2022 -01-29 12 :50:44.422651+00:00","title":"Example"},{"location":"cli/#info","text":"$ boxs list -h usage: boxs info [ -h ] QUERY positional arguments: QUERY The query in format [ <box>:<data>:<run> ] for the item whose info should be printed. optional arguments: -h, --help show this help message and exit The info command allows print information about a single data item identified by a query.","title":"info"},{"location":"cli/#query_1","text":"The query is a string, that can contain a box filter, a data filter and a run filter separated by \":\" in the format \" : : \". Since the command can show only one info at a time, the query has to be unambiguous, returning only a single item. For more information see the description for list","title":"QUERY"},{"location":"cli/#example_5","text":"$ boxs info :trained_model:release_1.1 Info d91bf391601f6f53 0e63ad74-8102-11ec-9c51-48f17f64520d Property Value ref : box_id : my-box-id data_id : d91bf391601f6f53 run_id : 0e63ad74-8102-11ec-9c51-48f17f64520d origin : train name : trained_model tags : {} parents : [{ 'ref' : { 'box_id' : 'my-box-id' , 'data_id' : '15d29183ad09cbfc' , 'run_id' : '0e63ad74-8102-11ec-9c51-48f17f64520d' } , 'origin' : 'normalize_input_data' , 'name' : 'normalized_train_input' , 'tags' : {} , 'parents' : [{ 'ref' : { 'box_id' : 'boat_price' , 'data_id' :... meta : value_type : boxs.tensorflow:TensorflowKerasModelValueType:tf size_in_bytes : 1963138 number_of_lines : 12482 store_start : 2022 -01-29T12:50:44.413+00:00 store_end : 2022 -01-29T12:50:44.413+00:00 model_format : tf checksum_digest : 8ec304eafb8453f7fe41d7547e7b297b1ef335f855acbf3085aa5a5e95e814e1 checksum_digest_size: 32 checksum_algorithm : blake2b","title":"Example"},{"location":"cli/#diff","text":"$ boxs diff -h usage: boxs diff [ -h ] [ -d DIFF ] [ -l ] QUERY QUERY [ DIFF-ARG [ DIFF-ARG ... ]] positional arguments: QUERY The queries in format [ <box>:<data>:<run> ] describing the items to compare. DIFF-ARG Arbitrary arguments for the diff command. optional arguments: -h, --help show this help message and exit -d DIFF, --diff-command DIFF The command to use for comparing, defaults to 'diff' . -l, --without-labels Disable the labels. The diff command creates a diff of two data items. It uses the system \"diff\" tool for this, but the command that is called can be configured.","title":"diff"},{"location":"cli/#query_2","text":"The query is a string, that can contain a box filter, a data filter and a run filter separated by \":\" in the format \" : : \". Since this command compares two items, it takes two queries, Both queries have to be unambiguous, returning only a single item. For more information see the description for list","title":"QUERY"},{"location":"cli/#diff-arg","text":"The command takes arbitrary additional commands that are relayed to the diff tool.","title":"DIFF-ARG"},{"location":"cli/#-diff-command-d","text":"This option allows to use a different command for creating the diff. If not specified \"diff\" is used.","title":"--diff-command, -d"},{"location":"cli/#-without-labels-l","text":"The command line interface saves the data items to temporary files in order to be able to use diff. When comparing those files, diff prints their temporary paths, which make it hard to know which file is which item. Therefore, the tool adds additional \"--label\" arguments to the diff call, which change the labels to be the item query. Since not all diff tools support these option, \"--without-labels\" disables that those options are added.","title":"--without-labels, -l"},{"location":"cli/#example_6","text":"$ boxs diff :trained_model:release_1.1 :trained_model:release_1.0 Binary files :trained_model:release_1.1 and :trained_model:release_1.0 differ","title":"Example"},{"location":"cli/#export","text":"$ boxs export -h usage: boxs export [ -h ] QUERY FILE positional arguments: QUERY The query in format [ <box>:<data>:<run> ] describing the item to export. FILE The file path to export to. optional arguments: -h, --help show this help message and exit The export command exports data items to the local file system.","title":"export"},{"location":"cli/#query_3","text":"The query is a string, that can contain a box filter, a data filter and a run filter separated by \":\" in the format \" : : \". Since the command can export only one item at a time, the query has to be unambiguous, returning only a single item. For more information see the description for list","title":"QUERY"},{"location":"cli/#file","text":"A file path to which the data item should be exported.","title":"FILE"},{"location":"cli/#example_7","text":"$ boxs export :trained_model:release_1.1 /tmp/model :trained_model:release_1.1 successfully exported to /tmp/model","title":"Example"},{"location":"cli/#graph","text":"$ boxs graph -h usage: boxs graph [ -h ] QUERY [ FILE ] positional arguments: QUERY The query describing the items to graph. FILE The file to write the graph to. If left empty, the graph is written to stdout. optional arguments: -h, --help show this help message and exit The graph command creates a representation of the dependency graph in DOT format. It can be either written to a file or printed out to stdout.","title":"graph"},{"location":"cli/#query_4","text":"The query is a string, that can contain a box filter, a data filter and a run filter separated by \":\" in the format \" : : \". For more information see the description for list","title":"QUERY"},{"location":"cli/#file_1","text":"A file path to which the graph should be written. If the argument is left out, the graph is printed to stdout.","title":"FILE"},{"location":"cli/#example_8","text":"$ boxs graph :trained_model:release_1.1 digraph { subgraph \"cluster_0e63ad74-8102-11ec-9c51-48f17f64520d\" { label = \"Run 0e63ad74-8102-11ec-9c51-48f17f64520d\" ; \"boxs://boat_price/d91bf391601f6f53/0e63ad74-8102-11ec-9c51-48f17f64520d\" [ label = \"trained_model\\norigin train\\nsize 1963138\" ] \"boxs://boat_price/ddb065be789696cb/0e63ad74-8102-11ec-9c51-48f17f64520d\" [ label = \"encoded_eval_output\\norigin encode_data\\nsize 32189\" ] \"boxs://boat_price/efb03082d67da076/0e63ad74-8102-11ec-9c51-48f17f64520d\" [ label = \"eval_data\\norigin partition_data\\nsize 189854\" ] \"boxs://boat_price/6f31c9a1c68b3b02/0e63ad74-8102-11ec-9c51-48f17f64520d\" [ label = \"normalized_eval_input\\norigin normalize_input_data\\nsize 327758\" ] \"boxs://boat_price/800b5a5c9a972d3e/0e63ad74-8102-11ec-9c51-48f17f64520d\" [ label = \"encoded_eval_input\\norigin encode_data\\nsize 226617\" ] ...","title":"Example"},{"location":"faq/","text":"FAQ \ud83d\udd17 When to use DataInfo and when to use DataRef? \ud83d\udd17 \ud83d\udd17","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#when-to-use-datainfo-and-when-to-use-dataref","text":"","title":"When to use DataInfo and when to use DataRef?"},{"location":"faq/#_1","text":"","title":""},{"location":"getting_started/","text":"Getting started \ud83d\udd17 Install the library \ud83d\udd17 Install the latest version from PyPI using pip: pip install boxs Configure where boxs stores your data \ud83d\udd17 Within your python script, import boxs and create a new Box with a Storage : import boxs ... storage = boxs . FileSystemStorage ( '/path/to/my/data' ) box = boxs . Box ( 'my-box-id' , storage ) Store data in your box \ud83d\udd17 Use the store() function to store your data, which returns a DataInfo object with a reference to the stored data and some additional meta-data: ... def my_function ( x ): ... value = ... data = boxs . store ( value , box = 'my-box-id' , name = 'my-data' ) return data Load the data from the reference \ud83d\udd17 Loading the data can be done either directly on the DataInfo object, or by giving it as argument to the free load() function from the boxs package: ... def my_other_function ( data ): value = boxs . load ( data ) # or directly from the reference value = data . load () List your last runs \ud83d\udd17 Boxs comes with a command-line interface that allows to interact with the cached data. It can be used e.g. to list the runs: $ boxs -i 'my_python_module' -b 'my-box-id' list-runs List runs | box_id | run_id | name | time | my-box-id 0e63ad74-8102-11ec-9c51-48f17f64520d 2022 -01-29 12 :50:44.422651+00:00 my-box-id 12d03f94-7e0a-11ec-9020-48f17f64520d saved_model 2022 -01-25 18 :10:35.297825+00:00 my-box-id ed923ea0-7df8-11ec-9020-48f17f64520d 2022 -01-25 16 :07:43.658161+00:00 my-box-id 118d9332-7df3-11ec-9020-48f17f64520d 2022 -01-25 15 :25:47.026477+00:00 my-box-id bec3dfb2-7df2-11ec-9020-48f17f64520d 2022 -01-25 15 :23:28.143102+00:00 my-box-id c5caaee0-7d2e-11ec-9020-48f17f64520d 2022 -01-24 16 :00:38.460836+00:00 my-box-id c0b342b4-7c9d-11ec-abee-48f17f64520d 2022 -01-23 22 :42:32.900216+00:00 my-box-id bb157404-7c9c-11ec-abee-48f17f64520d 2022 -01-23 22 :36:59.329551+00:00 my-box-id cbd0b6dd-7935-11ec-a32c-48f17f64520d First run 2022 -01-19 14 :40:50.280643+00:00 Compare items between two runs \ud83d\udd17 Boxs comes with a command-line interface that allows to interact with the cached data. It can be used e.g. to compare some data artifacts between different runs: $ boxs -i 'my_python_module' -b 'my-box-id' diff :train_data:c0b :train_data:0e6 -- -y | head ,Unnamed: 0 ,manufacturer,year,length,price ,Unnamed: 0 ,manufacturer,year,length,price 11263 ,11263,lagoon,2003,12.37,209000 | 6640 ,6640,ohlson ( se ) ,1980,8.8,15308 7536 ,7536,bremer bootsbau vegesack ( de ) ,1979,14.2,61898 | 3036 ,3036,prout sail boats,1980,15.0,110000 9778 ,9778,beneteau,2007,17.8,267000 | 1241 ,1241,bavaria,2018,9.99,118044 3122 ,3122,UNKNOWN,1930,9.25,4034 | 11463 ,11463,ovington boats sail boats,1998,9.42,36860 252 ,252,UNKNOWN,1999,18.84,661860 | 7617 ,7617,jeanneau,2013,13.34,115000 Where to go from here? \ud83d\udd17 Read the user guide for some more in-depth explanation about boxs and its concepts. What types of values can be stored? Standard python values Pandas Tensorflow How to write value types for your own values? How to use all functions of the CLI: Command line tool functions? Where can I store the data? boxs.filesystem.FileSystemStorage","title":"Getting started"},{"location":"getting_started/#getting-started","text":"","title":"Getting started"},{"location":"getting_started/#install-the-library","text":"Install the latest version from PyPI using pip: pip install boxs","title":"Install the library"},{"location":"getting_started/#configure-where-boxs-stores-your-data","text":"Within your python script, import boxs and create a new Box with a Storage : import boxs ... storage = boxs . FileSystemStorage ( '/path/to/my/data' ) box = boxs . Box ( 'my-box-id' , storage )","title":"Configure where boxs stores your data"},{"location":"getting_started/#store-data-in-your-box","text":"Use the store() function to store your data, which returns a DataInfo object with a reference to the stored data and some additional meta-data: ... def my_function ( x ): ... value = ... data = boxs . store ( value , box = 'my-box-id' , name = 'my-data' ) return data","title":"Store data in your box"},{"location":"getting_started/#load-the-data-from-the-reference","text":"Loading the data can be done either directly on the DataInfo object, or by giving it as argument to the free load() function from the boxs package: ... def my_other_function ( data ): value = boxs . load ( data ) # or directly from the reference value = data . load ()","title":"Load the data from the reference"},{"location":"getting_started/#list-your-last-runs","text":"Boxs comes with a command-line interface that allows to interact with the cached data. It can be used e.g. to list the runs: $ boxs -i 'my_python_module' -b 'my-box-id' list-runs List runs | box_id | run_id | name | time | my-box-id 0e63ad74-8102-11ec-9c51-48f17f64520d 2022 -01-29 12 :50:44.422651+00:00 my-box-id 12d03f94-7e0a-11ec-9020-48f17f64520d saved_model 2022 -01-25 18 :10:35.297825+00:00 my-box-id ed923ea0-7df8-11ec-9020-48f17f64520d 2022 -01-25 16 :07:43.658161+00:00 my-box-id 118d9332-7df3-11ec-9020-48f17f64520d 2022 -01-25 15 :25:47.026477+00:00 my-box-id bec3dfb2-7df2-11ec-9020-48f17f64520d 2022 -01-25 15 :23:28.143102+00:00 my-box-id c5caaee0-7d2e-11ec-9020-48f17f64520d 2022 -01-24 16 :00:38.460836+00:00 my-box-id c0b342b4-7c9d-11ec-abee-48f17f64520d 2022 -01-23 22 :42:32.900216+00:00 my-box-id bb157404-7c9c-11ec-abee-48f17f64520d 2022 -01-23 22 :36:59.329551+00:00 my-box-id cbd0b6dd-7935-11ec-a32c-48f17f64520d First run 2022 -01-19 14 :40:50.280643+00:00","title":"List your last runs"},{"location":"getting_started/#compare-items-between-two-runs","text":"Boxs comes with a command-line interface that allows to interact with the cached data. It can be used e.g. to compare some data artifacts between different runs: $ boxs -i 'my_python_module' -b 'my-box-id' diff :train_data:c0b :train_data:0e6 -- -y | head ,Unnamed: 0 ,manufacturer,year,length,price ,Unnamed: 0 ,manufacturer,year,length,price 11263 ,11263,lagoon,2003,12.37,209000 | 6640 ,6640,ohlson ( se ) ,1980,8.8,15308 7536 ,7536,bremer bootsbau vegesack ( de ) ,1979,14.2,61898 | 3036 ,3036,prout sail boats,1980,15.0,110000 9778 ,9778,beneteau,2007,17.8,267000 | 1241 ,1241,bavaria,2018,9.99,118044 3122 ,3122,UNKNOWN,1930,9.25,4034 | 11463 ,11463,ovington boats sail boats,1998,9.42,36860 252 ,252,UNKNOWN,1999,18.84,661860 | 7617 ,7617,jeanneau,2013,13.34,115000","title":"Compare items between two runs"},{"location":"getting_started/#where-to-go-from-here","text":"Read the user guide for some more in-depth explanation about boxs and its concepts. What types of values can be stored? Standard python values Pandas Tensorflow How to write value types for your own values? How to use all functions of the CLI: Command line tool functions? Where can I store the data? boxs.filesystem.FileSystemStorage","title":"Where to go from here?"},{"location":"user_guide/","text":"User guide \ud83d\udd17 This user guide can be used as a starting point for getting a deeper understanding of the inner workings of the boxs library. It is meant for users who want to learn about individual details or who plan to extend its features by developing own value types or transformers. Data organization \ud83d\udd17 Boxs keeps track of data items and their dependencies that are created when executing python code. Data items are identified by some automatic derived data_id , but for easier usage user-defined unique names within a single run are supported, too. Each execution leads to a new set of data items without overwriting anything. This allows to compare them across different \"runs\". All data items are organized in \"Boxes\", that can be used for grouping together related items. Multiple Boxes can share a single Storage, which actually stores the data and their meta-data. Each individual data item can be referenced by 3 different ids: box_id: The id of the box, in which the data item is stored. data_id: The id identifying the same data entity across multiple runs. run_id: The id that identifies the run in which this data item was created. Warning Boxs treats all data as immutable. Once written, a data item can't be updated. Instead a new data item with a different run_id should be used. Even though deleting a run and reusing its run_id is possible, it is HIGHLY discouraged since doing so can lead to inconsistencies especially with dependency tracking across different runs. User API \ud83d\udd17 Boxs user API can be imported from the boxs package. All classes and functions that are meant for users, are importable from the top level package. store() \ud83d\udd17 boxs.store() is the function that stores an actual value. It takes a couple of arguments, that influence where the data is stored, how the value is serialized, how its data id is calculated and what additional meta-data should be stored along with it. The full signature of the method looks like this: def store ( value , * parents , name = None , origin = ORIGIN_FROM_FUNCTION_NAME , tags = None , meta = None , value_type = None , run_id = None , box = None ) -> boxs . DataInfo : The function returns an object of type boxs.DataInfo . This type contains a reference to the stored data, which allows to load it again at a later time, and some additional meta information about it, including how it was stored. store() arguments are described as follows: value \ud83d\udd17 value contains the data that should be stored. Out of the box, boxs supports natively a couple of different types that can be stored: String Bytes/Bytebuffer Stream Files or directories in form of pathlib.Path With some limitation it can store list s and dict s, too, as long as every contained value can be serialized to JSON without the need of a custom JSONEncoder . All other types of values can be stored either by explicitly setting the value_type argument or adding one that supports this type to the box which will contain the value. *parents \ud83d\udd17 Boxs supports tracking dependencies between different values. This can be helpful e.g. when trying to understand the impact of changes in complex situations or when data is reused from different runs. Adding already stored data items as parents to a new data item is done by providing them as additional positional arguments to the store() call, e.g.: import boxs ... def fetch_data (): ... data = boxs . store ( data_values , box = 'my-box-id' , name = 'data' ) return data def partition_data ( data ): ... train_data = boxs . store ( train_values , data , box = 'my-box-id' , name = 'train_data' ) eval_data = boxs . store ( eval_value , data , box = 'my-box-id' , name = 'eval_data' ) return train_data , eval_data ... data = fetch_data () train_data , eval_data = partition_data ( data ) In this example the second function partition_data(data) stores two new data items train_data and eval_data using data as a parent data item. origin=ORIGIN_FROM_FUNCTION_NAME, \ud83d\udd17 Stored data items are referenced by a data_id, that is automatically derived from the origin of the data, defined by this keyword argument, and their parents. The origin is meant to describe in textual fashion, where some data originated. Its argument value can be either a str , or a Callable that returns a string. As a default, a callable is used, that extracts the name of the function from the stack, where store() is called from. The callable can optionally take a OriginContext object, from whose attributes the origin can be constructed. For more information take a look at the type of the OriginMappingFunction . name=None \ud83d\udd17 Referencing all data just from its automatically generated data_id is not the most convenient way for users. With every new dependency or some changes to the origin the data id changes to something completely different, so it becomes hard to keep track of things. To alleviate this, data items can be named by providing a value for the name keyword argument when storing the data. These names have to be unique within a run and can be used to refer to a specific data item from the command line. As a default, no names are given. tags=None \ud83d\udd17 Often it can be helpful to group data items by some criteria. This is why one can assign a set of tags to each data item when storing new data. These tags are mappings from string keys to string values. The tags can later be used for listing data items or determine how they should be handled. As a default, no tags are used. meta=None \ud83d\udd17 The meta keyword argument is meant for storing arbitrary meta-data about the item that might be useful later. This can be things like information about the size or source of data, e.g. a date which tells the update date of its data source. In general, all keys in meta must be strings. The values can differ, though. It can be any of the types that are supported by the python JSON encoder, so even dicts and lists can be used, as long as all values they contain can be serialized to JSON. Boxs uses the same meta-data internally, for keeping track of the type of the value as well as some useful information like checksums or size of the data. So when inspecting the meta attribute of a data item, not only user-defined meta-data is shown. value_type=None \ud83d\udd17 ValueType s are the mechanism that allows to store values in the first place. In order to know, how to serialize and deserialize a specific value, boxs needs a corresponding value type. For a set of common used types, boxs has a predefined list of value types that are used, e.g. for files, strings, bytes or stream, so the value_type argument doesn't need to be set and can stay on its default None . For custom types though, a value_type has to be provided. run_id=None \ud83d\udd17 Boxs automatically generates a new run_id every time, it is run in a new process. This run_id allows to correlate the version of a specific data item to a single invocation of the script, that created the data. There might be situations, where the user wants to override this automatic mechanism and do a manual run_id management. In this case, providing a custom run_id will override the automatically generated one. box=None \ud83d\udd17 Boxs organizes data in collections, called \"boxes\". This keyword argument can be used for specifying, in which box the data should be stored. Its value can be either a str with the box_id of the box, or the Box object itself. If no box is specified, the default_box from the configuration is used. Since a box is required, a ValueError is raised, if no box is specified neither as keyword argument nor in the configuration. load() \ud83d\udd17 Once a value has been stored, the question is now, how to load it once we need to use it again. For this boxs provides a boxs.load() function, that takes a reference to the data item and returns the stored value, that can be of any type. def load ( data , value_type = None ) -> Any : data \ud83d\udd17 The data item whose value should be loaded. data can be of the two types, either boxs.data.DataInfo or boxs.data.DataRef . DataInfo is the type returned by the store() method. It contains information about the data item, how it was stored and its ancestors. In contrast, DataRef contains only the necessary ids for uniquely identifying a data item. Both, DataInfo and DataRef provide a load() method just for convenience, that internally use the boxs.load() function. value_type=None \ud83d\udd17 The ValueType to use for converting the stored data to a python value. Usually, this doesn't need to be provided and can be left as its default None , since when storing of a value, the used value_type is added to the meta-data of the item, so that the same value_type can be reused, when the value is loaded again. Sometimes though, a user wants to use a different value type when loading data. In this case the value_type provided explicitly when calling load() can override the value type that is stored with the value. info() \ud83d\udd17 info() returns the DataInfo about a data item from its DataRef reference. This function is usually not called directly, because it is more convenient to use the corresponding property DataRef.info that uses the info() function internally. ValueType \ud83d\udd17 Within a python script different types of data are used. In order to know, how these different values can be stored and loaded, boxs uses the concept of ValueType s . A value type corresponds usually to one specific python type that it supports. ValueType defines two methods, that are used for actually writing the value to storage and reading it at a later time: @abc . abstractmethod def write_value_to_writer ( self , value , writer ): raise NotImplementedError @abc . abstractmethod def read_value_from_reader ( self , reader ): raise NotImplementedError ValueType.write_value_to_writer(value, writer) takes two arguments, value and writer. value is the value, that should be stored. The writer argument points to a storage specific implementation of the Writer interface, that allows to write data and the additional infos to the storage. ValueType.read_value_from_reader(reader) takes only a single argument. reader contains a storage specific implementation of the Reader interface, that allows to read data or infos back from storage. Each Box contains a pre-defined list of value types for common types like strings, bytes or files and directories. These value types are automatically used depending on the type of value . This works by them implementing another method of the ValueType interface, supports(value) : def supports ( self , value ): return False This method is given a value that should be stored and returns, if it supports writing this value or not. When a box should store a value without an explicit defined value type, it loops through its list of default types and uses the first type that returns True when its supports(value) method is called. ValueType defines two additional methods, that are used for recreating a value that has been stored before. When a value has been stored, boxs calls the get_specification() method of the used value type, which returns a string specification of the value type. This specification is then added as an additional field 'value_type' to the meta-data. Once this value should be loaded, the corresponding value type is recreated using the class method from_specification(cls, specification) which takes the specification string from the meta-data and returns a ValueType instance that is then used for reading the value. Box \ud83d\udd17 A Box is the class that actually implements the logic of storing and loading of values. Its interface matches the free functions store() , load() and info() from the boxs package once created: store() see boxs.store() for a description load() see boxs.load() for a description info() see boxs.info() for a description Before a box can be used, it needs to be defined. This is done by creating a new instance of its class: import boxs ... box = boxs . Box ( 'my-box-id' , storage ) Its constructor takes a string containing the box_id and the underlying storage object, that actually stores the data of the items stored in the box. When a Box is created, it registers itself with its box_id . This allows to find the box by its id at a later time, using the get_box(box_id) function. A box comes with a pre-defined list of value types to support storing a some common types. Additional ValueType can be added by its add_value_type(value_type) method. This method adds the new value type at the beginning of the list, so that it takes precedence before the standard types. Storage \ud83d\udd17 Storage is the interface that defines what methods storage implementations have to implement and adhere to, to be used by boxs for storing and loading data. Reading and writing items \ud83d\udd17 A Storage implementation provides the means to read and write data items by creating new storage specific readers and writers for each data item that should be stored or loaded. Responsible for this are the two methods create_reader(item) and create_writer(item, name, tags) of the Storage interface. In both cases the argument item is of type boxs.storage.Item which contains the ids of the item to be read or written. @abc . abstractmethod def create_reader ( self , item ): \"\"\" Returns: boxs.storage.Reader: The reader that will load the data from the storage. \"\"\" @abc . abstractmethod def create_writer ( self , item , name = None , tags = None ): \"\"\" Returns: boxs.storage.Writer: The writer that will write the data into the storage. \"\"\" Writer \ud83d\udd17 A Writer implementation has to inherit from the boxs.storage.Writer base class. The base class defines a set of properties and methods that are used within boxs to write data items. When implementing the interface, only 2 methods are needed: @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream to which the data content should be written. Returns: io.RawIOBase: The binary io-stream. \"\"\" @abc . abstractmethod def write_info ( self , info ): \"\"\" Write the info for the data item to the storage. Args: info (Dict[str,Any]): The information about the new data item. \"\"\" as_stream() is used by the individual value types to transfer the actual data of the values that should be stored. The implementation has to return a binary stream, that is not already opened. The second method write_info(info) is called by boxs, once the data has been written. It takes a single dictionary as argument, that contains information describing the data item. The Writer implementation shouldn't expect anything about the format of the dictionary. The only guaranteed property is that it can be serialized using the standard JSON library. Both methods must raise a boxs.errors.DataCollision exception when an item with the same ids already exists. Alternatively, the error can be raised when the writer is created. Reader \ud83d\udd17 Similar to the Writer class, the Reader class has the corresponding 2 methods: @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream from which the data content can be read. Returns: io.RawIOBase: A stream instance from which the data can be read. \"\"\" @property @abc . abstractmethod def info ( self ): \"\"\"Dictionary containing information about the data.\"\"\" as_stream() is used by the individual value types to read the actual data of the value that was stored. The implementation has to return a binary stream, that is not already opened. info is a property, that returns the info dictionary, that was previously written. Ideally, the implementation caches the info once it has been read. Both methods must raise a boxs.errors.DataNotFound exception when the item that should be read, doesn't exist. Alternatively, the error can be raised when the reader is created. Querying and manipulating a storage \ud83d\udd17 Besides creating the Writer or Reader , the Storage interface contains additional methods, that are used for querying or manipulating the stored data items. These methods are currently only used by the command-line interface . Warning The Storage interface is not meant to be used directly by the user, but should be regarded as an implementation detail of boxs whose interface might change between versions. This does NOT include the interfaces Writer and Reader which have to be used by ValueType implementations and therefore should be stable. @abc . abstractmethod def list_runs ( self , box_id , limit = None , name_filter = None ): \"\"\" List the runs within a box stored in this storage. The runs should be returned in descending order of their start time. Args: box_id (str): `box_id` of the box in which to look for runs. limit (Optional[int]): Limits the returned runs to maximum `limit` number. Defaults to `None` in which case all runs are returned. name_filter (Optional[str]): If set, only include runs which have names that have the filter as prefix. Defaults to `None` in which case all runs are returned. Returns: List[box.storage.Run]: The runs. \"\"\" @abc . abstractmethod def list_items ( self , item_query ): \"\"\" List all items that match a given query. The item query can contain parts of box id, run id or run name and data id or data name. If a query value is not set (`== None`) it is not used as a filter criteria. Args: item_query (boxs.storage.ItemQuery): The query which defines which items should be listed. Returns: List[box.storage.Item]: The runs. \"\"\" @abc . abstractmethod def set_run_name ( self , box_id , run_id , name ): \"\"\" Set the name of a run. The name can be updated and removed by providing `None`. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be named. name (Optional[str]): New name of the run. If `None`, an existing name will be removed. Returns: box.storage.Run: The run with its new name. \"\"\" @abc . abstractmethod def delete_run ( self , box_id , run_id ): \"\"\" Delete all the data of the specified run. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be deleted. \"\"\" Transformer \ud83d\udd17 Transformers are a mechanism for extending how data is stored and what meta-data is stored alongside. This works by wrapping the Reader and Writer that are created by the Storage and returning a different reader/writer. Boxs comes with some ready-to-use transformers. The StatisticsTransformer gathers additional statistics about each data item like the size in bytes or number of lines. Another built-in transformer is the ChecksumTransformer which calculates checksums when storing data and verifies the checksum when that data is loaded again. This allows to detect transfer errors and can be used later for de-duplicating the data stored in a storage. Using transformers \ud83d\udd17 Enabling transformers is done on a per-box level. A transformer is enabled by adding it as positional argument to instantiation of the box that should use it: import boxs box = boxs . Box ( 'my-box-id' , boxs . FileSystemStorage ( '/my/path/to/storage/dir' ), boxs . StatisticsTransformer (), boxs . ChecksumTransformer (), ) Implementing transformers \ud83d\udd17 The Transformer base class contains only two simple methods: def transform_writer ( self , writer ): return writer def transform_reader ( self , reader ): return reader transform_writer(writer) takes a Writer instance as argument and returns a new writer. This allows to intercept the write operations and modify the data as it is written. The writer gives access to the item specific meta-data, too, so that the transformed writer can add new attributes. The implementation of the base class returns the same writer it gets, so doing nothing. transform_reader(reader) works in the same way. It receives a Reader instance that can be wrapped with an own implementation that modifies the data as it is being read. Modifying meta-data can be done, too, but is not recommended, since it creates an inconsistency between the meta-data in the storage, and the one that is seen by the value type loading the value. The base implementation returns the reader without any modification. To make the implementation easier, boxs.transformer contains already a reader and a writer that delegates all its methods to a wrapped reader/writer. These DelegatingReader and DelegatingWriter classes can be used for implementing a custom transformer. Similarly, If the data stream should be intercepted, the boxs.io.DelegatingStream class can be used for modifying the read() or write() operations on the stream. Configuration \ud83d\udd17 Even though, boxs tries to minimize the amount of steps necessary to use it, some aspects of it can be configured. For this it uses internally a configuration, that is returned from its get_config() function. The configuration is automatically created on first use. Configurable values \ud83d\udd17 default_box \ud83d\udd17 One configuration value that can be set is the default_box . This value is a string, that contains the box_id of the box that should be used, if no box is explicitly specified. The value can be either set directly import boxs config = boxs . get_config () config . default_box = 'my-default-box' or as part of the environment by specifying the environment variable BOXS_DEFAULT_BOX . init_module \ud83d\udd17 The value 'init_module' contains the module name of python module, that should be automatically imported once boxs has been initialized. This allows to make sure that a specific box has been defined before the code using it is executed. The value can be either set directly import boxs config = boxs . get_config () config . init_module = 'my_box_init' or as part of the environment by specifying the environment variable BOXS_INIT_MODULE . Warning Setting this value at run-time will lead to the module getting imported if it hasn't been loaded yet. Be careful about circular dependencies between this module and boxs. How to use boxs \ud83d\udd17 Now with some knowledge about the different concepts within boxs at our hands, let's dive into the topic of how to put the library to good use. Install the library \ud83d\udd17 Use stable release from PyPI \ud83d\udd17 All stable versions of bandsaw are available on PyPI and can be downloaded and installed from there. The easiest option to get it installed into your python environment is by using pip : pip install boxs Use from source \ud83d\udd17 Boxs's Git repository is available for everyone and can easily be cloned into a new repository on your local machine: $ cd /your/local/directory $ git clone https://gitlab.com/kantai/boxs.git $ cd boxs If you want to make changes to library, please follow the guidance in the README.md on how to setup the necessary tools for testing your changes. If you just want to use the library, it is sufficient to add the path to your local boxs repository to your $PYTHONPATH variable, e.g.: $ export PYTHONPATH = \" $PYTHONPATH :/your/local/directory/boxs\"","title":"User guide"},{"location":"user_guide/#user-guide","text":"This user guide can be used as a starting point for getting a deeper understanding of the inner workings of the boxs library. It is meant for users who want to learn about individual details or who plan to extend its features by developing own value types or transformers.","title":"User guide"},{"location":"user_guide/#data-organization","text":"Boxs keeps track of data items and their dependencies that are created when executing python code. Data items are identified by some automatic derived data_id , but for easier usage user-defined unique names within a single run are supported, too. Each execution leads to a new set of data items without overwriting anything. This allows to compare them across different \"runs\". All data items are organized in \"Boxes\", that can be used for grouping together related items. Multiple Boxes can share a single Storage, which actually stores the data and their meta-data. Each individual data item can be referenced by 3 different ids: box_id: The id of the box, in which the data item is stored. data_id: The id identifying the same data entity across multiple runs. run_id: The id that identifies the run in which this data item was created. Warning Boxs treats all data as immutable. Once written, a data item can't be updated. Instead a new data item with a different run_id should be used. Even though deleting a run and reusing its run_id is possible, it is HIGHLY discouraged since doing so can lead to inconsistencies especially with dependency tracking across different runs.","title":"Data organization"},{"location":"user_guide/#user-api","text":"Boxs user API can be imported from the boxs package. All classes and functions that are meant for users, are importable from the top level package.","title":"User API"},{"location":"user_guide/#store","text":"boxs.store() is the function that stores an actual value. It takes a couple of arguments, that influence where the data is stored, how the value is serialized, how its data id is calculated and what additional meta-data should be stored along with it. The full signature of the method looks like this: def store ( value , * parents , name = None , origin = ORIGIN_FROM_FUNCTION_NAME , tags = None , meta = None , value_type = None , run_id = None , box = None ) -> boxs . DataInfo : The function returns an object of type boxs.DataInfo . This type contains a reference to the stored data, which allows to load it again at a later time, and some additional meta information about it, including how it was stored. store() arguments are described as follows:","title":"store()"},{"location":"user_guide/#value","text":"value contains the data that should be stored. Out of the box, boxs supports natively a couple of different types that can be stored: String Bytes/Bytebuffer Stream Files or directories in form of pathlib.Path With some limitation it can store list s and dict s, too, as long as every contained value can be serialized to JSON without the need of a custom JSONEncoder . All other types of values can be stored either by explicitly setting the value_type argument or adding one that supports this type to the box which will contain the value.","title":"value"},{"location":"user_guide/#parents","text":"Boxs supports tracking dependencies between different values. This can be helpful e.g. when trying to understand the impact of changes in complex situations or when data is reused from different runs. Adding already stored data items as parents to a new data item is done by providing them as additional positional arguments to the store() call, e.g.: import boxs ... def fetch_data (): ... data = boxs . store ( data_values , box = 'my-box-id' , name = 'data' ) return data def partition_data ( data ): ... train_data = boxs . store ( train_values , data , box = 'my-box-id' , name = 'train_data' ) eval_data = boxs . store ( eval_value , data , box = 'my-box-id' , name = 'eval_data' ) return train_data , eval_data ... data = fetch_data () train_data , eval_data = partition_data ( data ) In this example the second function partition_data(data) stores two new data items train_data and eval_data using data as a parent data item.","title":"*parents"},{"location":"user_guide/#originorigin_from_function_name","text":"Stored data items are referenced by a data_id, that is automatically derived from the origin of the data, defined by this keyword argument, and their parents. The origin is meant to describe in textual fashion, where some data originated. Its argument value can be either a str , or a Callable that returns a string. As a default, a callable is used, that extracts the name of the function from the stack, where store() is called from. The callable can optionally take a OriginContext object, from whose attributes the origin can be constructed. For more information take a look at the type of the OriginMappingFunction .","title":"origin=ORIGIN_FROM_FUNCTION_NAME,"},{"location":"user_guide/#namenone","text":"Referencing all data just from its automatically generated data_id is not the most convenient way for users. With every new dependency or some changes to the origin the data id changes to something completely different, so it becomes hard to keep track of things. To alleviate this, data items can be named by providing a value for the name keyword argument when storing the data. These names have to be unique within a run and can be used to refer to a specific data item from the command line. As a default, no names are given.","title":"name=None"},{"location":"user_guide/#tagsnone","text":"Often it can be helpful to group data items by some criteria. This is why one can assign a set of tags to each data item when storing new data. These tags are mappings from string keys to string values. The tags can later be used for listing data items or determine how they should be handled. As a default, no tags are used.","title":"tags=None"},{"location":"user_guide/#metanone","text":"The meta keyword argument is meant for storing arbitrary meta-data about the item that might be useful later. This can be things like information about the size or source of data, e.g. a date which tells the update date of its data source. In general, all keys in meta must be strings. The values can differ, though. It can be any of the types that are supported by the python JSON encoder, so even dicts and lists can be used, as long as all values they contain can be serialized to JSON. Boxs uses the same meta-data internally, for keeping track of the type of the value as well as some useful information like checksums or size of the data. So when inspecting the meta attribute of a data item, not only user-defined meta-data is shown.","title":"meta=None"},{"location":"user_guide/#value_typenone","text":"ValueType s are the mechanism that allows to store values in the first place. In order to know, how to serialize and deserialize a specific value, boxs needs a corresponding value type. For a set of common used types, boxs has a predefined list of value types that are used, e.g. for files, strings, bytes or stream, so the value_type argument doesn't need to be set and can stay on its default None . For custom types though, a value_type has to be provided.","title":"value_type=None"},{"location":"user_guide/#run_idnone","text":"Boxs automatically generates a new run_id every time, it is run in a new process. This run_id allows to correlate the version of a specific data item to a single invocation of the script, that created the data. There might be situations, where the user wants to override this automatic mechanism and do a manual run_id management. In this case, providing a custom run_id will override the automatically generated one.","title":"run_id=None"},{"location":"user_guide/#boxnone","text":"Boxs organizes data in collections, called \"boxes\". This keyword argument can be used for specifying, in which box the data should be stored. Its value can be either a str with the box_id of the box, or the Box object itself. If no box is specified, the default_box from the configuration is used. Since a box is required, a ValueError is raised, if no box is specified neither as keyword argument nor in the configuration.","title":"box=None"},{"location":"user_guide/#load","text":"Once a value has been stored, the question is now, how to load it once we need to use it again. For this boxs provides a boxs.load() function, that takes a reference to the data item and returns the stored value, that can be of any type. def load ( data , value_type = None ) -> Any :","title":"load()"},{"location":"user_guide/#data","text":"The data item whose value should be loaded. data can be of the two types, either boxs.data.DataInfo or boxs.data.DataRef . DataInfo is the type returned by the store() method. It contains information about the data item, how it was stored and its ancestors. In contrast, DataRef contains only the necessary ids for uniquely identifying a data item. Both, DataInfo and DataRef provide a load() method just for convenience, that internally use the boxs.load() function.","title":"data"},{"location":"user_guide/#value_typenone_1","text":"The ValueType to use for converting the stored data to a python value. Usually, this doesn't need to be provided and can be left as its default None , since when storing of a value, the used value_type is added to the meta-data of the item, so that the same value_type can be reused, when the value is loaded again. Sometimes though, a user wants to use a different value type when loading data. In this case the value_type provided explicitly when calling load() can override the value type that is stored with the value.","title":"value_type=None"},{"location":"user_guide/#info","text":"info() returns the DataInfo about a data item from its DataRef reference. This function is usually not called directly, because it is more convenient to use the corresponding property DataRef.info that uses the info() function internally.","title":"info()"},{"location":"user_guide/#valuetype","text":"Within a python script different types of data are used. In order to know, how these different values can be stored and loaded, boxs uses the concept of ValueType s . A value type corresponds usually to one specific python type that it supports. ValueType defines two methods, that are used for actually writing the value to storage and reading it at a later time: @abc . abstractmethod def write_value_to_writer ( self , value , writer ): raise NotImplementedError @abc . abstractmethod def read_value_from_reader ( self , reader ): raise NotImplementedError ValueType.write_value_to_writer(value, writer) takes two arguments, value and writer. value is the value, that should be stored. The writer argument points to a storage specific implementation of the Writer interface, that allows to write data and the additional infos to the storage. ValueType.read_value_from_reader(reader) takes only a single argument. reader contains a storage specific implementation of the Reader interface, that allows to read data or infos back from storage. Each Box contains a pre-defined list of value types for common types like strings, bytes or files and directories. These value types are automatically used depending on the type of value . This works by them implementing another method of the ValueType interface, supports(value) : def supports ( self , value ): return False This method is given a value that should be stored and returns, if it supports writing this value or not. When a box should store a value without an explicit defined value type, it loops through its list of default types and uses the first type that returns True when its supports(value) method is called. ValueType defines two additional methods, that are used for recreating a value that has been stored before. When a value has been stored, boxs calls the get_specification() method of the used value type, which returns a string specification of the value type. This specification is then added as an additional field 'value_type' to the meta-data. Once this value should be loaded, the corresponding value type is recreated using the class method from_specification(cls, specification) which takes the specification string from the meta-data and returns a ValueType instance that is then used for reading the value.","title":"ValueType"},{"location":"user_guide/#box","text":"A Box is the class that actually implements the logic of storing and loading of values. Its interface matches the free functions store() , load() and info() from the boxs package once created: store() see boxs.store() for a description load() see boxs.load() for a description info() see boxs.info() for a description Before a box can be used, it needs to be defined. This is done by creating a new instance of its class: import boxs ... box = boxs . Box ( 'my-box-id' , storage ) Its constructor takes a string containing the box_id and the underlying storage object, that actually stores the data of the items stored in the box. When a Box is created, it registers itself with its box_id . This allows to find the box by its id at a later time, using the get_box(box_id) function. A box comes with a pre-defined list of value types to support storing a some common types. Additional ValueType can be added by its add_value_type(value_type) method. This method adds the new value type at the beginning of the list, so that it takes precedence before the standard types.","title":"Box"},{"location":"user_guide/#storage","text":"Storage is the interface that defines what methods storage implementations have to implement and adhere to, to be used by boxs for storing and loading data.","title":"Storage"},{"location":"user_guide/#reading-and-writing-items","text":"A Storage implementation provides the means to read and write data items by creating new storage specific readers and writers for each data item that should be stored or loaded. Responsible for this are the two methods create_reader(item) and create_writer(item, name, tags) of the Storage interface. In both cases the argument item is of type boxs.storage.Item which contains the ids of the item to be read or written. @abc . abstractmethod def create_reader ( self , item ): \"\"\" Returns: boxs.storage.Reader: The reader that will load the data from the storage. \"\"\" @abc . abstractmethod def create_writer ( self , item , name = None , tags = None ): \"\"\" Returns: boxs.storage.Writer: The writer that will write the data into the storage. \"\"\"","title":"Reading and writing items"},{"location":"user_guide/#writer","text":"A Writer implementation has to inherit from the boxs.storage.Writer base class. The base class defines a set of properties and methods that are used within boxs to write data items. When implementing the interface, only 2 methods are needed: @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream to which the data content should be written. Returns: io.RawIOBase: The binary io-stream. \"\"\" @abc . abstractmethod def write_info ( self , info ): \"\"\" Write the info for the data item to the storage. Args: info (Dict[str,Any]): The information about the new data item. \"\"\" as_stream() is used by the individual value types to transfer the actual data of the values that should be stored. The implementation has to return a binary stream, that is not already opened. The second method write_info(info) is called by boxs, once the data has been written. It takes a single dictionary as argument, that contains information describing the data item. The Writer implementation shouldn't expect anything about the format of the dictionary. The only guaranteed property is that it can be serialized using the standard JSON library. Both methods must raise a boxs.errors.DataCollision exception when an item with the same ids already exists. Alternatively, the error can be raised when the writer is created.","title":"Writer"},{"location":"user_guide/#reader","text":"Similar to the Writer class, the Reader class has the corresponding 2 methods: @abc . abstractmethod def as_stream ( self ): \"\"\" Return a stream from which the data content can be read. Returns: io.RawIOBase: A stream instance from which the data can be read. \"\"\" @property @abc . abstractmethod def info ( self ): \"\"\"Dictionary containing information about the data.\"\"\" as_stream() is used by the individual value types to read the actual data of the value that was stored. The implementation has to return a binary stream, that is not already opened. info is a property, that returns the info dictionary, that was previously written. Ideally, the implementation caches the info once it has been read. Both methods must raise a boxs.errors.DataNotFound exception when the item that should be read, doesn't exist. Alternatively, the error can be raised when the reader is created.","title":"Reader"},{"location":"user_guide/#querying-and-manipulating-a-storage","text":"Besides creating the Writer or Reader , the Storage interface contains additional methods, that are used for querying or manipulating the stored data items. These methods are currently only used by the command-line interface . Warning The Storage interface is not meant to be used directly by the user, but should be regarded as an implementation detail of boxs whose interface might change between versions. This does NOT include the interfaces Writer and Reader which have to be used by ValueType implementations and therefore should be stable. @abc . abstractmethod def list_runs ( self , box_id , limit = None , name_filter = None ): \"\"\" List the runs within a box stored in this storage. The runs should be returned in descending order of their start time. Args: box_id (str): `box_id` of the box in which to look for runs. limit (Optional[int]): Limits the returned runs to maximum `limit` number. Defaults to `None` in which case all runs are returned. name_filter (Optional[str]): If set, only include runs which have names that have the filter as prefix. Defaults to `None` in which case all runs are returned. Returns: List[box.storage.Run]: The runs. \"\"\" @abc . abstractmethod def list_items ( self , item_query ): \"\"\" List all items that match a given query. The item query can contain parts of box id, run id or run name and data id or data name. If a query value is not set (`== None`) it is not used as a filter criteria. Args: item_query (boxs.storage.ItemQuery): The query which defines which items should be listed. Returns: List[box.storage.Item]: The runs. \"\"\" @abc . abstractmethod def set_run_name ( self , box_id , run_id , name ): \"\"\" Set the name of a run. The name can be updated and removed by providing `None`. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be named. name (Optional[str]): New name of the run. If `None`, an existing name will be removed. Returns: box.storage.Run: The run with its new name. \"\"\" @abc . abstractmethod def delete_run ( self , box_id , run_id ): \"\"\" Delete all the data of the specified run. Args; box_id (str): `box_id` of the box in which the run is stored. run_id (str): Run id of the run which should be deleted. \"\"\"","title":"Querying and manipulating a storage"},{"location":"user_guide/#transformer","text":"Transformers are a mechanism for extending how data is stored and what meta-data is stored alongside. This works by wrapping the Reader and Writer that are created by the Storage and returning a different reader/writer. Boxs comes with some ready-to-use transformers. The StatisticsTransformer gathers additional statistics about each data item like the size in bytes or number of lines. Another built-in transformer is the ChecksumTransformer which calculates checksums when storing data and verifies the checksum when that data is loaded again. This allows to detect transfer errors and can be used later for de-duplicating the data stored in a storage.","title":"Transformer"},{"location":"user_guide/#using-transformers","text":"Enabling transformers is done on a per-box level. A transformer is enabled by adding it as positional argument to instantiation of the box that should use it: import boxs box = boxs . Box ( 'my-box-id' , boxs . FileSystemStorage ( '/my/path/to/storage/dir' ), boxs . StatisticsTransformer (), boxs . ChecksumTransformer (), )","title":"Using transformers"},{"location":"user_guide/#implementing-transformers","text":"The Transformer base class contains only two simple methods: def transform_writer ( self , writer ): return writer def transform_reader ( self , reader ): return reader transform_writer(writer) takes a Writer instance as argument and returns a new writer. This allows to intercept the write operations and modify the data as it is written. The writer gives access to the item specific meta-data, too, so that the transformed writer can add new attributes. The implementation of the base class returns the same writer it gets, so doing nothing. transform_reader(reader) works in the same way. It receives a Reader instance that can be wrapped with an own implementation that modifies the data as it is being read. Modifying meta-data can be done, too, but is not recommended, since it creates an inconsistency between the meta-data in the storage, and the one that is seen by the value type loading the value. The base implementation returns the reader without any modification. To make the implementation easier, boxs.transformer contains already a reader and a writer that delegates all its methods to a wrapped reader/writer. These DelegatingReader and DelegatingWriter classes can be used for implementing a custom transformer. Similarly, If the data stream should be intercepted, the boxs.io.DelegatingStream class can be used for modifying the read() or write() operations on the stream.","title":"Implementing transformers"},{"location":"user_guide/#configuration","text":"Even though, boxs tries to minimize the amount of steps necessary to use it, some aspects of it can be configured. For this it uses internally a configuration, that is returned from its get_config() function. The configuration is automatically created on first use.","title":"Configuration"},{"location":"user_guide/#configurable-values","text":"","title":"Configurable values"},{"location":"user_guide/#default_box","text":"One configuration value that can be set is the default_box . This value is a string, that contains the box_id of the box that should be used, if no box is explicitly specified. The value can be either set directly import boxs config = boxs . get_config () config . default_box = 'my-default-box' or as part of the environment by specifying the environment variable BOXS_DEFAULT_BOX .","title":"default_box"},{"location":"user_guide/#init_module","text":"The value 'init_module' contains the module name of python module, that should be automatically imported once boxs has been initialized. This allows to make sure that a specific box has been defined before the code using it is executed. The value can be either set directly import boxs config = boxs . get_config () config . init_module = 'my_box_init' or as part of the environment by specifying the environment variable BOXS_INIT_MODULE . Warning Setting this value at run-time will lead to the module getting imported if it hasn't been loaded yet. Be careful about circular dependencies between this module and boxs.","title":"init_module"},{"location":"user_guide/#how-to-use-boxs","text":"Now with some knowledge about the different concepts within boxs at our hands, let's dive into the topic of how to put the library to good use.","title":"How to use boxs"},{"location":"user_guide/#install-the-library","text":"","title":"Install the library"},{"location":"user_guide/#use-stable-release-from-pypi","text":"All stable versions of bandsaw are available on PyPI and can be downloaded and installed from there. The easiest option to get it installed into your python environment is by using pip : pip install boxs","title":"Use stable release from PyPI"},{"location":"user_guide/#use-from-source","text":"Boxs's Git repository is available for everyone and can easily be cloned into a new repository on your local machine: $ cd /your/local/directory $ git clone https://gitlab.com/kantai/boxs.git $ cd boxs If you want to make changes to library, please follow the guidance in the README.md on how to setup the necessary tools for testing your changes. If you just want to use the library, it is sufficient to add the path to your local boxs repository to your $PYTHONPATH variable, e.g.: $ export PYTHONPATH = \" $PYTHONPATH :/your/local/directory/boxs\"","title":"Use from source"},{"location":"storages/file/","text":"FileSystemStorage \ud83d\udd17 The FileSystemStorage stores the values, their meta-data and the information about the individual runs in a directory in the local file system. For this it takes a directory path as configuration, which is the root of all stored data. The directory structure inside looks like the following: \u2514\u2500\u2500 <box-id> \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 <data-id> \u2502 \u2502 \u251c\u2500\u2500 <run-id>.data \u2502 \u2502 \u251c\u2500\u2500 <run-id>.info \u2502 \u2502 \u251c\u2500\u2500 <other-run-id>.data \u2502 \u2502 \u2514\u2500\u2500 <other-run-id>.info \u2502 \u251c\u2500\u2500 <other-data-id> \u2502 \u2502 \u251c\u2500\u2500 <run-id>.data \u2502 \u2502 \u251c\u2500\u2500 <run-id>.info \u2502 \u2502 \u251c\u2500\u2500 <other-run-id>.data \u2502 \u2502 \u2514\u2500\u2500 <other-run-id>.info ... \u2502 \u2514\u2500\u2500 <another-data-id> \u2514\u2500\u2500 runs \u251c\u2500\u2500 <run-id> \u2502 \u251c\u2500\u2500 <data-id> \u2502 \u251c\u2500\u2500 <other-data-id> \u2502 \u251c\u2500\u2500 <another-data-id> \u2502 \u2514\u2500\u2500 _named \u2502 \u251c\u2500\u2500 <data-name> -> ../<data-id> \u2502 \u251c\u2500\u2500 <other-data-name> -> ../<other-data-id> \u2502 \u2514\u2500\u2500 <another-data-name> -> ../<another-data-id> ... \u2514\u2500\u2500 _named \u251c\u2500\u2500 <run-name> -> ../<run-id> \u2514\u2500\u2500 <other-run-name> -> ../<other-run-id> The root directory contains one subdirectory per box named with the box id. Within these box-directories, one finds two directories named \"data\" and \"runs\". \"data\" contains one subdirectory per data id and within each of those two files that contain the stored value (\".data\") and the information including the meta-data about this value (\".info\") per run, where this data item was created. \"runs\" doesn't contain any data itself, but just pointers to the data items, that were created in a run. For each new run, a subdirectory named with the run-id is created. This subdirectory contains empty files that are named with the data-ids of all data items that were created in this run. Additionally, each run directory can contains a subdirectory \"_named\" which contains symbolic links named with the name of a specific data item, that links to the file containing the data-id of this data item. The same mechanism is used on \"runs\" level, to map a run-name to its corresponding run-id. Here an abbreviated example of a storage directory tree: \u2514\u2500\u2500 my-box-id \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 1bb60c8869c65276 \u2502 \u2502 \u251c\u2500\u2500 118d9332-7df3-11ec-9020-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 118d9332-7df3-11ec-9020-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 bec3dfb2-7df2-11ec-9020-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 bec3dfb2-7df2-11ec-9020-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 c0b342b4-7c9d-11ec-abee-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 c0b342b4-7c9d-11ec-abee-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 c5caaee0-7d2e-11ec-9020-48f17f64520d.data \u2502 \u2502 \u2514\u2500\u2500 c5caaee0-7d2e-11ec-9020-48f17f64520d.info \u2502 \u251c\u2500\u2500 21bfb27c4a636f4e \u2502 \u2502 \u251c\u2500\u2500 0e63ad74-8102-11ec-9c51-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 0e63ad74-8102-11ec-9c51-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 118d9332-7df3-11ec-9020-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 118d9332-7df3-11ec-9020-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 bec3dfb2-7df2-11ec-9020-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 bec3dfb2-7df2-11ec-9020-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 c5caaee0-7d2e-11ec-9020-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 c5caaee0-7d2e-11ec-9020-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 ed923ea0-7df8-11ec-9020-48f17f64520d.data \u2502 \u2502 \u2514\u2500\u2500 ed923ea0-7df8-11ec-9020-48f17f64520d.info ... \u2502 \u2514\u2500\u2500 fc657a8c9d33b5fc \u2514\u2500\u2500 runs \u251c\u2500\u2500 0e63ad74-8102-11ec-9c51-48f17f64520d \u2502 \u251c\u2500\u2500 15d29183ad09cbfc \u2502 \u251c\u2500\u2500 21bfb27c4a636f4e \u2502 \u251c\u2500\u2500 6f31c9a1c68b3b02 \u2502 \u251c\u2500\u2500 7473d9676cbc377e \u2502 \u251c\u2500\u2500 800b5a5c9a972d3e \u2502 \u251c\u2500\u2500 b2560fb2c8b88621 \u2502 \u251c\u2500\u2500 cf64163dd7c1898c \u2502 \u251c\u2500\u2500 d91bf391601f6f53 \u2502 \u251c\u2500\u2500 ddb065be789696cb \u2502 \u251c\u2500\u2500 efb03082d67da076 \u2502 \u2514\u2500\u2500 _named \u2502 \u251c\u2500\u2500 encoded_eval_input -> ../800b5a5c9a972d3e \u2502 \u251c\u2500\u2500 encoded_eval_output -> ../ddb065be789696cb \u2502 \u251c\u2500\u2500 encoded_train_input -> ../7473d9676cbc377e \u2502 \u251c\u2500\u2500 encoded_train_output -> ../21bfb27c4a636f4e \u2502 \u251c\u2500\u2500 eval_data -> ../efb03082d67da076 \u2502 \u251c\u2500\u2500 normalized_eval_input -> ../6f31c9a1c68b3b02 \u2502 \u251c\u2500\u2500 normalized_train_input -> ../15d29183ad09cbfc \u2502 \u251c\u2500\u2500 tensorboard_logs -> ../b2560fb2c8b88621 \u2502 \u251c\u2500\u2500 train_data -> ../cf64163dd7c1898c \u2502 \u2514\u2500\u2500 trained_model -> ../d91bf391601f6f53 ... \u2514\u2500\u2500 _named \u251c\u2500\u2500 First run -> ../cbd0b6dd-7935-11ec-a32c-48f17f64520d \u251c\u2500\u2500 release_1.0 -> ../12d03f94-7e0a-11ec-9020-48f17f64520d \u2514\u2500\u2500 release_1.1 -> ../0e63ad74-8102-11ec-9c51-48f17f64520d Configuration \ud83d\udd17 The constructor of FileSystemStorage takes a single argument directory which denotes the directory, where it should store its data. Example \ud83d\udd17 import boxs ... storage = boxs . FileSystemStorage ( '/my/storage/directory' ) box = boxs . Box ( 'my-box-id' , storage )","title":"File"},{"location":"storages/file/#filesystemstorage","text":"The FileSystemStorage stores the values, their meta-data and the information about the individual runs in a directory in the local file system. For this it takes a directory path as configuration, which is the root of all stored data. The directory structure inside looks like the following: \u2514\u2500\u2500 <box-id> \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 <data-id> \u2502 \u2502 \u251c\u2500\u2500 <run-id>.data \u2502 \u2502 \u251c\u2500\u2500 <run-id>.info \u2502 \u2502 \u251c\u2500\u2500 <other-run-id>.data \u2502 \u2502 \u2514\u2500\u2500 <other-run-id>.info \u2502 \u251c\u2500\u2500 <other-data-id> \u2502 \u2502 \u251c\u2500\u2500 <run-id>.data \u2502 \u2502 \u251c\u2500\u2500 <run-id>.info \u2502 \u2502 \u251c\u2500\u2500 <other-run-id>.data \u2502 \u2502 \u2514\u2500\u2500 <other-run-id>.info ... \u2502 \u2514\u2500\u2500 <another-data-id> \u2514\u2500\u2500 runs \u251c\u2500\u2500 <run-id> \u2502 \u251c\u2500\u2500 <data-id> \u2502 \u251c\u2500\u2500 <other-data-id> \u2502 \u251c\u2500\u2500 <another-data-id> \u2502 \u2514\u2500\u2500 _named \u2502 \u251c\u2500\u2500 <data-name> -> ../<data-id> \u2502 \u251c\u2500\u2500 <other-data-name> -> ../<other-data-id> \u2502 \u2514\u2500\u2500 <another-data-name> -> ../<another-data-id> ... \u2514\u2500\u2500 _named \u251c\u2500\u2500 <run-name> -> ../<run-id> \u2514\u2500\u2500 <other-run-name> -> ../<other-run-id> The root directory contains one subdirectory per box named with the box id. Within these box-directories, one finds two directories named \"data\" and \"runs\". \"data\" contains one subdirectory per data id and within each of those two files that contain the stored value (\".data\") and the information including the meta-data about this value (\".info\") per run, where this data item was created. \"runs\" doesn't contain any data itself, but just pointers to the data items, that were created in a run. For each new run, a subdirectory named with the run-id is created. This subdirectory contains empty files that are named with the data-ids of all data items that were created in this run. Additionally, each run directory can contains a subdirectory \"_named\" which contains symbolic links named with the name of a specific data item, that links to the file containing the data-id of this data item. The same mechanism is used on \"runs\" level, to map a run-name to its corresponding run-id. Here an abbreviated example of a storage directory tree: \u2514\u2500\u2500 my-box-id \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 1bb60c8869c65276 \u2502 \u2502 \u251c\u2500\u2500 118d9332-7df3-11ec-9020-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 118d9332-7df3-11ec-9020-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 bec3dfb2-7df2-11ec-9020-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 bec3dfb2-7df2-11ec-9020-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 c0b342b4-7c9d-11ec-abee-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 c0b342b4-7c9d-11ec-abee-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 c5caaee0-7d2e-11ec-9020-48f17f64520d.data \u2502 \u2502 \u2514\u2500\u2500 c5caaee0-7d2e-11ec-9020-48f17f64520d.info \u2502 \u251c\u2500\u2500 21bfb27c4a636f4e \u2502 \u2502 \u251c\u2500\u2500 0e63ad74-8102-11ec-9c51-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 0e63ad74-8102-11ec-9c51-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 118d9332-7df3-11ec-9020-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 118d9332-7df3-11ec-9020-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 bec3dfb2-7df2-11ec-9020-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 bec3dfb2-7df2-11ec-9020-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 c5caaee0-7d2e-11ec-9020-48f17f64520d.data \u2502 \u2502 \u251c\u2500\u2500 c5caaee0-7d2e-11ec-9020-48f17f64520d.info \u2502 \u2502 \u251c\u2500\u2500 ed923ea0-7df8-11ec-9020-48f17f64520d.data \u2502 \u2502 \u2514\u2500\u2500 ed923ea0-7df8-11ec-9020-48f17f64520d.info ... \u2502 \u2514\u2500\u2500 fc657a8c9d33b5fc \u2514\u2500\u2500 runs \u251c\u2500\u2500 0e63ad74-8102-11ec-9c51-48f17f64520d \u2502 \u251c\u2500\u2500 15d29183ad09cbfc \u2502 \u251c\u2500\u2500 21bfb27c4a636f4e \u2502 \u251c\u2500\u2500 6f31c9a1c68b3b02 \u2502 \u251c\u2500\u2500 7473d9676cbc377e \u2502 \u251c\u2500\u2500 800b5a5c9a972d3e \u2502 \u251c\u2500\u2500 b2560fb2c8b88621 \u2502 \u251c\u2500\u2500 cf64163dd7c1898c \u2502 \u251c\u2500\u2500 d91bf391601f6f53 \u2502 \u251c\u2500\u2500 ddb065be789696cb \u2502 \u251c\u2500\u2500 efb03082d67da076 \u2502 \u2514\u2500\u2500 _named \u2502 \u251c\u2500\u2500 encoded_eval_input -> ../800b5a5c9a972d3e \u2502 \u251c\u2500\u2500 encoded_eval_output -> ../ddb065be789696cb \u2502 \u251c\u2500\u2500 encoded_train_input -> ../7473d9676cbc377e \u2502 \u251c\u2500\u2500 encoded_train_output -> ../21bfb27c4a636f4e \u2502 \u251c\u2500\u2500 eval_data -> ../efb03082d67da076 \u2502 \u251c\u2500\u2500 normalized_eval_input -> ../6f31c9a1c68b3b02 \u2502 \u251c\u2500\u2500 normalized_train_input -> ../15d29183ad09cbfc \u2502 \u251c\u2500\u2500 tensorboard_logs -> ../b2560fb2c8b88621 \u2502 \u251c\u2500\u2500 train_data -> ../cf64163dd7c1898c \u2502 \u2514\u2500\u2500 trained_model -> ../d91bf391601f6f53 ... \u2514\u2500\u2500 _named \u251c\u2500\u2500 First run -> ../cbd0b6dd-7935-11ec-a32c-48f17f64520d \u251c\u2500\u2500 release_1.0 -> ../12d03f94-7e0a-11ec-9020-48f17f64520d \u2514\u2500\u2500 release_1.1 -> ../0e63ad74-8102-11ec-9c51-48f17f64520d","title":"FileSystemStorage"},{"location":"storages/file/#configuration","text":"The constructor of FileSystemStorage takes a single argument directory which denotes the directory, where it should store its data.","title":"Configuration"},{"location":"storages/file/#example","text":"import boxs ... storage = boxs . FileSystemStorage ( '/my/storage/directory' ) box = boxs . Box ( 'my-box-id' , storage )","title":"Example"},{"location":"transformers/checksum/","text":"ChecksumTransformer \ud83d\udd17 The ChecksumTransformer generates a checksum from a value when it is stored and adds it as additional meta-data attribute. When the value is loaded later, the checksum is again computed and verified. If the checksum differs from the checksum that was created when storing the value, a boxs.checksum.DataChecksumMismatch error is raised. The checksum allows detecting transmission errors or faulty value types, but it can be used for implementing some kind of deduplication scheme inside a Storage . The current implementation uses the blake2b hashing function with a configurable digest_size . Configuration \ud83d\udd17 When creating the ChecksumTransformer its constructor can take an optional digest_size argument. This defines the size of the used digest in bytes. If the argument is not given, a default size of 32 bytes is used. Additional meta-data attributes \ud83d\udd17 'checksum_digest' : The hex representation of the calculated digest. 'checksum_digest_size' : The size of the digest (not its representation) in bytes. 'checksum_algorithm' : 'black2b' Example \ud83d\udd17 import boxs ... box = boxs . Box ( 'my-box-id' , storage , boxs . ChecksumTransformer ( digest_size = 16 )) value_info = boxs . store ( 'My value \\n ' , box = box ) print ( value_info . meta [ 'checksum_digest' ]) print ( value_info . meta [ 'checksum_digest_size' ]) print ( value_info . meta [ 'checksum_algorithm' ]) try : value = value_info . load () except boxs . DataChecksumMismatch as error : print ( \"Checksum verification failed: %s \" , error )","title":"Checksum"},{"location":"transformers/checksum/#checksumtransformer","text":"The ChecksumTransformer generates a checksum from a value when it is stored and adds it as additional meta-data attribute. When the value is loaded later, the checksum is again computed and verified. If the checksum differs from the checksum that was created when storing the value, a boxs.checksum.DataChecksumMismatch error is raised. The checksum allows detecting transmission errors or faulty value types, but it can be used for implementing some kind of deduplication scheme inside a Storage . The current implementation uses the blake2b hashing function with a configurable digest_size .","title":"ChecksumTransformer"},{"location":"transformers/checksum/#configuration","text":"When creating the ChecksumTransformer its constructor can take an optional digest_size argument. This defines the size of the used digest in bytes. If the argument is not given, a default size of 32 bytes is used.","title":"Configuration"},{"location":"transformers/checksum/#additional-meta-data-attributes","text":"'checksum_digest' : The hex representation of the calculated digest. 'checksum_digest_size' : The size of the digest (not its representation) in bytes. 'checksum_algorithm' : 'black2b'","title":"Additional meta-data attributes"},{"location":"transformers/checksum/#example","text":"import boxs ... box = boxs . Box ( 'my-box-id' , storage , boxs . ChecksumTransformer ( digest_size = 16 )) value_info = boxs . store ( 'My value \\n ' , box = box ) print ( value_info . meta [ 'checksum_digest' ]) print ( value_info . meta [ 'checksum_digest_size' ]) print ( value_info . meta [ 'checksum_algorithm' ]) try : value = value_info . load () except boxs . DataChecksumMismatch as error : print ( \"Checksum verification failed: %s \" , error )","title":"Example"},{"location":"transformers/statistics/","text":"StatisticsTransformer \ud83d\udd17 The StatisticsTransformer gathers some statistics about a value when it is stored and adds those as additional meta-data attributes. Configuration \ud83d\udd17 None Additional meta-data attributes \ud83d\udd17 'size_in_bytes' : The number of written bytes when storing the value. 'number_of_lines' : The number of lines that the stored value contains. 'store_start' : The timestamp UTC in ISO format when storing the value began. 'store_end' : The timestamp UTC in ISO format when storing the value ended. Example \ud83d\udd17 import boxs ... box = boxs . Box ( 'my-box-id' , storage , boxs . StatisticsTransformer ()) value_info = boxs . store ( 'My value \\n in \\n multiple \\n lines. \\n ' , box = box ) print ( value_info . meta [ 'size_in_bytes' ]) print ( value_info . meta [ 'number_of_lines' ]) print ( value_info . meta [ 'store_start' ]) print ( value_info . meta [ 'store_end' ])","title":"Statistics"},{"location":"transformers/statistics/#statisticstransformer","text":"The StatisticsTransformer gathers some statistics about a value when it is stored and adds those as additional meta-data attributes.","title":"StatisticsTransformer"},{"location":"transformers/statistics/#configuration","text":"None","title":"Configuration"},{"location":"transformers/statistics/#additional-meta-data-attributes","text":"'size_in_bytes' : The number of written bytes when storing the value. 'number_of_lines' : The number of lines that the stored value contains. 'store_start' : The timestamp UTC in ISO format when storing the value began. 'store_end' : The timestamp UTC in ISO format when storing the value ended.","title":"Additional meta-data attributes"},{"location":"transformers/statistics/#example","text":"import boxs ... box = boxs . Box ( 'my-box-id' , storage , boxs . StatisticsTransformer ()) value_info = boxs . store ( 'My value \\n in \\n multiple \\n lines. \\n ' , box = box ) print ( value_info . meta [ 'size_in_bytes' ]) print ( value_info . meta [ 'number_of_lines' ]) print ( value_info . meta [ 'store_start' ]) print ( value_info . meta [ 'store_end' ])","title":"Example"},{"location":"value_types/common/","text":"Value types for common python values \ud83d\udd17 Boxs comes with some ready-to-use ValueType implementations, that allow to store python types that are common used. All of these value types are automatically available and used for the supported types. BytesValueType \ud83d\udd17 The BytesValueType allows to store binary values. Supported python types \ud83d\udd17 bytes , bytearray Configuration \ud83d\udd17 Not available Additional meta-data attributes \ud83d\udd17 None DirectoryValueType \ud83d\udd17 The DirectoryValueType can be used for storing directories and their content. These directories get added to a Zip archive that is then stored in the storage. Not all file properties are kept, because the Zip format doesn't support them. This is especially true for file permissions and owner and group information. These may change when loading a directory. Supported python types \ud83d\udd17 pathlib.Path that refer to an existing directory. Configuration \ud83d\udd17 When a directory is loaded, the path to the destination directory can be set by creating a new DirectoryValueType with the dir_path argument. If no dir_path is given, which is default, the directory is loaded to a temporary directory, that should be deleted by the user after its no longer needed. Additional meta-data attributes \ud83d\udd17 None FileValueType \ud83d\udd17 The FileValueType can be used for storing single files. No file properties are kept. This is especially true for file permissions and owner and group information. These may change when loading the file again. Supported python types \ud83d\udd17 pathlib.Path that refer to an existing file. Configuration \ud83d\udd17 When a file is loaded, the path to the destination file can be set by creating a new FileValueType with the file_path argument. If no file_path is given, which is default, the file is loaded to a temporary file, that should be deleted by the user after its no longer needed. Additional meta-data attributes \ud83d\udd17 None JsonValueType \ud83d\udd17 The JsonValueType can be used for storing lists and dictionaries of primitive values. It encodes those data structures as JSON string and stores it. Supported python types \ud83d\udd17 list and dict , as long, as they contain only values of types that can be serialized to JSON using the standard json encoder, without the need of a custom JSONEncoder class. Configuration \ud83d\udd17 Not available Additional meta-data attributes \ud83d\udd17 'media_type' : 'application/json' StreamValueType \ud83d\udd17 The StreamValueType can be used for storing the content of binary streams. The value type reads from this stream, until it reaches EOF. The stream is not automatically closed, so it can be reused. Supported python types \ud83d\udd17 typing.BinaryIO(IO[bytes]) Configuration \ud83d\udd17 Not available Additional meta-data attributes \ud83d\udd17 None StringValueType \ud83d\udd17 The StringValueType can be used for storing the content of binary streams. The value type reads from this stream, until it reaches EOF. The stream is not automatically closed, so it can be reused. The encoding that is used for storing the string can be set when defining the value_type explicitly. The encoding is stored in the meta-data and reused when loading a value. Supported python types \ud83d\udd17 str Configuration \ud83d\udd17 The value type supports configuring its default_encoding . This encoding will be used when storing a string. The encoding uses 'utf-8' as default. It can be used with a different default_encoding when a new instance of StringValueType is created that takes a different encoding as constructor argument. Additional meta-data attributes \ud83d\udd17 'encoding' : The encoding that was used storing this value.","title":"Common"},{"location":"value_types/common/#value-types-for-common-python-values","text":"Boxs comes with some ready-to-use ValueType implementations, that allow to store python types that are common used. All of these value types are automatically available and used for the supported types.","title":"Value types for common python values"},{"location":"value_types/common/#bytesvaluetype","text":"The BytesValueType allows to store binary values.","title":"BytesValueType"},{"location":"value_types/common/#supported-python-types","text":"bytes , bytearray","title":"Supported python types"},{"location":"value_types/common/#configuration","text":"Not available","title":"Configuration"},{"location":"value_types/common/#additional-meta-data-attributes","text":"None","title":"Additional meta-data attributes"},{"location":"value_types/common/#directoryvaluetype","text":"The DirectoryValueType can be used for storing directories and their content. These directories get added to a Zip archive that is then stored in the storage. Not all file properties are kept, because the Zip format doesn't support them. This is especially true for file permissions and owner and group information. These may change when loading a directory.","title":"DirectoryValueType"},{"location":"value_types/common/#supported-python-types_1","text":"pathlib.Path that refer to an existing directory.","title":"Supported python types"},{"location":"value_types/common/#configuration_1","text":"When a directory is loaded, the path to the destination directory can be set by creating a new DirectoryValueType with the dir_path argument. If no dir_path is given, which is default, the directory is loaded to a temporary directory, that should be deleted by the user after its no longer needed.","title":"Configuration"},{"location":"value_types/common/#additional-meta-data-attributes_1","text":"None","title":"Additional meta-data attributes"},{"location":"value_types/common/#filevaluetype","text":"The FileValueType can be used for storing single files. No file properties are kept. This is especially true for file permissions and owner and group information. These may change when loading the file again.","title":"FileValueType"},{"location":"value_types/common/#supported-python-types_2","text":"pathlib.Path that refer to an existing file.","title":"Supported python types"},{"location":"value_types/common/#configuration_2","text":"When a file is loaded, the path to the destination file can be set by creating a new FileValueType with the file_path argument. If no file_path is given, which is default, the file is loaded to a temporary file, that should be deleted by the user after its no longer needed.","title":"Configuration"},{"location":"value_types/common/#additional-meta-data-attributes_2","text":"None","title":"Additional meta-data attributes"},{"location":"value_types/common/#jsonvaluetype","text":"The JsonValueType can be used for storing lists and dictionaries of primitive values. It encodes those data structures as JSON string and stores it.","title":"JsonValueType"},{"location":"value_types/common/#supported-python-types_3","text":"list and dict , as long, as they contain only values of types that can be serialized to JSON using the standard json encoder, without the need of a custom JSONEncoder class.","title":"Supported python types"},{"location":"value_types/common/#configuration_3","text":"Not available","title":"Configuration"},{"location":"value_types/common/#additional-meta-data-attributes_3","text":"'media_type' : 'application/json'","title":"Additional meta-data attributes"},{"location":"value_types/common/#streamvaluetype","text":"The StreamValueType can be used for storing the content of binary streams. The value type reads from this stream, until it reaches EOF. The stream is not automatically closed, so it can be reused.","title":"StreamValueType"},{"location":"value_types/common/#supported-python-types_4","text":"typing.BinaryIO(IO[bytes])","title":"Supported python types"},{"location":"value_types/common/#configuration_4","text":"Not available","title":"Configuration"},{"location":"value_types/common/#additional-meta-data-attributes_4","text":"None","title":"Additional meta-data attributes"},{"location":"value_types/common/#stringvaluetype","text":"The StringValueType can be used for storing the content of binary streams. The value type reads from this stream, until it reaches EOF. The stream is not automatically closed, so it can be reused. The encoding that is used for storing the string can be set when defining the value_type explicitly. The encoding is stored in the meta-data and reused when loading a value.","title":"StringValueType"},{"location":"value_types/common/#supported-python-types_5","text":"str","title":"Supported python types"},{"location":"value_types/common/#configuration_5","text":"The value type supports configuring its default_encoding . This encoding will be used when storing a string. The encoding uses 'utf-8' as default. It can be used with a different default_encoding when a new instance of StringValueType is created that takes a different encoding as constructor argument.","title":"Configuration"},{"location":"value_types/common/#additional-meta-data-attributes_5","text":"'encoding' : The encoding that was used storing this value.","title":"Additional meta-data attributes"},{"location":"value_types/pandas/","text":"Value types for pandas data structures \ud83d\udd17 Pandas is a library for data analysis and manipulation. In order to make working with pandas and boxs easier, boxs comes with types for storing pandas types. Those types are only available, if the pandas package is available, otherwise the value types are not defined because of missing dependencies. PandasDataFrameCsvValueType \ud83d\udd17 The PandasDataFrameCsvValueType allows to store a pandas.DataFrame . The data is exported to a CSV file using the pandas to_csv() and read_csv() functions. Supported python types \ud83d\udd17 pandas.DataFrame Configuration \ud83d\udd17 The value type supports configuring its default_encoding . This encoding will be used when storing a the data frame. The encoding uses 'utf-8' as default. It can be used with a different default_encoding when a new instance of PandasDataFrameCsvValueType is created that takes a different encoding as constructor argument. Additional meta-data attributes \ud83d\udd17 'encoding' : The encoding that was used storing this value.","title":"Pandas"},{"location":"value_types/pandas/#value-types-for-pandas-data-structures","text":"Pandas is a library for data analysis and manipulation. In order to make working with pandas and boxs easier, boxs comes with types for storing pandas types. Those types are only available, if the pandas package is available, otherwise the value types are not defined because of missing dependencies.","title":"Value types for pandas data structures"},{"location":"value_types/pandas/#pandasdataframecsvvaluetype","text":"The PandasDataFrameCsvValueType allows to store a pandas.DataFrame . The data is exported to a CSV file using the pandas to_csv() and read_csv() functions.","title":"PandasDataFrameCsvValueType"},{"location":"value_types/pandas/#supported-python-types","text":"pandas.DataFrame","title":"Supported python types"},{"location":"value_types/pandas/#configuration","text":"The value type supports configuring its default_encoding . This encoding will be used when storing a the data frame. The encoding uses 'utf-8' as default. It can be used with a different default_encoding when a new instance of PandasDataFrameCsvValueType is created that takes a different encoding as constructor argument.","title":"Configuration"},{"location":"value_types/pandas/#additional-meta-data-attributes","text":"'encoding' : The encoding that was used storing this value.","title":"Additional meta-data attributes"},{"location":"value_types/tensorflow/","text":"Value types for tensorflow \ud83d\udd17 Tensorflow is a python framework for machine learning. Boxs comes with some value types for storing and loading tensorflow data types. These types require, that the tensorflow package is in the PYTHONPATH and can be loaded in order to store or load values. TensorflowKerasModelValueType \ud83d\udd17 The TensorflowKerasModelValueType allows to store a tensorflow.keras.Model . It uses the functions save_model() and load_model() from the tensorflow.keras.models package to first save the model to a temporary directory and then store the directory as a Zip archive. Loading the value goes the other way round, extracting the zip to a temporary directory and then recreate the model using load_model() function. Supported python types \ud83d\udd17 None, the value type has to be used explicitly by providing it as value_type argument to the call of store() . Configuration \ud83d\udd17 dir_path \ud83d\udd17 When a model is loaded, the path to the destination directory can be set by creating a new TensorflowKerasModelValueType with the dir_path argument. If no dir_path is given, which is default, the model is loaded to a temporary directory, that is automatically deleted. If dir_path is set, the model is extracted to the given directory and the directory is not deleted. default_format \ud83d\udd17 Additionally, the model can be stored in two different formats, 'h5' and 'tf'. As a default, 'tf' is used. For more information about this, please refer to the tensorflow documentation . Additional meta-data attributes \ud83d\udd17 'model_format' : The model format that was used storing the model. TensorBoardLogDirValueType \ud83d\udd17 The TensorBoardLogDirValueType allows to store the log directory for visualizing the training in Tensorboard. Tensorboard is a web frontend that allows to display training progress and metrics. Supported python types \ud83d\udd17 pathlib.Path , but the value type should only be used explicitly by providing it as value_type argument to the call of store() . Configuration \ud83d\udd17 When a log directory is loaded, the path to the destination directory can be set by creating a new TensorBoardLogDirValueType with the dir_path argument. Additional meta-data attributes \ud83d\udd17 'dir_content' : 'tensorboard-logs'","title":"Tensorflow"},{"location":"value_types/tensorflow/#value-types-for-tensorflow","text":"Tensorflow is a python framework for machine learning. Boxs comes with some value types for storing and loading tensorflow data types. These types require, that the tensorflow package is in the PYTHONPATH and can be loaded in order to store or load values.","title":"Value types for tensorflow"},{"location":"value_types/tensorflow/#tensorflowkerasmodelvaluetype","text":"The TensorflowKerasModelValueType allows to store a tensorflow.keras.Model . It uses the functions save_model() and load_model() from the tensorflow.keras.models package to first save the model to a temporary directory and then store the directory as a Zip archive. Loading the value goes the other way round, extracting the zip to a temporary directory and then recreate the model using load_model() function.","title":"TensorflowKerasModelValueType"},{"location":"value_types/tensorflow/#supported-python-types","text":"None, the value type has to be used explicitly by providing it as value_type argument to the call of store() .","title":"Supported python types"},{"location":"value_types/tensorflow/#configuration","text":"","title":"Configuration"},{"location":"value_types/tensorflow/#dir_path","text":"When a model is loaded, the path to the destination directory can be set by creating a new TensorflowKerasModelValueType with the dir_path argument. If no dir_path is given, which is default, the model is loaded to a temporary directory, that is automatically deleted. If dir_path is set, the model is extracted to the given directory and the directory is not deleted.","title":"dir_path"},{"location":"value_types/tensorflow/#default_format","text":"Additionally, the model can be stored in two different formats, 'h5' and 'tf'. As a default, 'tf' is used. For more information about this, please refer to the tensorflow documentation .","title":"default_format"},{"location":"value_types/tensorflow/#additional-meta-data-attributes","text":"'model_format' : The model format that was used storing the model.","title":"Additional meta-data attributes"},{"location":"value_types/tensorflow/#tensorboardlogdirvaluetype","text":"The TensorBoardLogDirValueType allows to store the log directory for visualizing the training in Tensorboard. Tensorboard is a web frontend that allows to display training progress and metrics.","title":"TensorBoardLogDirValueType"},{"location":"value_types/tensorflow/#supported-python-types_1","text":"pathlib.Path , but the value type should only be used explicitly by providing it as value_type argument to the call of store() .","title":"Supported python types"},{"location":"value_types/tensorflow/#configuration_1","text":"When a log directory is loaded, the path to the destination directory can be set by creating a new TensorBoardLogDirValueType with the dir_path argument.","title":"Configuration"},{"location":"value_types/tensorflow/#additional-meta-data-attributes_1","text":"'dir_content' : 'tensorboard-logs'","title":"Additional meta-data attributes"}]}